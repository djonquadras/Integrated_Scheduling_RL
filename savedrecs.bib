
@article{ WOS:000626841000007,
Author = {Zhang, Qing and Yin, Gang George and Wang, Le Yi},
Title = {Two-time scale reinforcement learning and applications to production
   planning},
Journal = {IET CONTROL THEORY AND APPLICATIONS},
Year = {2020},
Volume = {14},
Number = {19},
Pages = {3052-3061},
Month = {DEC 21},
Abstract = {This study is concerned with reinforcement learning enhanced by two-time
   scale approximations. Many systems arising in applications are large and
   complex. To treat these problems, it is often beneficial, and sometimes
   necessary, to reduce the dimensionality and aggregate states that are
   `close' to each other. In this study, the authors propose a two-time
   scale reinforcement learning method for such an aggregation process. In
   particular, they present how to classify states that are `close' and
   demonstrate the effectiveness of the authors' state aggregation based
   two-time scale methods. Thus the problem can be considered as using
   learning for identifying the system. A production planning problem with
   failure-prone machines is used throughout this study to illustrate the
   main ideas, key steps and results. Monte Carlo simulations are used to
   generate the random environment.},
Publisher = {WILEY},
Address = {111 RIVER ST, HOBOKEN 07030-5774, NJ USA},
Type = {Article},
Language = {English},
Affiliation = {Zhang, Q (Corresponding Author), Univ Georgia, Dept Math, Athens, GA 30602 USA.
   Zhang, Qing, Univ Georgia, Dept Math, Athens, GA 30602 USA.
   Yin, Gang George, Univ Connecticut, Dept Math, Storrs, CT 06269 USA.
   Wang, Le Yi, Wayne State Univ, Dept Elect \& Comp Engn, Detroit, MI 48202 USA.},
DOI = {10.1049/iet-cta.2020.0049},
ISSN = {1751-8644},
EISSN = {1751-8652},
Keywords = {production planning; learning (artificial intelligence); Monte Carlo
   methods; two-time scale approximations; aggregate states; two-time scale
   reinforcement learning method; aggregation process; authors; two-time
   scale methods; production planning problem},
Research-Areas = {Automation \& Control Systems; Engineering; Instruments \&
   Instrumentation},
Web-of-Science-Categories  = {Automation \& Control Systems; Engineering, Electrical \& Electronic;
   Instruments \& Instrumentation},
Author-Email = {qz@uga.edu},
Funding-Acknowledgement = {Army Research Office {[}W911NF-19-1-0176]},
Funding-Text = {This research was supported in part by the Army Research Office under
   grant W911NF-19-1-0176.},
Cited-References = {AKELLA R, 1986, IEEE T AUTOMAT CONTR, V31, P116, DOI 10.1109/TAC.1986.1104206.
   {[}白尔维 Bai Erwei], 2016, {[}中国科学. 数学, Scientia Sinica Mathematica], V46, P1383.
   Bensoussan A, 2005, SIAM J CONTROL OPTIM, V44, P1650, DOI 10.1137/S0363012904443737.
   Berkovitz L. D., 1974, OPTIMAL CONTROL THEO.
   Cadavid JPU, 2019, IFAC PAPERSONLINE, V52, P385, DOI 10.1016/j.ifacol.2019.11.155.
   COSTA OLV, 2013, SPRINGER BRIEFS MATH.
   Guo J, 2021, ASIAN J CONTROL, V23, P118, DOI 10.1002/asjc.2237.
   Han J, 2018, P NATL ACAD SCI USA, V115, P8505, DOI 10.1073/pnas.1718942115.
   Kushner H, 1997, STOCHASTIC APPROXIMA.
   Kushner HJ., 1984, APPROXIMATION WEAK C.
   Manning JR, 2013, J AM HEART ASSOC, V2, DOI 10.1161/JAHA.113.000459.
   Mu BQ, 2018, AUTOMATICA, V94, P381, DOI 10.1016/j.automatica.2018.04.035.
   Mu BQ, 2017, AUTOMATICA, V77, P322, DOI 10.1016/j.automatica.2016.11.009.
   O'Malley R. E., 1991, SINGULAR PERTURBATIO.
   Perthame B., 1987, 18 EC NORM SUP.
   PHILLIPS RG, 1981, IEEE T AUTOMAT CONTR, V26, P1087, DOI 10.1109/TAC.1981.1102780.
   Sethi S. P., 1994, HIERARCHICAL DECISIO.
   SIMON HA, 1961, ECONOMETRICA, V29, P111, DOI 10.2307/1909285.
   Tran KQ, 2017, IET CONTROL THEORY A, V11, P2521, DOI 10.1049/iet-cta.2016.1621.
   TSITSIKLIS JN, 1994, MACH LEARN, V16, P185, DOI 10.1023/A:1022689125041.
   Cadavid JPU, 2020, J INTELL MANUF, V31, P1531, DOI 10.1007/s10845-019-01531-7.
   WATKINS CJCH, 1992, MACH LEARN, V8, P279, DOI 10.1007/bf00992698.
   Yin G, 2008, J OPTIMIZ THEORY APP, V137, P435, DOI 10.1007/s10957-007-9331-9.
   Yin G., 2013, 2 TIME SCALE MARKOVI.
   Zhang Q, 2005, MULTISCALE MODEL SIM, V4, P172, DOI 10.1137/040606338.
   Zhang Q, 1999, IEEE T AUTOMAT CONTR, V44, P2271, DOI 10.1109/9.811209.},
Number-of-Cited-References = {26},
Times-Cited = {0},
Usage-Count-Last-180-days = {3},
Usage-Count-Since-2013 = {6},
Journal-ISO = {IET Contr. Theory Appl.},
Doc-Delivery-Number = {QT8LW},
Web-of-Science-Index = {Science Citation Index Expanded (SCI-EXPANDED)},
Unique-ID = {WOS:000626841000007},
DA = {2022-04-30},
}

@article{ WOS:000769273200005,
Author = {Kosanoglu, Fuat and Atmis, Mahir and Turan, Hasan Huseyin},
Title = {A deep reinforcement learning assisted simulated annealing algorithm for
   a maintenance planning problem},
Journal = {ANNALS OF OPERATIONS RESEARCH},
Abstract = {Maintenance planning aims to improve the reliability of assets, prevent
   the occurrence of asset failures, and reduce maintenance costs
   associated with downtime of assets and maintenance resources (such as
   spare parts and workforce). Thus, effective maintenance planning is
   instrumental in ensuring high asset availability with the minimum cost.
   Nevertheless, to find such optimal planning is a nontrivial task due to
   the (i) complex and usually nonlinear inter-relationship between
   different planning decisions (e.g., inventory level and workforce
   capacity), and (ii) stochastic nature of the system (e.g., random
   failures of parts installed in assets). To alleviate these challenges,
   we study a joint maintenance planning problem by considering several
   decisions simultaneously, including workforce planning, workforce
   training, and spare parts inventory management. We develop a hybrid
   solution algorithm (DRLSA) that is a combination of Double Deep
   Q-Network based Deep Reinforcement Learning (DRL) and Simulated
   Annealing (SA) algorithms. In each episode of the proposed algorithm,
   the best solution found by DRL is delivered to SA to be used as an
   initial solution, and the best solution of SA is delivered to DRL to be
   used as the initial state. Different from the traditional SA algorithms
   where neighborhood structures are selected only randomly, the DRL part
   of DRLSA learns to choose the best neighborhood structure to use based
   on experience gained from previous episodes. We compare the performance
   of the proposed solution algorithm with several well-known
   meta-heuristic algorithms, including Simulated Annealing, Genetic
   Algorithm (GA), and Variable Neighborhood Search (VNS). Further, we also
   develop a Machine Learning (ML) algorithm (i.e., K-Median) as another
   benchmark in which different properties of spare parts (e.g., failure
   rates, holding costs, and repair rates) are used as clustering features
   for theMLalgorithm. Our study reveals that the DRLSA finds the optimal
   solutions for relatively small-size instances, and it has the potential
   to outperform traditional meta-heuristic and ML algorithms.},
Publisher = {SPRINGER},
Address = {VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS},
Type = {Article; Early Access},
Language = {English},
Affiliation = {Turan, HH (Corresponding Author), Univ New South Wales, Capabil Syst Ctr, Canberra, ACT, Australia.
   Kosanoglu, Fuat; Atmis, Mahir, Yalova Univ, Dept Ind Engn, Yalova, Turkey.
   Turan, Hasan Huseyin, Univ New South Wales, Capabil Syst Ctr, Canberra, ACT, Australia.},
DOI = {10.1007/s10479-022-04612-8},
EarlyAccessDate = {MAR 2022},
ISSN = {0254-5330},
EISSN = {1572-9338},
Keywords = {Maintenance planning; Workforce planning and training; Inventory
   management; Double deep Q-network; Deep reinforcement learning;
   Simulated annealing},
Keywords-Plus = {PART INVENTORY SYSTEM; JOINT OPTIMIZATION; NETWORK APPROACH;
   MULTI-INDENTURE; MULTIECHELON; BACKORDERS; ONLINE; LEVEL},
Research-Areas = {Operations Research \& Management Science},
Web-of-Science-Categories  = {Operations Research \& Management Science},
Author-Email = {h.turan@adfa.edu.au},
Funding-Acknowledgement = {CAUL},
Funding-Text = {Open Access funding enabled and organized by CAUL and its Member
   Institutions.},
Cited-References = {Allen TT, 2018, COMPUT IND ENG, V126, P578, DOI 10.1016/j.cie.2018.09.051.
   Andriotis CP, 2019, RELIAB ENG SYST SAFE, V191, DOI 10.1016/j.ress.2019.04.036.
   Andriotis C.P., 2018, ARXIV181102052 CORR.
   Arsenault R, 2016, STAT WEEK RISING COS.
   Bello I., 2017, ARXIV161109940.
   Bengio Y, 2021, EUR J OPER RES, V290, P405, DOI 10.1016/j.ejor.2020.07.063.
   Chen W., 2017, ARXIV PREPRINT ARXIV.
   Chen X., 2019, ARXIV181000337.
   CONNOLLY DT, 1990, EUR J OPER RES, V46, P93, DOI 10.1016/0377-2217(90)90301-Q.
   Deudon M, 2018, LECT NOTES COMPUT SC, V10848, P170, DOI 10.1007/978-3-319-93031-2\_12.
   Du K.-L, 2016, SEARCH OPTIMIZATION, P29, DOI {[}10.1007/978-3-319-41192-7\_2, DOI 10.1007/978-3-319-41192-7\_2].
   Duan L., 2019, ARXIV180406896.
   Etheve Marc, 2020, Integration of Constraint Programming, Artificial Intelligence, and Operations Research. 17th International Conference, CPAIOR 2020. Proceedings. Lecture Notes in Computer Science (LNCS 12296), P176, DOI 10.1007/978-3-030-58942-4\_12.
   Francois-Lavet V, 2018, FOUND TRENDS MACH LE, V11, P219, DOI 10.1561/2200000071.
   Gama R, 2020, ARXIV201103647.
   Hicks G, 2019, MUCH IS EQUIPMENT DO.
   Hottung A, 2020, COMPUT OPER RES, V113, DOI 10.1016/j.cor.2019.104781.
   Hu H., 2017, ARXIV170805930.
   Hu JY, 2020, IEEE T VEH TECHNOL, V69, P14413, DOI 10.1109/TVT.2020.3034800.
   Huang J, 2020, EXPERT SYST APPL, V160, DOI 10.1016/j.eswa.2020.113701.
   Hubbs CD, 2020, COMPUT CHEM ENG, V141, DOI 10.1016/j.compchemeng.2020.106982.
   Jiuxia Zhao, 2021, IEEE Transactions on Intelligent Transportation Systems, V22, P7208, DOI 10.1109/TITS.2020.3003163.
   JORDAN WC, 1995, MANAGE SCI, V41, P577, DOI 10.1287/mnsc.41.4.577.
   Kandel I, 2020, ICT EXPRESS, V6, P312, DOI 10.1016/j.icte.2020.04.010.
   King DB, 2015, ACS SYM SER, V1214, P1.
   KIRKPATRICK S, 1984, J STAT PHYS, V34, P975, DOI 10.1007/BF01009452.
   KIRKPATRICK S, 1983, SCIENCE, V220, P671, DOI 10.1126/science.220.4598.671.
   Kool W, 2019, ARXIV180308475V3.
   Kosanoglu F., 2018, P INT C COMP IND ENG, P1.
   Krasheninnikova E, 2019, ENG APPL ARTIF INTEL, V80, P8, DOI 10.1016/j.engappai.2019.01.010.
   Levner E, 2011, INT J PROD ECON, V132, P43, DOI 10.1016/j.ijpe.2011.03.004.
   Li Z, 2019, CHINESE J AERONAUT, V32, P2133, DOI 10.1016/j.cja.2019.07.003.
   Liang SS, 2020, LECT NOTES ARTIF INT, V12085, P906, DOI 10.1007/978-3-030-47436-2\_68.
   Lin B., 2020, ARXIV201002068.
   Liu CL, 2020, IEEE ACCESS, V8, P71752, DOI 10.1109/ACCESS.2020.2987820.
   Ma Q., 2019, COMBINATORIAL OPTIMI.
   Mahmoodzadeh Z, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20195708.
   Mao HZ, 2016, PROCEEDINGS OF THE 15TH ACM WORKSHOP ON HOT TOPICS IN NETWORKS (HOTNETS `16), P50, DOI 10.1145/3005745.3005750.
   Mazyavkina N., 2020, ARXIV200303600.
   Mnih V, 2015, NATURE, V518, P529, DOI 10.1038/nature14236.
   Muckstadt JA, 2005, SPRINGER SER OPER RE, P1.
   MUCKSTADT JA, 1973, MANAGE SCI B-APPL, V20, P472, DOI 10.1287/mnsc.20.4.472.
   Nazari M, 2018, ADV NEUR IN, V31.
   Ong K. S. H., 2020, P IEEE 6 WORLD FOR I, P1.
   Petsagkourakis P, 2020, COMPUT CHEM ENG, V133, DOI 10.1016/j.compchemeng.2019.106649.
   Rahmati SHA, 2018, ANN OPER RES, V269, P583, DOI 10.1007/s10479-017-2594-0.
   Ranka S, 2018, LEARNING PERMUTATION.
   Rocchetta R, 2019, APPL ENERG, V241, P291, DOI 10.1016/j.apenergy.2019.03.027.
   Salari N, 2020, ANN OPER RES, V287, P351, DOI 10.1007/s10479-019-03371-3.
   Samouei P, 2015, ANN OPER RES, V226, P551, DOI 10.1007/s10479-014-1718-z.
   SHERBROOKE CC, 1986, OPER RES, V34, P311, DOI 10.1287/opre.34.2.311.
   SHERBROOKE CC, 1968, OPER RES, V16, P122, DOI 10.1287/opre.16.1.122.
   Skordilis E, 2020, COMPUT IND ENG, V147, DOI 10.1016/j.cie.2020.106600.
   Sleptchenko A, 2019, INT J PROD ECON, V209, P334, DOI 10.1016/j.ijpe.2017.12.018.
   Sleptchenko A, 2018, EUR J OPER RES, V271, P97, DOI 10.1016/j.ejor.2018.05.014.
   Sleptchenko A, 2016, RELIAB ENG SYST SAFE, V153, P64, DOI 10.1016/j.ress.2016.04.006.
   Suman B, 2006, J OPER RES SOC, V57, P1143, DOI 10.1057/palgrave.jors.2602068.
   Tang Y., 2020, ARXIV190604859.
   Turan HH, 2020, RELIAB ENG SYST SAFE, V204, DOI 10.1016/j.ress.2020.107199.
   Turan HH, 2020, COMPUT OPER RES, V117, DOI 10.1016/j.cor.2020.104887.
   Turan HH, 2021, INT J PROD RES, V59, P2624, DOI 10.1080/00207543.2020.1735665.
   Turan HH, 2018, COMPUT IND ENG, V125, P232, DOI 10.1016/j.cie.2018.08.032.
   Van Harten A, 2003, QUEUEING SYST, V43, P307, DOI 10.1023/A:1023209813523.
   Walraven E, 2016, ENG APPL ARTIF INTEL, V52, P203, DOI 10.1016/j.engappai.2016.01.001.
   Wang Y, 2020, ANN OPER RES, DOI 10.1007/s10479-020-03805-3.
   Waschneck B, 2018, PROC CIRP, V72, P1264, DOI 10.1016/j.procir.2018.03.212.
   Waschneck B, 2018, ASMC PROC, P301, DOI 10.1109/ASMC.2018.8373191.
   WATKINS CJCH, 1992, MACH LEARN, V8, P279, DOI 10.1007/bf00992698.
   Wei SY, 2020, STRUCT SAF, V83, DOI 10.1016/j.strusafe.2019.101906.
   Wu Y., 2019, ARXIV190806477.
   Yao LY, 2020, COMPUT-AIDED CIV INF, V35, P1230, DOI 10.1111/mice.12558.
   Yu JJQ, 2019, IEEE T INTELL TRANSP, V20, P3806, DOI 10.1109/TITS.2019.2909109.
   Zhang C, 2019, LECT NOTES ARTIF INT, V11053, P488, DOI 10.1007/978-3-030-10997-4\_30.
   Zhang NL, 2020, RELIAB ENG SYST SAFE, V203, DOI 10.1016/j.ress.2020.107094.},
Number-of-Cited-References = {74},
Times-Cited = {0},
Usage-Count-Last-180-days = {3},
Usage-Count-Since-2013 = {3},
Journal-ISO = {Ann. Oper. Res.},
Doc-Delivery-Number = {ZT6OM},
Web-of-Science-Index = {Science Citation Index Expanded (SCI-EXPANDED)},
Unique-ID = {WOS:000769273200005},
OA = {hybrid},
DA = {2022-04-30},
}

@inproceedings{ WOS:000493989300014,
Author = {Kuhnle, Andreas and Lanza, Gisela},
Editor = {Beyerer, J and Kuhnert, C and Niggemann, O},
Title = {Application of Reinforcement Learning in Production Planning and Control
   of Cyber Physical Production Systems},
Booktitle = {MACHINE LEARNING FOR CYBER PHYSICAL SYSTEMS, ML4CPS 2018},
Series = {Technologien fur die intelligente Automation},
Year = {2019},
Volume = {9},
Pages = {123-132},
Note = {4th Conference on Machine Learning for Cyber-Physical-Systems and
   Industry 4.0 (ML4CPS), Fraunhofer IOSB, Karlsruhe, GERMANY, OCT 23-24,
   2018},
Abstract = {Cyber Physical Production Systems (CPPS) provide a huge amount and
   variety of process and production data. Simultaneously, operational
   decisions are getting ever more complex due to smaller batch sizes (down
   to batch size one), a larger product variety and complex processes in
   production systems. Production engineers struggle to utilize the
   recorded data to optimize production processes effectively.
   In contrast, CPPS promote decentralized decision-making, so-called
   intelligent agents that are able to gather data (via sensors), process
   these data, possibly in combination with other information via a
   connection to and exchange with others, and finally take decisions into
   action (via actors). Modular and decentralized decision-making systems
   are thereby able to handle far more complex systems than rigid and
   static architectures.
   This paper discusses possible applications of Machine Learning (ML)
   algorithms, in particular Reinforcement Learning (RL), and the
   potentials towards an production planning and control aiming for
   operational excellence.},
Publisher = {SPRINGER-VERLAG BERLIN},
Address = {HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY},
Type = {Proceedings Paper},
Language = {English},
Affiliation = {Kuhnle, A (Corresponding Author), Karlsruhe Inst Technol KIT, Wbk Inst Prod Sci, Karlsruhe, Germany.
   Kuhnle, Andreas; Lanza, Gisela, Karlsruhe Inst Technol KIT, Wbk Inst Prod Sci, Karlsruhe, Germany.},
DOI = {10.1007/978-3-662-58485-9\_14},
ISBN = {978-3-662-58485-9; 978-3-662-58484-2},
Keywords = {Production planning and control; Order dispatching; Maintenance
   management; Artificial intelligence; Reinforcement Learning},
Research-Areas = {Computer Science; Engineering},
Web-of-Science-Categories  = {Computer Science, Artificial Intelligence; Engineering,
   Multidisciplinary},
Author-Email = {andreas.kuhnle@kit.edu},
Funding-Acknowledgement = {German Federal Ministry of Education and Research (BMBF)Federal Ministry
   of Education \& Research (BMBF) {[}02P14B161]},
Funding-Text = {We extend our sincere thanks to the German Federal Ministry of Education
   and Research (BMBF) for supporting this research project 02P14B161
   ``Empowerment and Implementation Strategies for Industry 4.0{''}.},
Cited-References = {Csaji BC, 2006, ADV ENG INFORM, V20, P279, DOI 10.1016/j.aei.2006.01.001.
   Ertel W, 2011, INTRO ARTIFICIAL INT.
   Gunther J, 2016, MECHATRONICS, V34, P1, DOI 10.1016/j.mechatronics.2015.09.004.
   Mnih V., 2013, PROC 27 C NEURAL INF, P1.
   Monch L., 2013, PRODUCTION PLANNING.
   Monostori L, 2006, CIRP ANN-MANUF TECHN, V55, P697, DOI 10.1016/j.cirp.2006.10.004.
   Monostori L, 2004, CIRP ANN-MANUF TECHN, V53, P349, DOI 10.1016/S0007-8506(07)60714-8.
   Russel S.J., 2016, ARTIFICIAL INTELLIGE.
   Schulman J., 2017, 170706347 ARXIV.
   Schulman J, 2015, PR MACH LEARN RES, V37, P1889.
   Stegherr F., 2000, REINFORCEMENT LEARNI.
   Stricker N, 2018, CIRP ANN-MANUF TECHN, V67, P511, DOI 10.1016/j.cirp.2018.04.041.
   Sturm R, 2006, MODELLBASIERTES VERF.
   Sutton R. S., 1998, REINFORCEMENT LEARNI.
   Thomas M., 1997, MACHINE LEARNING, V1.},
Number-of-Cited-References = {15},
Times-Cited = {6},
Usage-Count-Last-180-days = {3},
Usage-Count-Since-2013 = {8},
Doc-Delivery-Number = {BO0YY},
Web-of-Science-Index = {Conference Proceedings Citation Index - Science (CPCI-S)},
Unique-ID = {WOS:000493989300014},
OA = {hybrid},
DA = {2022-04-30},
}

@article{ WOS:000663910000007,
Author = {Andriotis, C. P. and Papakonstantinou, K. G.},
Title = {Deep reinforcement learning driven inspection and maintenance planning
   under incomplete information and constraints},
Journal = {RELIABILITY ENGINEERING \& SYSTEM SAFETY},
Year = {2021},
Volume = {212},
Month = {AUG},
Abstract = {Determination of inspection and maintenance policies for minimizing
   long-term risks and costs in deteriorating engineering environments
   constitutes a complex optimization problem. Major computational
   challenges include the (i) curse of dimensionality, due to exponential
   scaling of state/action set cardinalities with the number of components;
   (ii) curse of history, related to exponentially growing decision-trees
   with the number of decisionsteps; (iii) presence of state uncertainties,
   induced by inherent environment stochasticity and variability of
   inspection/monitoring measurements; (iv) presence of constraints,
   pertaining to stochastic long-term limitations, due to resource scarcity
   and other infeasible/undesirable system responses. In this work, these
   challenges are addressed within a joint framework of constrained
   Partially Observable Markov Decision Processes (POMDP) and multi-agent
   Deep Reinforcement Learning (DRL). POMDPs optimally tackle (ii)-(iii),
   combining stochastic dynamic programming with Bayesian inference
   principles. Multi-agent DRL addresses (i), through deep function
   parametrizations and decentralized control assumptions. Challenge (iv)
   is herein handled through proper state augmentation and Lagrangian
   relaxation, with emphasis on life-cycle risk-based constraints and
   budget limitations. The underlying algorithmic steps are provided, and
   the proposed framework is found to outperform well-established policy
   baselines and facilitate adept prescription of inspection and
   intervention actions, in cases where decisions must be made in the most
   resource- and risk-aware manner.},
Publisher = {ELSEVIER SCI LTD},
Address = {THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, OXON, ENGLAND},
Type = {Article},
Language = {English},
Affiliation = {Andriotis, CP (Corresponding Author), Delft Univ Technol, Fac Architecture \& Built Environm, NL-2628 BL Delft, Netherlands.
   Andriotis, C. P., Delft Univ Technol, Fac Architecture \& Built Environm, NL-2628 BL Delft, Netherlands.
   Papakonstantinou, K. G., Penn State Univ, Dept Civil \& Environm Engn, University Pk, PA USA.},
DOI = {10.1016/j.ress.2021.107551},
EarlyAccessDate = {APR 2021},
Article-Number = {107551},
ISSN = {0951-8320},
EISSN = {1879-0836},
Keywords = {Inspection and maintenance planning; System risk and reliability;
   Constrained stochastic optimization; Partially observable Markov
   decision processes; Deep reinforcement learning; Decentralized
   multi-agent control},
Keywords-Plus = {MARKOV DECISION-PROCESSES; STRUCTURAL INSPECTION; FRAMEWORK; ALGORITHMS;
   POLICIES; INFRASTRUCTURE; OPERATION; SYSTEMS; DESIGN; POMDP},
Research-Areas = {Engineering; Operations Research \& Management Science},
Web-of-Science-Categories  = {Engineering, Industrial; Operations Research \& Management Science},
Author-Email = {c.andriotis@tudelft.nl},
ORCID-Numbers = {Andriotis, Charalampos P./0000-0002-0140-5021},
Funding-Acknowledgement = {U.S. National Science FoundationNational Science Foundation (NSF)
   {[}1751941]; Center for Integrated Asset Management for Multimodal
   Transportation Infrastructure Systems (CIAMTIS), 2018 U.S. DOT Region 3
   University Center},
Funding-Text = {This material is based upon work supported by the U.S. National Science
   Foundation under CAREER Grant No. 1751941, and the Center for Integrated
   Asset Management for Multimodal Transportation Infrastructure Systems
   (CIAMTIS), 2018 U.S. DOT Region 3 University Center.},
Cited-References = {Achiam J, 2017, 34 INT C MACH LEARN.
   ALTMAN E, 1999, STOCH MODEL SER.
   Amir M, J ENG MECH, V2021.
   Andriotis CP, 2019, RELIAB ENG SYST SAFE, V191, DOI 10.1016/j.ress.2019.04.036.
   Andriotis CP, 2018, J ENG MECH, V144, DOI 10.1061/(ASCE)EM.1943-7889.0001478.
   Andriotis CP, 2019, 13 INT C APPL STAT P.
   Andriotis CP, 2018, P COMP STOCH MECH C.
   Andriotis CP, 2020, IN PRESS.
   Baker B., 2019, ARXIV190907528.
   BELLMAN R, 1956, P NATL ACAD SCI USA, V42, P767, DOI 10.1073/pnas.42.10.767.
   Bellman R., 1957, DYNAMIC PROGRAMMING.
   Bernstein DS, 2002, MATH OPER RES, V27, P819, DOI 10.1287/moor.27.4.819.297.
   Bertsekas D, 1999, NONLINEAR PROGRAMMIN.
   Bertsekas Dimitri P., 2005, DYNAMIC PROGRAMMING, V1.
   Bismut E, 2018, 6 INT S REL ENG RISK.
   Bocchini P, 2011, RELIAB ENG SYST SAFE, V96, P332, DOI 10.1016/j.ress.2010.09.001.
   Bocchini P, 2012, J BRIDGE ENG, V17, P117, DOI 10.1061/(ASCE)BE.1943-5592.0000201.
   Castanier B, 2003, APPL STOCH MODEL BUS, V19, P327, DOI 10.1002/asmb.493.
   Chow Y., 2017, J MACH LEARN RES, V18, P6070.
   Colone L, 2019, WIND ENERGY, V22, P1230, DOI 10.1002/we.2352.
   Corotis R.B., 1995, J INFRASTRUCT SYST, V1, P92, DOI {[}10.1061/(ASCE)1076-0342(1995)1:2(92), DOI 10.1061/(ASCE)1076-0342(1995)1:2(92)].
   Degris T., 2012, ARXIV12054839.
   Di Castro D, 2012, ARXIV12066404.
   Faber MH, 2003, RELIAB ENG SYST SAFE, V80, P173, DOI 10.1016/S0951-8320(03)00027-9.
   Frangopol D.M., 2004, PROG STRUCT MAT ENG, V6, P197, DOI {[}DOI 10.1002/PSE.180, 10.1002/pse.180].
   Frangopol DM, 1997, J STRUCT ENG-ASCE, V123, P1390, DOI 10.1061/(ASCE)0733-9445(1997)123:10(1390).
   Garcia J, 2015, J MACH LEARN RES, V16, P1437.
   Gonzalez AD, 2016, COMPUT-AIDED CIV INF, V31, P334, DOI 10.1111/mice.12171.
   Goulet JA, 2015, STRUCT SAF, V52, P1, DOI 10.1016/j.strusafe.2014.08.001.
   Grall A, 2002, IEEE T RELIAB, V51, P141, DOI 10.1109/TR.2002.1011518.
   Grall A, 2002, RELIAB ENG SYST SAFE, V76, P167, DOI 10.1016/S0951-8320(01)00148-X.
   Gupta JK, 2017, INT C AUT AG MULT SY.
   Hernandez-Leal P, 2019, AUTON AGENT MULTI-AG, V33, P750, DOI 10.1007/s10458-019-09421-1.
   ineau J, 2003, INT JOINT C ART INT.
   Isom JD, 2008, ASS ADV ART INT AAAI.
   Kaelbling LP, 1998, ARTIF INTELL, V101, P99, DOI 10.1016/S0004-3702(98)00023-X.
   Kim Dongho, 2011, 22 INT JOINT C ART I.
   Kingma D.P., 2014, ARXIV PREPRINT ARXIV.
   Liu Y, 2020, EUR J OPER RES, V283, P166, DOI 10.1016/j.ejor.2019.10.049.
   Luque J, 2019, STRUCT SAF, V76, P68, DOI 10.1016/j.strusafe.2018.08.002.
   Madanat S, 1993, TRANSPORT RES C-EMER, V1, P77, DOI DOI 10.1016/0968-090X(93)90021-7.
   Marseguerra M, 2002, RELIAB ENG SYST SAFE, V77, P151, DOI 10.1016/S0951-8320(02)00043-1.
   Memarzadeh M, 2016, RELIAB ENG SYST SAFE, V153, P159, DOI 10.1016/j.ress.2016.04.016.
   Memarzadeh M, 2016, COMPUT-AIDED CIV INF, V31, P403, DOI 10.1111/mice.12178.
   Morato PG, 2019, 13 INT C APPL STAITS.
   Morato PG, 2020, STRUCT SAF.
   Nicolai RP, 2008, SPRINGER SER RELIAB, P263, DOI 10.1007/978-1-84800-011-7\_11.
   Nozhati S, 2020, RELIAB ENG SYST SAFE, V193, DOI 10.1016/j.ress.2019.106627.
   Oliehoek F. A., 2016, CONCISE INTRO DECENT.
   OroojlooyJadid A, 2019, REV COOPERATIVE MULT.
   Papakonstantinou KG, 2014, PROBABILIST ENG MECH, V37, P93, DOI 10.1016/j.probengmech.2014.06.002.
   Papakonstantinou KG, 2014, RELIAB ENG SYST SAFE, V130, P214, DOI 10.1016/j.ress.2014.04.006.
   Papakonstantinou KG, 2014, RELIAB ENG SYST SAFE, V130, P202, DOI 10.1016/j.ress.2014.04.005.
   Papakonstantinou KG, 2021, IN PRESS.
   Papakonstantinou KG, 2016, P 5 INT S LIF CYCL C.
   Papakonstantinou KG, 2016, IFIP WG 75 C REL OPT.
   Papakonstantinou KG, 2019, 13 INT C APPL STAT P.
   Papakonstantinou KG, 2018, STRUCT INFRASTRUCT E, V14, P869, DOI 10.1080/15732479.2018.1439973.
   Peng XB, 2018, ACM T GRAPHIC, V37, DOI 10.1145/3197517.3201311.
   Poupart P, 2015, 29 C ASS ADV ART INT.
   Prashanth LA, 2016, MACH LEARN, V105, P367, DOI 10.1007/s10994-016-5569-5.
   Putterman M. L., 1994, MARKOV DECISION PROC.
   Rackwitz R, 2005, STRUCT SAF, V27, P187, DOI 10.1016/j.strusafe.2004.10.002.
   Rocchetta R, 2019, APPL ENERG, V241, P291, DOI 10.1016/j.apenergy.2019.03.027.
   Rockafellar RT, 2002, J BANK FINANC, V26, P1443, DOI 10.1016/S0378-4266(02)00271-6.
   Rokneddin K, 2013, STRUCT INFRASTRUCT E, V9, P1050, DOI 10.1080/15732479.2011.654230.
   Sanchez-Silva M, 2016, J STRUCT ENG, V142, DOI 10.1061/(ASCE)ST.1943-541X.0001543.
   Saydam D, 2015, J STRUCT ENG, V141, DOI 10.1061/(ASCE)ST.1943-541X.0001038.
   Schobi R, 2016, STRUCT INFRASTRUCT E, V12, P977, DOI 10.1080/15732479.2015.1076485.
   Schulman John, 2015, INT C MACH LEARN.
   Shani G, 2013, AUTON AGENT MULTI-AG, V27, P1, DOI 10.1007/s10458-012-9200-2.
   Skordilis E, 2020, COMPUT IND ENG, V147, DOI 10.1016/j.cie.2020.106600.
   Smith AE, 1995, HDB EVOLUTIONARY COM, V1, P97.
   Sondik E.J, 1971, OPTIMAL CONTROL PART.
   Sorensen JD, 2009, WIND ENERGY, V12, P493, DOI 10.1002/we.344.
   Straub D, 2005, STRUCT SAF, V27, P335, DOI 10.1016/j.strusafe.2005.04.001.
   Tessler C., 2018, ARXIV180511074.
   Walraven E, 2018, J ARTIF INTELL RES, V62, P489, DOI 10.1613/jair.1.11216.
   Wang Z., 2016, ARXIV161101224.
   Yang DY, 2019, RELIAB ENG SYST SAFE, V183, P197, DOI 10.1016/j.ress.2018.11.016.
   Zhang N, 2020, COMPUT-AIDED CIV INF, V35, P116, DOI 10.1111/mice.12482.
   Zhang Y., 2020, ARXIV200206506.},
Number-of-Cited-References = {82},
Times-Cited = {7},
Usage-Count-Last-180-days = {12},
Usage-Count-Since-2013 = {15},
Journal-ISO = {Reliab. Eng. Syst. Saf.},
Doc-Delivery-Number = {SV6DJ},
Web-of-Science-Index = {Science Citation Index Expanded (SCI-EXPANDED)},
Unique-ID = {WOS:000663910000007},
OA = {Green Published, Green Submitted, Bronze},
DA = {2022-04-30},
}

@article{ WOS:000648207900001,
Author = {Zhang, Huidong and Djurdjanovic, Dragan},
Title = {Integrated production and maintenance planning under uncertain demand
   with concurrent learning of yield rate},
Journal = {FLEXIBLE SERVICES AND MANUFACTURING JOURNAL},
Abstract = {Strong interactions between decisions in the maintenance and production
   scheduling domains, and their impacts on the equipment yield rates
   necessitate maintenance and production decisions being optimized
   concurrently, with considerations of yield dependencies on the equipment
   conditions and production rates. This paper proposes an integrated
   decision-making policy for production and maintenance operations on a
   single machine under uncertain demand, with concurrent considerations
   and learning of yield dependencies on the equipment conditions and
   production rates. This policy is obtained through a two-stage stochastic
   programming model, which considers the variable demand, machine
   degradation, and maintenance times. This model incorporates outsourcing
   decisions and operational decisions regarding reworking, scraping of
   imperfect products to ensure the demand is adequately met. A closed-form
   reinforcement learning method is utilized to learn yield dependencies.
   Simulations confirm the necessity of yield learning and show the
   proposed method outperforms the traditional, fragmented approaches where
   the effects of production rates and machine conditions on the resulting
   yield rates are not considered. The two-stage stochastic setting is
   demonstrated by comparing with the traditional one-stage deterministic
   approach, where decisions are made based on the expected demand and
   production performance, with scrapping, reworking, and outsourcing
   decisions established before the demand and production performance are
   observed.},
Publisher = {SPRINGER},
Address = {VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS},
Type = {Article; Early Access},
Language = {English},
Affiliation = {Zhang, HD (Corresponding Author), Univ Texas Austin, Program Operat Res \& Ind Engn, 204 E Dean Keeton St, Austin, TX 78712 USA.
   Zhang, Huidong, Univ Texas Austin, Program Operat Res \& Ind Engn, 204 E Dean Keeton St, Austin, TX 78712 USA.
   Djurdjanovic, Dragan, Univ Texas Austin, Dept Mech Engn, 204 E Dean Keeton St, Austin, TX 78712 USA.},
DOI = {10.1007/s10696-021-09417-8},
EarlyAccessDate = {MAY 2021},
ISSN = {1936-6582},
EISSN = {1936-6590},
Keywords = {Integrated decision-making; Maintenance scheduling; Production planning;
   Learning of yield rate; Two-stage stochastic programming},
Keywords-Plus = {LINE EQUIPMENT CONDITION; STOCHASTIC PROGRAMS; MODEL},
Research-Areas = {Engineering; Operations Research \& Management Science},
Web-of-Science-Categories  = {Engineering, Industrial; Engineering, Manufacturing; Operations Research
   \& Management Science},
Author-Email = {huidong.zhang@utexas.edu
   dragand@me.utexas.edu},
ORCID-Numbers = {Zhang, Huidong/0000-0001-6017-0595},
Funding-Acknowledgement = {Department of Mechanical Engineering, University of Texas at Austin},
Funding-Text = {This study was funded by Department of Mechanical Engineering,
   University of Texas at Austin.},
Cited-References = {Aktekin T, 2016, NAV RES LOG, V63, P460, DOI 10.1002/nav.21716.
   Al-Turki U., 2014, INTEGRATED MAINTENAN, P5.
   Alaswad S, 2017, RELIAB ENG SYST SAFE, V157, P54, DOI 10.1016/j.ress.2016.08.009.
   Bajestani MA, 2014, INT J PROD RES, V52, P7377, DOI 10.1080/00207543.2014.931609.
   Batun S, 2012, PROD OPER MANAG, V21, P396, DOI 10.1111/j.1937-5956.2011.01250.x.
   Bearda T., 2018, HDB SILICON WAFER CL, P87, DOI {[}10.1016/B978-0-323-51084-4.00002-2, DOI 10.1016/B978-0-323-51084-4.00002-2].
   Birge JR, 2011, SPRINGER SER OPER RE, P3, DOI 10.1007/978-1-4614-0237-4.
   Celen M., 2016, THESIS U TEXAS LIB.
   Christensen R., 2011, BAYESIAN IDEAS DATA.
   Derman Cyrus, 1970, FINITE STATE MARKOVI.
   Djurdjanovic D, 2018, J MANUF SCI E-T ASME, V140, DOI 10.1115/1.4038074.
   Ekin T, 2018, RELIAB ENG SYST SAFE, V179, P52, DOI 10.1016/j.ress.2017.07.011.
   Ekin T, 2017, NAV RES LOG, V64, P613, DOI 10.1002/nav.21778.
   Ekin T, 2014, DECIS ANAL, V11, P250, DOI 10.1287/deca.2014.0303.
   Homem-de-Mello T., 2014, SURV OPER RES MANAG, V19, P56, DOI DOI 10.1016/J.SORMS.2014.05.001.
   Iravani SMR, 2002, IIE TRANS, V34, P423, DOI 10.1023/A:1013596731865.
   KHOUJA M, 1994, J OPER RES SOC, V45, P1405, DOI 10.1057/jors.1994.217.
   Lattimore T, 2020, BANDIT ALGORITHMS, P1, DOI 10.1017/9781108571401.
   Russo DJ, 2018, FOUND TRENDS MACH LE, V11, P1, DOI 10.1561/2200000070.
   Shapiro A, 2009, MOS-SIAM SER OPTIMIZ, V9, P1, DOI 10.1137/1.9780898718751.
   Sloan T, 2008, NAV RES LOG, V55, P116, DOI 10.1002/nav.20270.
   Sloan TW, 2004, J OPER RES SOC, V55, P647, DOI 10.1057/palgrave.jors.2601725.
   Sloan TW, 2002, IIE TRANS, V34, P191, DOI 10.1023/A:1011900215443.
   Sloan TW, 2000, PROD OPER MANAG, V9, P379.
   Sutton RS, 2018, ADAPT COMPUT MACH LE, P1.
   Terwiesch C, 2004, IEEE T ENG MANAGE, V51, P70, DOI 10.1109/TEM.2003.822465.
   Terwiesch C, 2001, INT J PROD ECON, V70, P1, DOI 10.1016/S0925-5273(00)00045-1.
   Thompson WR, 1933, BIOMETRIKA, V25, P285, DOI 10.2307/2332286.
   Thompson WR, 1935, AM J MATH, V57, P450, DOI 10.2307/2371219.
   Wang HZ, 2002, EUR J OPER RES, V139, P469, DOI 10.1016/S0377-2217(01)00197-7.
   YANO CA, 1995, OPER RES, V43, P311, DOI 10.1287/opre.43.2.311.},
Number-of-Cited-References = {31},
Times-Cited = {0},
Usage-Count-Last-180-days = {4},
Usage-Count-Since-2013 = {9},
Journal-ISO = {Flex. Serv. Manuf. J.},
Doc-Delivery-Number = {RY9FD},
Web-of-Science-Index = {Science Citation Index Expanded (SCI-EXPANDED)},
Unique-ID = {WOS:000648207900001},
DA = {2022-04-30},
}

@article{ WOS:000736173700001,
Author = {Lee, Young Hoon and Lee, Seunghoon},
Title = {Deep reinforcement learning based scheduling within production plan in
   semiconductor fabrication},
Journal = {EXPERT SYSTEMS WITH APPLICATIONS},
Year = {2022},
Volume = {191},
Month = {APR 1},
Abstract = {In the semiconductor industry, efficient production planning and
   scheduling decisions are required to enhance the manufacturing
   productivity of a company as the system is complicated due to a re-entry
   characteristic and requires a long production lead time. Production
   planning is implemented before scheduling and is important for
   successful manufacturing operations. However, if scheduling at the
   operation level cannot execute the production plan, failures occur
   because of inconsistent decisions. Therefore, scheduling needs to
   fulfill the production plan to ensure realistic decision-making
   processes for the companies aiming for economic growth and global
   competitiveness. In this study, deep reinforcement learning (RL) is
   employed to deal with a scheduling process operating within the
   production plan. As the algorithm of the deep RL, Deep Q-network is
   conjugated, and a novel state, action, and reward are suggested to
   optimize the scheduling policy. As a result, the performance of the
   proposed deep RL method is in comparison with other dispatching rules,
   and the proposed method outperforms the other scheduling methods in
   diverse cases.},
Publisher = {PERGAMON-ELSEVIER SCIENCE LTD},
Address = {THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND},
Type = {Article},
Language = {English},
Affiliation = {Lee, S (Corresponding Author), Yonsei Univ, Dept Ind Engn, 50 Yonsei Ro, Seoul 03722, South Korea.
   Lee, Young Hoon; Lee, Seunghoon, Yonsei Univ, Dept Ind Engn, 50 Yonsei Ro, Seoul 03722, South Korea.},
DOI = {10.1016/j.eswa.2021.116222},
EarlyAccessDate = {DEC 2021},
Article-Number = {116222},
ISSN = {0957-4174},
EISSN = {1873-6793},
Keywords = {Deep reinforcement learning; Production planning; Scheduling;
   Semiconductor fabrication; Intelligent manufacturing},
Keywords-Plus = {INDUSTRY 4.0; OPTIMIZATION},
Research-Areas = {Computer Science; Engineering; Operations Research \& Management Science},
Web-of-Science-Categories  = {Computer Science, Artificial Intelligence; Engineering, Electrical \&
   Electronic; Operations Research \& Management Science},
Author-Email = {shbrandonlee@yonsei.ac.kr},
Cited-References = {Atallah R, 2017, 2017 15TH INTERNATIONAL SYMPOSIUM ON MODELING AND OPTIMIZATION IN MOBILE, AD HOC, AND WIRELESS NETWORKS (WIOPT).
   Bergstra J, 2012, J MACH LEARN RES, V13, P281.
   Chen JC, 2004, INT J PROD RES, V42, P4547, DOI 10.1080/00207540410001721736.
   CONNORS D, 1994, IEEE T ROBOTIC AUTOM, V10, P88, DOI 10.1109/70.282534.
   Dabbas RM, 2003, IEEE T SEMICONDUCT M, V16, P501, DOI 10.1109/TSM.2003.815201.
   Demirkol E, 1997, COMPUT IND ENG, V33, P261, DOI 10.1016/S0360-8352(97)00088-0.
   Guo CT, 2012, COMPUT IND ENG, V62, P141, DOI 10.1016/j.cie.2011.09.002.
   Hubbs CD, 2020, COMPUT CHEM ENG, V141, DOI 10.1016/j.compchemeng.2020.106982.
   Hung-We Wen, 2001, Proceedings 2001 ICRA. IEEE International Conference on Robotics and Automation (Cat. No.01CH37164), P3559, DOI 10.1109/ROBOT.2001.933169.
   Jain V, 2003, INT J PROD RES, V41, P3501, DOI 10.1080/0020754031000118152.
   Kaskavelis CA, 1998, IIE TRANS, V30, P1085.
   Kim SH, 2016, COMPUT IND ENG, V96, P72, DOI 10.1016/j.cie.2016.03.019.
   Kim YD, 1998, J MANUF SYST, V17, P107.
   Kumar S, 2001, IEEE T ROBOTIC AUTOM, V17, P548, DOI 10.1109/70.964657.
   Lang S, 2020, WINT SIMUL C PROC, P3057, DOI 10.1109/WSC48552.2020.9383997.
   Lee S, 2020, SUSTAINABILITY-BASEL, V12, DOI 10.3390/su12208718.
   Lee S, 2020, HEALTHCARE-BASEL, V8, DOI 10.3390/healthcare8020077.
   Lee YH, 2011, INT J ADV MANUF TECH, V54, P323, DOI 10.1007/s00170-010-2934-6.
   Li L, 2012, INT J MODEL IDENTIF, V15, P259, DOI 10.1504/IJMIC.2012.046404.
   Liao DY, 1996, IEEE T SEMICONDUCT M, V9, P550, DOI 10.1109/66.542170.
   LU SCH, 1994, IEEE T SEMICONDUCT M, V7, P374, DOI 10.1109/66.311341.
   Luo S, 2020, APPL SOFT COMPUT, V91, DOI 10.1016/j.asoc.2020.106208.
   Mnih V, 2015, NATURE, V518, P529, DOI 10.1038/nature14236.
   Park IB, 2020, IEEE T AUTOM SCI ENG, V17, P1420, DOI 10.1109/TASE.2019.2956762.
   Pinedo ML, 2012, SCHEDULING: THEORY, ALGORITHMS, AND SYSTEMS, FOURTH EDITION, P1, DOI 10.1007/978-1-4614-2361-4.
   Qiao F, 2013, IEEE T AUTOM SCI ENG, V10, P197, DOI 10.1109/TASE.2012.2204049.
   Shi DM, 2020, INT J PROD RES, V58, P3362, DOI 10.1080/00207543.2020.1717008.
   Sourirajan K, 2007, J SCHEDULING, V10, P41, DOI 10.1007/s10951-006-0325-5.
   Stricker N, 2018, CIRP ANN-MANUF TECHN, V67, P511, DOI 10.1016/j.cirp.2018.04.041.
   Sung CS, 2000, EUR J OPER RES, V120, P559, DOI 10.1016/S0377-2217(98)00391-9.
   Tao F, 2019, ENGINEERING-PRC, V5, P653, DOI 10.1016/j.eng.2019.01.014.
   Tao F, 2018, J MANUF SYST, V48, P157, DOI 10.1016/j.jmsy.2018.01.006.
   Tsai C.-H., 2003, INT J COMPUTER, V11, P64.
   Wang JJ, 2018, J MANUF SYST, V48, P144, DOI 10.1016/j.jmsy.2018.01.003.
   Waschneck B, 2018, PROC CIRP, V72, P1264, DOI 10.1016/j.procir.2018.03.212.
   Waschneck B, 2018, ASMC PROC, P301, DOI 10.1109/ASMC.2018.8373191.
   Watkins C, 1989, LEARNING DELAYED REW.
   WEIN LM, 1988, IEEE T SEMICONDUCT M, V1, P115, DOI 10.1109/66.4384.
   Zhang J, 2019, J INTELL MANUF, V30, P1809, DOI 10.1007/s10845-017-1350-2.
   Zhong RY, 2017, ENGINEERING-PRC, V3, P616, DOI 10.1016/J.ENG.2017.05.015.},
Number-of-Cited-References = {40},
Times-Cited = {0},
Usage-Count-Last-180-days = {30},
Usage-Count-Since-2013 = {30},
Journal-ISO = {Expert Syst. Appl.},
Doc-Delivery-Number = {XX3AS},
Web-of-Science-Index = {Science Citation Index Expanded (SCI-EXPANDED)},
Unique-ID = {WOS:000736173700001},
DA = {2022-04-30},
}

@inproceedings{ WOS:000774441800053,
Author = {Kerkkamp, David and Bukhsh, Zaharah A. and Zhang, Yingqian and Jansen,
   Nils},
Editor = {Rocha, AP and Steels, L and VandenHerik, J},
Title = {Grouping of Maintenance Actions with Deep Reinforcement Learning and
   Graph Convolutional Networks},
Booktitle = {ICAART: PROCEEDINGS OF THE 14TH INTERNATIONAL CONFERENCE ON AGENTS AND
   ARTIFICIAL INTELLIGENCE - VOL 2},
Series = {ICAART},
Year = {2022},
Pages = {574-585},
Note = {14th International Conference on Agents and Artificial Intelligence
   (ICAART), ELECTR NETWORK, FEB 03-05, 2022},
Abstract = {Reinforcement learning (RL) has shown promising performance in several
   applications such as robotics and games. However, the use of RL in
   emerging real-world domains such as smart industry and asset management
   remains scarce. This paper addresses the problem of optimal maintenance
   planning using historical data. We propose a novel Deep RL (DRL)
   framework based on Graph Convolutional Networks (GCN) to leverage the
   inherent graph structure of typical assets. As demonstrator, we employ
   an underground sewer pipe network. In particular, instead of dispersed
   maintenance actions of individual pipes across the network, the GCN
   ensures the grouping of maintenance actions of geographically close
   pipes. We perform experiments using the distinct physical
   characteristics, deterioration profiles, and historical data of sewer
   inspections within an urban environment. The results show that combining
   Deep Q-Networks (DQN) with GCN leads to structurally more reliable
   networks and a higher degree of maintenance grouping, compared to DQN
   with fully-connected layers and standard preventive and corrective
   maintenance strategy that are often adopted in practice. Our approach
   shows potential for developing efficient and practical maintenance plans
   in terms of cost and reliability.},
Publisher = {SCITEPRESS},
Address = {AV D MANUELL, 27A 2 ESQ, SETUBAL, 2910-595, PORTUGAL},
Type = {Proceedings Paper},
Language = {English},
Affiliation = {Kerkkamp, D (Corresponding Author), Radboud Univ Nijmegen, Nijmegen, Netherlands.
   Kerkkamp, David; Jansen, Nils, Radboud Univ Nijmegen, Nijmegen, Netherlands.
   Bukhsh, Zaharah A.; Zhang, Yingqian, Eindhoven Univ Technol, Eindhoven, Netherlands.},
DOI = {10.5220/0010907500003116},
ISSN = {2184-433X},
ISBN = {978-989-758-547-0},
Keywords = {Maintenance Planning; Deep Reinforcement Learning; Graph Neural
   Networks; Sewer Asset Management},
Keywords-Plus = {RENEWAL; SYSTEMS},
Research-Areas = {Computer Science},
Web-of-Science-Categories  = {Computer Science, Artificial Intelligence; Computer Science,
   Interdisciplinary Applications; Computer Science, Software Engineering;
   Computer Science, Theory \& Methods},
Funding-Acknowledgement = {NWONetherlands Organization for Scientific Research (NWO) {[}PrimaVera
   NWA.1160.18.238]},
Funding-Text = {This research has been partially funded by NWO under the grant PrimaVera
   NWA.1160.18.238.},
Cited-References = {Ahmad R, 2012, COMPUT IND ENG, V63, P135, DOI 10.1016/j.cie.2012.02.002.
   Almasan P., 2020, ARXIV191007421CS.
   Battaglia Peter W., 2018, ARXIV180601261.
   Birolini A., 2013, RELIABILITY ENG THEO.
   Chen YF, 2017, IEEE INT C INT ROBOT, P1343, DOI 10.1109/IROS.2017.8202312.
   da Costa P. R. de O., 2020, ARXIV200401608.
   Dai H., 2018, LEARNING COMBINATORI.
   Fey M., 2019, ICLR WORKSH REPR LEA.
   Fontecha JE, 2021, RISK ANAL, V41, P2356, DOI 10.1111/risa.13742.
   Garg S., 2019, P INT C AUT PLANN SC, V29, P631.
   Hansen BD, 2019, 2019 IEEE SYMPOSIUM SERIES ON COMPUTATIONAL INTELLIGENCE (IEEE SSCI 2019), P834, DOI 10.1109/SSCI44817.2019.9002727.
   Hu L, 2020, J MANUF SYST, V55, P1, DOI 10.1016/j.jmsy.2020.02.004.
   Janisch J., 2021, ARXIV200912462CS.
   Joshi C. K., 2019, EFFICIENT GRAPH CONV.
   Kaelbling LP, 1996, J ARTIF INTELL RES, V4, P237, DOI 10.1613/jair.301.
   Kipf Thomas N, 2017, P 5 INT C LEARN REPR.
   Li FF, 2011, 2011 INTERNATIONAL CONFERENCE ON QUALITY, RELIABILITY, RISK, MAINTENANCE, AND SAFETY ENGINEERING (ICQR2MSE), P601.
   Li YH, 2017, PROCEEDINGS OF THE TWENTY-SIXTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P2230.
   Luong NC, 2019, IEEE COMMUN SURV TUT, V21, P3133, DOI 10.1109/COMST.2019.2916583.
   Mnih V., 2013, ARXIV.
   Mnih V, 2016, PR MACH LEARN RES, V48.
   Pargar F, 2017, COMPUT IND ENG, V110, P43, DOI 10.1016/j.cie.2017.05.024.
   Petit-Boix A, 2016, WATER RESOUR MANAG, V30, P1117, DOI 10.1007/s11269-015-1214-5.
   Prates M, 2019, THIRTY-THIRD AAAI CONFERENCE ON ARTIFICIAL INTELLIGENCE / THIRTY-FIRST INNOVATIVE APPLICATIONS OF ARTIFICIAL INTELLIGENCE CONFERENCE / NINTH AAAI SYMPOSIUM ON EDUCATIONAL ADVANCES IN ARTIFICIAL INTELLIGENCE, P4731.
   Puterman M.L., 2005, MARKOV DECISION PROC, DOI DOI 10.1002/9780470316887.
   Rokstad MM, 2015, RELIAB ENG SYST SAFE, V142, P148, DOI 10.1016/j.ress.2015.05.014.
   Scheidegger A, 2011, WATER RES, V45, P4983, DOI 10.1016/j.watres.2011.07.008.
   Sun PH, 2021, IEEE COMMUN LETT, V25, P176, DOI 10.1109/LCOMM.2020.3025298.
   Sutton RS, 2000, ADV NEUR IN, V12, P1057.
   TESAURO G, 1995, COMMUN ACM, V38, P58, DOI 10.1145/203330.203343.
   Tscheikner-Gratl F, 2019, URBAN WATER J, V16, P662, DOI 10.1080/1573062X.2020.1713382.
   van Hasselt H, 2016, THIRTIETH AAAI CONFERENCE ON ARTIFICIAL INTELLIGENCE, P2094.
   Velickovi P., 2018, GRAPH ATTENTION NETW.
   WATKINS CJCH, 1992, MACH LEARN, V8, P279, DOI 10.1007/bf00992698.
   Weeraddana D., 2020, UTILIZING MACHINE LE.
   Yan ZX, 2020, IEEE J SEL AREA COMM, V38, P1040, DOI 10.1109/JSAC.2020.2986662.
   Yin XF, 2020, AUTOMAT CONSTR, V116, DOI 10.1016/j.autcon.2020.103181.},
Number-of-Cited-References = {37},
Times-Cited = {0},
Usage-Count-Last-180-days = {1},
Usage-Count-Since-2013 = {1},
Doc-Delivery-Number = {BS8ON},
Web-of-Science-Index = {Conference Proceedings Citation Index - Science (CPCI-S)},
Unique-ID = {WOS:000774441800053},
OA = {hybrid},
DA = {2022-04-30},
}

@inproceedings{ WOS:000471253000068,
Author = {Kuhnle, Andreas and Roehrig, Nicole and Lanza, Gisela},
Editor = {Teti, R and DAddona, DM},
Title = {Autonomous order dispatching in the semiconductor industry using
   reinforcement learning},
Booktitle = {12TH CIRP CONFERENCE ON INTELLIGENT COMPUTATION IN MANUFACTURING
   ENGINEERING},
Series = {Procedia CIRP},
Year = {2019},
Volume = {79},
Pages = {391-396},
Note = {12th CIRP Conference on Intelligent Computation in Manufacturing
   Engineering (CIRP ICME), Naples, ITALY, JUL 18-20, 2018},
Organization = {Int Acad Prod Engn; Fraunhofer Joint Lab Excellence Adv Prod Technol;
   CIRP},
Abstract = {Cyber Physical Production Systems (CPPS) provide a huge amount of data.
   Simultaneously, operational decisions are getting ever more complex due
   to smaller batch sizes, a larger product variety and complex processes
   in production systems. Production engineers struggle to utilize the
   recorded data to optimize production processes effectively because of a
   rising level of complexity. This paper shows the successful
   implementation of an autonomous order dispatching system that is based
   on a Reinforcement Learning (RL) algorithm. The real-world use case in
   the semiconductor industry is a highly suitable example of a cyber
   physical and digitized production system. (C) 2019 The Authors.
   Published by Elsevier B. V.},
Publisher = {ELSEVIER SCIENCE BV},
Address = {SARA BURGERHARTSTRAAT 25, PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS},
Type = {Proceedings Paper},
Language = {English},
Affiliation = {Kuhnle, A (Corresponding Author), Karlsruhe Inst Technol, Wbk Inst Prod Sci, Kaiserstr 12, D-76137 Karlsruhe, Germany.
   Kuhnle, Andreas; Roehrig, Nicole; Lanza, Gisela, Karlsruhe Inst Technol, Wbk Inst Prod Sci, Kaiserstr 12, D-76137 Karlsruhe, Germany.},
DOI = {10.1016/j.procir.2019.02.101},
ISSN = {2212-8271},
Keywords = {Production planning; Reinforcement learning; Semiconductor industry},
Research-Areas = {Computer Science; Engineering},
Web-of-Science-Categories  = {Computer Science, Artificial Intelligence; Engineering, Manufacturing},
Author-Email = {andreas.kuhnle@kit.edu},
Funding-Acknowledgement = {German Federal Ministry of Education and Research (BMBF)Federal Ministry
   of Education \& Research (BMBF) {[}02P14B161]},
Funding-Text = {We extend our sincere thanks to the German Federal Ministry of Education
   and Research (BMBF) for supporting this research project 02P14B161
   ``Empowerment and Implementation Strategies for Industry 4.0{''}.},
Cited-References = {Csaji BC, 2006, ADV ENG INFORM, V20, P279, DOI 10.1016/j.aei.2006.01.001.
   Gunther J, 2016, MECHATRONICS, V34, P1, DOI 10.1016/j.mechatronics.2015.09.004.
   Kormushev P, 2010, IEEE INT C INT ROBOT, P3232, DOI 10.1109/IROS.2010.5649089.
   Lawler E. L., 1993, HDB OPERATIONS RES M, V4, P445.
   Luckhurst M, 2005, THEATRE AND CELEBRITY IN BRITAIN 1660-2000, P1.
   Mnih V., 2013, PROC 27 C NEURAL INF, P1.
   Monch L., 2013, PRODUCTION PLANNING.
   Monostori L, 2006, CIRP ANN-MANUF TECHN, V55, P697, DOI 10.1016/j.cirp.2006.10.004.
   Monostori L, 2004, CIRP ANN-MANUF TECHN, V53, P349, DOI 10.1016/S0007-8506(07)60714-8.
   Russel S.J., 2016, ARTIFICIAL INTELLIGE.
   Schulman J., 2017, 170706347 ARXIV.
   Schulman J, 2015, PR MACH LEARN RES, V37, P1889.
   Stegherr F., 2000, REINFORCEMENT LEARNI.
   Sutton R. S., 1998, REINFORCEMENT LEARNI.
   Thomas Philip, 2009, Proc Innov Appl Artif Intell Conf, V2009, P165.
   Wang YC, 2005, ENG APPL ARTIF INTEL, V18, P73, DOI 10.1016/j.engappai.2004.08.018.
   Waschneck B, 2016, CEUR WORKSHOP P, V1793, P12.},
Number-of-Cited-References = {17},
Times-Cited = {11},
Usage-Count-Last-180-days = {4},
Usage-Count-Since-2013 = {5},
Doc-Delivery-Number = {BM9RA},
Web-of-Science-Index = {Conference Proceedings Citation Index - Science (CPCI-S)},
Unique-ID = {WOS:000471253000068},
OA = {gold},
DA = {2022-04-30},
}

@article{ WOS:000672478100019,
Author = {Woo, Jong Hun and Kim, Byeongseop and Ju, SuHeon and Cho, Young In},
Title = {Automation of load balancing for Gantt planning using reinforcement
   learning},
Journal = {ENGINEERING APPLICATIONS OF ARTIFICIAL INTELLIGENCE},
Year = {2021},
Volume = {101},
Month = {MAY},
Abstract = {Typically, in the shipbuilding industry, several vessels are built
   concurrently, and a production plan is established through a
   hierarchical planning process. This process largely comprises strategic
   planning (long-term) and master planning (mid-term) aspects. The portion
   that requires the most manual work of the planner is the load balancing
   in the master planning stage. The load balancing of master planning is
   an area where optimization studies using mixed integer programming,
   genetic algorithms, tabu search algorithms, and others have been
   actively conducted in the field of operational research. However, its
   practical application has not been successful due to the complexity and
   the curse of dimensionality, which is dependent on the manual work of
   the planner. Therefore, a new method that can facilitate the efficient
   action of optimal decisions is required, replacing conventional
   production planning methods based on the manual work of the planner.
   With the advent of the 4th industrial revolution in recent years,
   machine learning technology based on deep neural networks has been
   rapidly developing and applied to a wide range of engineering problems.
   This study introduces a methodology that can quickly improve the load
   balancing problem in shipyard master planning by using a deep neural
   network-based reinforcement learning algorithm among various machine
   learning techniques. Furthermore, we aim to verify the feasibility of
   the developed methodology using the ship block production data of an
   actual shipyard.},
Publisher = {PERGAMON-ELSEVIER SCIENCE LTD},
Address = {THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND},
Type = {Article},
Language = {English},
Affiliation = {Cho, YI (Corresponding Author), Seoul Natl Univ, Dept Naval Architecture \& Ocean Engn, Seoul, South Korea.
   Woo, Jong Hun; Kim, Byeongseop; Ju, SuHeon; Cho, Young In, Seoul Natl Univ, Dept Naval Architecture \& Ocean Engn, Seoul, South Korea.},
DOI = {10.1016/j.engappai.2021.104226},
EarlyAccessDate = {MAR 2021},
Article-Number = {104226},
ISSN = {0952-1976},
EISSN = {1873-6769},
Keywords = {Shipbuilding; Production planning; Workload balancing; Reinforcement
   learning; Deep neural networks},
Research-Areas = {Automation \& Control Systems; Computer Science; Engineering},
Web-of-Science-Categories  = {Automation \& Control Systems; Computer Science, Artificial
   Intelligence; Engineering, Multidisciplinary; Engineering, Electrical \&
   Electronic},
Author-Email = {j.woo@snu.ac.kr
   jjolla93@snu.ac.kr
   wntngjs@snu.ac.kr
   whduddlsi@snu.ac.kr},
ORCID-Numbers = {Kim, Byeongseop/0000-0001-6842-5046},
Funding-Acknowledgement = {IoT and AI-based development of Digital Twin for Block Assembly Process
   of the Korean Ministry of Trade, Industry and Energy {[}20006978]},
Funding-Text = {This research was supported by following research projects: (1) IoT and
   AI-based development of Digital Twin for Block Assembly Process
   (20006978) of the Korean Ministry of Trade, Industry and Energy.},
Cited-References = {BAE HEECHUL, 2007, {[}Industrial Engineers Interfaces, 산업공학(IE interfaces)], V20, P33.
   Basan NP, 2017, WINT SIMUL C PROC, P3218, DOI 10.1109/WSC.2017.8248040.
   Cho KK, 1998, CIRP ANNALS 1998 - MANUFACTURING TECHNOLOGY, VOL 47, NO 1, V47, P419.
   Clark Wallace., 1922, GANTT CHART WORKING.
   Dong-seon Shin, 2020, {[}Journal of the Society of Naval Architects of Korea, 대한조선학회 논문집], V57, P191, DOI 10.3744/SNAK.2020.57.4.191.
   Hameed Mohammed Sharafath Abdul, 2020, ARXIV200903836.
   Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527.
   Hu SC, 2019, J OPER RES SOC, V70, P1349, DOI 10.1080/01605682.2018.1489340.
   Jae Kyu Lee, 1994, International Journal of Intelligent Systems in Accounting, Finance and Management, V3, P111.
   Jeong JH, 2020, INT J NAV ARCH OCEAN, V12, P428, DOI 10.1016/j.ijnaoe.2020.03.005.
   Joon Shin Hyun, 2010, {[}Journal of Korea Academia-Industrial cooperation Society, 한국산학기술학회논문지], V11, P4174.
   Kim B, 2020, INT J PROD RES, V58, P5062, DOI 10.1080/00207543.2020.1748247.
   Konig M., 2007, P 6 EUROSIM C MOD SI P 6 EUROSIM C MOD SI.
   Kwon B, 2015, COMPUT IND ENG, V89, P203, DOI 10.1016/j.cie.2015.04.036.
   황인혁, 2010, {[}JOURNAL OF THE KOREA SOCIETY FOR SIMULATION, 한국시뮬레이션학회 논문지], V19, P73.
   Lee Soonsup, 2014, {[}Journal of Ocean Engineering and Technology, 한국해양공학회지], V28, P533.
   Lee WJ, 2019, WINT SIMUL C PROC, P2236, DOI 10.1109/WSC40007.2019.9004886.
   Lee Y.G., 2020, IEEE ACCESS, P1, DOI 10.1007/978-981-15-1293-3\_1.
   Liu Z, 2011, INT J PROD RES, V49, P6249, DOI 10.1080/00207543.2010.527388.
   Mnih V., 2013, PROC 27 C NEURAL INF, P1.
   Mnih Volodymyr, 2016, INT C MACH LEARN, P1928, DOI DOI 10.5555/3045390.3045594.
   Romero-Hdz J, 2020, ENG APPL ARTIF INTEL, V91, DOI 10.1016/j.engappai.2020.103612.
   Rose CD, 2015, INT J PROD RES, V53, P5782, DOI 10.1080/00207543.2014.998786.
   Shang ZY, 2017, MATH PROBL ENG, V2017, DOI 10.1155/2017/1923646.
   Shi DM, 2020, INT J PROD RES, V58, P3362, DOI 10.1080/00207543.2020.1717008.
   Woo S.B., 2003, J KOREAN I IND ENG, V16, P332.
   Zhuo L, 2012, INT J PROD RES, V50, P5986, DOI 10.1080/00207543.2011.639816.},
Number-of-Cited-References = {27},
Times-Cited = {2},
Usage-Count-Last-180-days = {2},
Usage-Count-Since-2013 = {4},
Journal-ISO = {Eng. Appl. Artif. Intell.},
Doc-Delivery-Number = {TI0NH},
Web-of-Science-Index = {Science Citation Index Expanded (SCI-EXPANDED)},
Unique-ID = {WOS:000672478100019},
OA = {hybrid},
DA = {2022-04-30},
}

@article{ WOS:000303281800024,
Author = {Shin, Moonsoo and Ryu, Kwangyeol and Jung, Mooyoung},
Title = {Reinforcement learning approach to goal-regulation in a
   self-evolutionary manufacturing system},
Journal = {EXPERT SYSTEMS WITH APPLICATIONS},
Year = {2012},
Volume = {39},
Number = {10},
Pages = {8736-8743},
Month = {AUG},
Abstract = {Up-to-date market dynamics has been forcing manufacturing systems to
   adapt quickly and continuously to the ever-changing environment.
   Self-evolution of manufacturing systems means a continuous process of
   adapting to the environment on the basis of autonomous goal-formation
   and goal-oriented dynamic organization. This paper proposes a
   goal-regulation mechanism that applies a reinforcement learning
   approach, which is a principal working mechanism for autonomous
   goal-formation. Individual goals are regulated by a neural network-based
   fuzzy inference system, namely, a goal-regulation network (GRN) updated
   by a reinforcement signal from another neural network called
   goal-evaluation network (GEN). The GEN approximates the compatibility of
   goals with current environmental situation. In this paper, a production
   planning problem is also examined by a simulation study in order to
   validate the proposed goal regulation mechanism. (c) 2012 Elsevier Ltd.
   All rights reserved.},
Publisher = {PERGAMON-ELSEVIER SCIENCE LTD},
Address = {THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND},
Type = {Article},
Language = {English},
Affiliation = {Jung, M (Corresponding Author), Ulsan Natl Inst Sci \& Technol UNIST, Sch Technol Management, Banyeon Ri 100, Ulsan 689798, South Korea.
   Jung, Mooyoung, Ulsan Natl Inst Sci \& Technol UNIST, Sch Technol Management, Ulsan 689798, South Korea.
   Shin, Moonsoo, Hanbat Natl Univ, Dept Ind \& Management Engn, Taejon 305719, South Korea.
   Ryu, Kwangyeol, Pusan Natl Univ, Dept Ind Engn, Pusan 690735, South Korea.},
DOI = {10.1016/j.eswa.2012.01.207},
ISSN = {0957-4174},
Keywords = {Self-evolutionary manufacturing system; Fractal organization;
   Goal-regulation; Reinforcement learning; Agent; Production planning},
Keywords-Plus = {AGENT-BASED ARCHITECTURE; FRACTAL ORGANIZATION; METAMORPH; FRAMEWORK;
   POLICIES},
Research-Areas = {Computer Science; Engineering; Operations Research \& Management Science},
Web-of-Science-Categories  = {Computer Science, Artificial Intelligence; Engineering, Electrical \&
   Electronic; Operations Research \& Management Science},
Author-Email = {myjung@unist.ac.kr},
ResearcherID-Numbers = {Shin, Moonsoo/Q-6513-2016
   Jung, Mooyoung/E-6404-2010
   },
ORCID-Numbers = {Shin, Moonsoo/0000-0001-6318-9662
   RYU, Kwangyeol/0000-0003-0892-5684},
Funding-Acknowledgement = {National Research Foundation of Korea (NRF)National Research Foundation
   of Korea; Ministry of Education, Science, and TechnologyMinistry of
   Education, Science and Technology, Republic of Korea {[}2009-0077660]},
Funding-Text = {This research was supported by the Basic Science Research Program
   through the National Research Foundation of Korea (NRF) funded by the
   Ministry of Education, Science, and Technology (2009-0077660). The
   authors would like to express their gratitude for the support.},
Cited-References = {Anderson C. W., 1986, THESIS U MASS.
   Arredondo F, 2010, COMPUT IND ENG, V58, P70, DOI 10.1016/j.cie.2009.08.005.
   BARTO AG, 1983, IEEE T SYST MAN CYB, V13, P834, DOI 10.1109/TSMC.1983.6313077.
   Bellman R., 1957, DYNAMIC PROGRAMMING.
   Berenji H. R., 1992, International Journal of Approximate Reasoning, V6, P267, DOI 10.1016/0888-613X(92)90020-Z.
   BERENJI HR, 1992, IEEE T NEURAL NETWOR, V3, P724, DOI 10.1109/72.159061.
   Csaji BC, 2006, ADV ENG INFORM, V20, P279, DOI 10.1016/j.aei.2006.01.001.
   Frayret JM, 2004, PROD PLAN CONTROL, V15, P42, DOI 10.1080/09537280410001658344.
   Heragu SS, 2002, IEEE T SYST MAN CY A, V32, P560, DOI 10.1109/TSMCA.2002.804788.
   Jouffe L, 1998, IEEE T SYST MAN CY C, V28, P338, DOI 10.1109/5326.704563.
   Leitao P, 2006, COMPUT IND, V57, P121, DOI 10.1016/j.compind.2005.05.005.
   Liu M, 2011, EXPERT SYST APPL, V38, P9248, DOI 10.1016/j.eswa.2011.01.136.
   Mandelbrot B.B., 1982, FRACTAL GEOMETRY NAT.
   Maturana F, 1999, INT J PROD RES, V37, P2159, DOI 10.1080/002075499190699.
   MIZUTANI E, 1997, NEUROFUZZY SOFT COMP, P258.
   Rau H, 2009, EXPERT SYST APPL, V36, P11287, DOI 10.1016/j.eswa.2009.03.020.
   Renna P, 2011, INT J ADV MANUF TECH, V56, P1235, DOI 10.1007/s00170-011-3255-0.
   RUMELHART DE, 1986, NATURE, V323, P533, DOI 10.1038/323533a0.
   Ryu K, 2006, INT J PROD RES, V44, P3105, DOI 10.1080/00207540500465659.
   Ryu K, 2004, INT J PROD RES, V42, P2207, DOI 10.1080/00207540410001661427.
   Shen WM, 2000, J INTELL MANUF, V11, P237, DOI 10.1023/A:1008915208259.
   Shin M, 2006, INT J PROD RES, V44, P447, DOI 10.1080/00207540500142845.
   Shin M, 2009, INT J PROD RES, V47, P1791, DOI 10.1080/00207540802036240.
   Shin M, 2009, COMPUT IND ENG, V56, P1029, DOI 10.1016/j.cie.2008.09.014.
   Sutton R.S., 1984, TEMPORAL CREDIT ASSI.
   Sutton R. S., 1998, REINFORCEMENT LEARNI.
   Tan AH, 2011, EXPERT SYST APPL, V38, P8477, DOI 10.1016/j.eswa.2011.01.045.
   Van Brussel H, 1998, COMPUT IND, V37, P255, DOI 10.1016/S0166-3615(98)00102-X.
   Wang YC, 2004, ROBOT CIM-INT MANUF, V20, P553, DOI {[}10.1016/j.rcim.2004.07.003, 10.1016/j.rcim.2004.07.033].
   Wang YC, 2007, INT J ADV MANUF TECH, V33, P323, DOI 10.1007/s00170-006-0465-y.
   Weiss G., 1999, MULTIAGENT SYSTEMS M.
   Zhang ZC, 2007, INT J ADV MANUF TECH, V34, P968, DOI 10.1007/s00170-006-0662-8.},
Number-of-Cited-References = {32},
Times-Cited = {20},
Usage-Count-Last-180-days = {2},
Usage-Count-Since-2013 = {28},
Journal-ISO = {Expert Syst. Appl.},
Doc-Delivery-Number = {932HR},
Web-of-Science-Index = {Science Citation Index Expanded (SCI-EXPANDED)},
Unique-ID = {WOS:000303281800024},
DA = {2022-04-30},
}

@article{ WOS:000535227500001,
Author = {Yao, Linyi and Dong, Qiao and Jiang, Jiwang and Ni, Fujian},
Title = {Deep reinforcement learning for long-term pavement maintenance planning},
Journal = {COMPUTER-AIDED CIVIL AND INFRASTRUCTURE ENGINEERING},
Year = {2020},
Volume = {35},
Number = {11, SI},
Pages = {1230-1245},
Month = {NOV},
Abstract = {Inappropriate maintenance and rehabilitation strategies cause many
   problems such as maintenance budget waste, ineffective pavement distress
   treatments, and so forth. A method based on a machine learning algorithm
   called deep reinforcement learning (DRL) was developed in this presented
   research in order to learn better maintenance strategies that maximize
   the long-term cost-effectiveness in maintenance decision-making through
   trial and error. In this method, each single-lane pavement segment can
   have different treatments, and the long-term maintenance
   cost-effectiveness of the entire section is treated as the optimization
   goal. In the DRL algorithm, states are embodied by 42 parameters
   involving the pavement structures and materials, traffic loads,
   maintenance records, pavement conditions, and so forth. Specific
   treatments as well as do-nothing are the actions. The reward is defined
   as the increased or decreased cost-effectiveness after taking
   corresponding actions. Two expressways, the Ningchang and Zhenli
   expressways, were selected for a case study. The results show that the
   DRL model is capable of learning a better strategy to improve the
   long-term maintenance cost-effectiveness. By implementing the optimized
   maintenance strategies produced by the developed model, the pavement
   conditions can be controlled in an acceptable range.},
Publisher = {WILEY},
Address = {111 RIVER ST, HOBOKEN 07030-5774, NJ USA},
Type = {Article},
Language = {English},
Affiliation = {Dong, Q (Corresponding Author), Southeast Univ, Coll Transportat, Dept Highway \& Railway Engn, 2 Sipailou, Nanjing 210096, Jiangsu, Peoples R China.
   Yao, Linyi; Dong, Qiao; Jiang, Jiwang; Ni, Fujian, Southeast Univ, Coll Transportat, Dept Highway \& Railway Engn, 2 Sipailou, Nanjing 210096, Jiangsu, Peoples R China.},
DOI = {10.1111/mice.12558},
EarlyAccessDate = {MAY 2020},
ISSN = {1093-9687},
EISSN = {1467-8667},
Keywords-Plus = {NEURAL DYNAMIC CLASSIFICATION; MULTIOBJECTIVE OPTIMIZATION; REPAIR
   POLICIES; REHABILITATION; PREDICTION; NETWORK; MODEL; FRAMEWORK;
   STRATEGY; GAME},
Research-Areas = {Computer Science; Construction \& Building Technology; Engineering;
   Transportation},
Web-of-Science-Categories  = {Computer Science, Interdisciplinary Applications; Construction \&
   Building Technology; Engineering, Civil; Transportation Science \&
   Technology},
Author-Email = {qiaodong@seu.edu.cn},
ResearcherID-Numbers = {Jiang, Jiwang/AAI-7615-2021
   Dong, Qiao/G-5087-2012
   },
ORCID-Numbers = {Dong, Qiao/0000-0001-7461-9226
   Jiang, Jiwang/0000-0001-8354-4617},
Cited-References = {Adeli H, 2001, COMPUT-AIDED CIV INF, V16, P126, DOI 10.1111/0885-9507.00219.
   Adeli H., 1994, MACHINE LEARNING NEU.
   Aslani M, 2018, CAN J CIVIL ENG, V45, P690, DOI 10.1139/cjce-2017-0408.
   Augeri MG, 2019, EUR TRANSP RES REV, V11, DOI 10.1186/s12544-019-0353-9.
   Azevedo CRB, 2016, IEEE T CYBERNETICS, V46, P778, DOI 10.1109/TCYB.2015.2415732.
   BELLMAN R, 1966, SCIENCE, V153, P34, DOI 10.1126/science.153.3731.34.
   Boyles SD, 2010, J INFRASTRUCT SYST, V16, P11, DOI 10.1061/(ASCE)1076-0342(2010)16:1(11).
   Cha YJ, 2017, COMPUT-AIDED CIV INF, V32, P361, DOI 10.1111/mice.12263.
   Chen K., 2015, DEEP REINFORCEMENT L.
   Choi JH, 2019, J CLEAN PROD, V209, P88, DOI 10.1016/j.jclepro.2018.10.226.
   Dong Q, 2013, J TRANSP ENG, V139, P797, DOI 10.1061/(ASCE)TE.1943-5436.0000556.
   Dong Q, 2012, J TRANSP ENG, V138, P681, DOI 10.1061/(ASCE)TE.1943-5436.0000378.
   Ernst D, 2005, J MACH LEARN RES, V6, P503.
   France-Mensah J, 2018, J MANAGE ENG, V34, DOI 10.1061/(ASCE)ME.1943-5479.0000599.
   FRIESZ TL, 1979, TRANSPORT RES B-METH, V13, P317, DOI 10.1016/0191-2615(79)90025-0.
   Fwa TF, 2000, J TRANSP ENG-ASCE, V126, P367, DOI 10.1061/(ASCE)0733-947X(2000)126:5(367).
   Galehouse L., 2003, PRINCIPLES PAVEMENT.
   Gao L, 2013, TRANSPORT RES REC, P59, DOI 10.3141/2366-07.
   Gao L, 2011, TRANSPORT RES REC, P109, DOI 10.3141/2225-12.
   Gao YQ, 2018, COMPUT-AIDED CIV INF, V33, P748, DOI 10.1111/mice.12363.
   Irfan M, 2012, ENG OPTIMIZ, V44, P565, DOI 10.1080/0305215X.2011.588226.
   Jiang ZB, 2019, COMPUT IND ENG, V127, P1131, DOI 10.1016/j.cie.2018.05.050.
   Kaelbling LP, 1996, J ARTIF INTELL RES, V4, P237, DOI 10.1613/jair.301.
   Labi S, 2007, J TRANSP ENG-ASCE, V133, P298, DOI 10.1061/(ASCE)0733-947X(2007)133:5(298).
   Lample G, 2017, P 31 AAAI C ART INT.
   Lamptey G, 2008, DECIS SUPPORT SYST, V46, P376, DOI 10.1016/j.dss.2008.07.004.
   Li F, 2019, MEASUREMENT, V145, P191, DOI 10.1016/j.measurement.2019.05.093.
   Li H. C, 2015, P AUSTR U POW ENG C, P1, DOI DOI 10.1109/AUPEC.2015.7324827.
   Li YW, 2002, TRANSPORT RES A-POL, V36, P525, DOI 10.1016/S0965-8564(01)00020-9.
   Li ZB, 2017, IEEE T INTELL TRANSP, V18, P3204, DOI 10.1109/TITS.2017.2687620.
   Liang XY, 2019, IEEE T VEH TECHNOL, V68, P1243, DOI 10.1109/TVT.2018.2890726.
   Lin KX, 2018, KDD'18: PROCEEDINGS OF THE 24TH ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY \& DATA MINING, P1774, DOI 10.1145/3219819.3219993.
   Liu Z, 2019, FUTURE GENER COMP SY, V97, P1, DOI 10.1016/j.future.2019.02.068.
   MADANAT S, 1994, TRANSPORT SCI, V28, P55, DOI 10.1287/trsc.28.1.55.
   Mannion P, 2016, AUTON SYST, P47, DOI 10.1007/978-3-319-25808-9\_4.
   Medury A, 2014, J INFRASTRUCT SYST, V20, DOI 10.1061/(ASCE)IS.1943-555X.0000149.
   Memarzadeh M, 2016, COMPUT-AIDED CIV INF, V31, P403, DOI 10.1111/mice.12178.
   Mnih V., 2013, PROC 27 C NEURAL INF, P1.
   Mnih V, 2015, NATURE, V518, P529, DOI 10.1038/nature14236.
   Mocanu E, 2019, IEEE T SMART GRID, V10, P3698, DOI 10.1109/TSG.2018.2834219.
   Ng MW, 2009, COMPUT-AIDED CIV INF, V24, P459, DOI 10.1111/j.1467-8667.2009.00606.x.
   Ouyang Y, 2004, TRANSPORT RES A-POL, V38, P347, DOI 10.1016/j.tra.2003.10.007.
   Rafiei MH, 2018, J CONSTR ENG M, V144, DOI 10.1061/(ASCE)CO.1943-7862.0001570.
   Rafiei MH, 2017, STRUCT DES TALL SPEC, V26, DOI 10.1002/tal.1400.
   Rafiei MH, 2017, IEEE T NEUR NET LEAR, V28, P3074, DOI 10.1109/TNNLS.2017.2682102.
   Rafiei MH, 2017, SOIL DYN EARTHQ ENG, V100, P417, DOI 10.1016/j.soildyn.2017.05.013.
   Rafiei MH, 2017, ACI MATER J, V114, P237, DOI 10.14359/51689560.
   Rafiei MH, 2016, J CONSTR ENG M, V142, DOI 10.1061/(ASCE)CO.1943-7862.0001047.
   Silver D, 2017, NATURE, V550, P354, DOI 10.1038/nature24270.
   Silver D, 2016, NATURE, V529, P484, DOI 10.1038/nature16961.
   Su P. H., 2015, LEARNING REAL USERS.
   Sun Y, 2019, HUM-CENT COMPUT INFO, V9, DOI 10.1186/s13673-019-0187-4.
   Sutton R. S., 1998, REINFORCEMENT LEARNI.
   Taggart A, 2014, INFRASTRUCT ASSET MA, V1, P10, DOI 10.1680/iasma.13.00012.
   TSUNOKAWA K, 1994, TRANSPORT RES A-POL, V28, P151, DOI 10.1016/0965-8564(94)90035-3.
   Nguyen T, 2019, COMPUT-AIDED CIV INF, V34, P316, DOI 10.1111/mice.12422.
   Walls J, 1998, LIFE CYCLE COST ANAL.
   Walraven E, 2016, ENG APPL ARTIF INTEL, V52, P203, DOI 10.1016/j.engappai.2016.01.001.
   Wang GM, 2013, J MATER CIVIL ENG, V25, P1050, DOI 10.1061/(ASCE)MT.1943-5533.0000563.
   Wang IL, 2011, COMPUT IND ENG, V60, P593, DOI 10.1016/j.cie.2011.01.001.
   Wang JX, 2016, ARTIF LIFE ROBOT, V21, P125, DOI 10.1007/s10015-015-0260-7.
   Yang YH, 2019, SUSTAINABILITY-BASEL, V11, DOI 10.3390/su11030877.
   Yao LY, 2019, TRANSPORT RES REC, V2673, P66, DOI 10.1177/0361198118822501.
   Yeo H, 2010, SUSTAINABLE AND RESILIENT CRITICAL INFRASTRUCTURE SYSTEMS: SIMULATION, MODELING, AND INTELLIGENT ENGINEERING, P185, DOI 10.1007/978-3-642-11405-2\_7.
   Zhang A, 2019, COMPUT-AIDED CIV INF, V34, P213, DOI 10.1111/mice.12409.
   Zhang BC, 2015, J INTELL ROBOT SYST, V77, P391, DOI 10.1007/s10846-013-9901-z.
   Zhang H, 2010, J INFRASTRUCT SYST, V16, P310, DOI 10.1061/(ASCE)IS.1943-555X.0000042.
   Zhang S, 2019, J TRANSL MED, V17, DOI 10.1186/s12967-019-2090-1.
   Zhou L., 2014, INT J PAVEMENT RES T, V7, P159.
   Zolfpour-Arokhlo M, 2014, ENG APPL ARTIF INTEL, V29, P163, DOI 10.1016/j.engappai.2014.01.001.},
Number-of-Cited-References = {70},
Times-Cited = {28},
Usage-Count-Last-180-days = {19},
Usage-Count-Since-2013 = {73},
Journal-ISO = {Comput.-Aided Civil Infrastruct. Eng.},
Doc-Delivery-Number = {OB2HQ},
Web-of-Science-Index = {Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)},
Unique-ID = {WOS:000535227500001},
DA = {2022-04-30},
}

@article{ WOS:000457944600004,
Author = {Kuhnle, Andreas and Jakubik, Johannes and Lanza, Gisela},
Title = {Reinforcement learning for opportunistic maintenance optimization},
Journal = {PRODUCTION ENGINEERING-RESEARCH AND DEVELOPMENT},
Year = {2019},
Volume = {13},
Number = {1},
Pages = {33-41},
Month = {FEB},
Abstract = {Intelligent systems, that support the maintenance of production
   resources, offer real-time data-based approaches to optimize the
   maintenance effort and to reduce the usage of resources within
   production systems. However, unused potentials remain regarding
   maintenance schedules with minimal opportunity costs of the measures
   taken. This work provides a novel, machine-learning-based approach for
   the exploitation of these remaining optimization opportunities as an
   exemplary extension of the current state of the art. The determination
   of an optimal maintenance schedule for parallel working machines, is
   based on the data of a production system. The main result of this work
   is the performance of the implemented reinforcement learning algorithms,
   both in terms of downtime reduction, which increases the production
   output, and in terms of reducing maintenance costs compared to existing
   maintenance strategies. Hence, this work provides a holistic approach to
   the optimization of maintenance strategies and gives further evidence of
   a meaningful applicability of reinforcement learning algorithms in
   manufacturing processes.},
Publisher = {SPRINGER HEIDELBERG},
Address = {TIERGARTENSTRASSE 17, D-69121 HEIDELBERG, GERMANY},
Type = {Article},
Language = {English},
Affiliation = {Kuhnle, A (Corresponding Author), KIT, Inst Prod Sci, Wbk, Kaiserstr 12, D-76131 Karlsruhe, Germany.
   Kuhnle, Andreas; Jakubik, Johannes; Lanza, Gisela, KIT, Inst Prod Sci, Wbk, Kaiserstr 12, D-76131 Karlsruhe, Germany.},
DOI = {10.1007/s11740-018-0855-7},
ISSN = {0944-6524},
EISSN = {1863-7353},
Keywords = {Reinforcement learning; Opportunistic maintenance; Opportunity cost
   reduction; Multi-agent-systems; Proximal policy optimization; Production
   planning and control},
Research-Areas = {Engineering},
Web-of-Science-Categories  = {Engineering, Manufacturing},
Author-Email = {andreas.kuhnle@kit.edu
   johannes.jakubik@yahoo.com},
ORCID-Numbers = {Jakubik, Johannes/0000-0002-6235-0300},
Funding-Acknowledgement = {German Federal Ministry of Education and Research (BMBF)Federal Ministry
   of Education \& Research (BMBF) {[}02K16C082]},
Funding-Text = {We extend our sincere thanks to the German Federal Ministry of Education
   and Research (BMBF) for supporting this research project 02K16C082
   Produktionsbezogene Dienstleistungssysteme auf Basis von
   Big-Data-Analysen (ProData).},
Cited-References = {Colledani M, 2018, CIRP ANN-MANUF TECHN, V67, P499, DOI 10.1016/j.cirp.2018.04.078.
   Crites R., 1995, NIPS, V8, P1017.
   Hashemian HM, 2011, IEEE T INSTRUM MEAS, V60, P3480, DOI 10.1109/TIM.2009.2036347.
   Lindstrom J, 2017, PROC CIRP, V63, P443, DOI 10.1016/j.procir.2017.03.099.
   Mnih V., 2013, PROC 27 C NEURAL INF, P1.
   Schijve Jaap., 2009, FATIGUE STRUCTURES M, P15.
   Schulman J, 2017, ADV NEURAL INF PROCE, V8, P1017.
   Schulman J, 2015, PR MACH LEARN RES, V37, P1889.
   Stricker N, 2018, CIRP ANN-MANUF TECHN, V67, P511, DOI 10.1016/j.cirp.2018.04.041.
   Sutton R. S., 2017, REINFORCEMENT LEARNI.
   Wang X., 2014, J COMPUTATIONAL INFO, V10, P9.
   Wang X, 2016, J INTELL MANUF, V27, P325, DOI 10.1007/s10845-013-0864-5.
   WILLIAMS RJ, 1992, MACH LEARN, V8, P229, DOI 10.1007/BF00992696.
   Wuest T, 2016, PROD MANUF RES, V4, P23, DOI 10.1080/21693277.2016.1192517.
   Xie M, 1996, RELIAB ENG SYST SAFE, V52, P87, DOI 10.1016/0951-8320(95)00149-2.
   Yang L, 2018, J MANUF SYST, V47, P12, DOI 10.1016/j.jmsy.2018.02.003.},
Number-of-Cited-References = {16},
Times-Cited = {12},
Usage-Count-Last-180-days = {2},
Usage-Count-Since-2013 = {17},
Journal-ISO = {Prod. Eng.-Res. Dev.},
Doc-Delivery-Number = {HK4PZ},
Web-of-Science-Index = {Emerging Sources Citation Index (ESCI)},
Unique-ID = {WOS:000457944600004},
DA = {2022-04-30},
}

@inproceedings{ WOS:000188415500179,
Author = {Cao, H and Xi, HF and Smith, SF},
Editor = {Chick, SE and Sanchez, PJ and Ferrin, D and Morrice, DJ},
Title = {A reinforcement learning approach to production planning in the
   fabrication/fulfillment manufacturing process},
Booktitle = {PROCEEDINGS OF THE 2003 WINTER SIMULATION CONFERENCE, VOLS 1 AND 2},
Year = {2003},
Pages = {1417-1423},
Note = {36th Winter Simulation Conference, NEW ORLEANS, LA, DEC 07-10, 2003},
Organization = {Amer Stat Assoc; IEEE Comp Soc; IEEE SMC; Inst Ind Engineers; INFORMS,
   Coll Simulat; NIST; Soc Modeling \& Simulat Int},
Abstract = {We have used Reinforcement Learning together with Monte Carlo simulation
   to solve a multi-period production planning problem in a two-stage
   hybrid manufacturing process (a combination of build-to-plan with
   build-to-order) with a capacity constraint. Our model minimizes
   inventory and penalty costs while considering real-world complexities
   such as different component types sharing the same manufacturing
   capacity, multi-end-products sharing common components, multi-echelon
   bill-of-material (BOM), random lead times, etc. To efficiently search in
   the huge solution space, we designed a two-phase learning scheme where
   ``good{''} capacity usage ratios are first found for different decision
   epochs, based on which a detailed production schedule is further
   improved through learning to minimize costs. We will illustrate our
   approach through an example and conclude the paper with a discussion of
   future research directions.},
Publisher = {IEEE},
Address = {345 E 47TH ST, NEW YORK, NY 10017 USA},
Type = {Proceedings Paper},
Language = {English},
Affiliation = {Cao, H (Corresponding Author), IBM Corp, TJ Watson Res Ctr, Yorktown Hts, NY 10598 USA.
   IBM Corp, TJ Watson Res Ctr, Yorktown Hts, NY 10598 USA.},
DOI = {10.1109/WSC.2003.1261584},
ISBN = {0-7803-8131-9},
Research-Areas = {Computer Science; Engineering},
Web-of-Science-Categories  = {Computer Science, Interdisciplinary Applications; Computer Science,
   Software Engineering; Engineering, Manufacturing},
Author-Email = {hengcao@us.ibm.com
   haifengx@us.ibm.com
   sfs@cs.cmu.edu},
Cited-References = {CAO H, 2002, INT C PAR DISTR PROC.
   CAO H, 2003, INFORMS ANN M ATL.
   Finke DA, 2002, PROCEEDINGS OF THE 2002 WINTER SIMULATION CONFERENCE, VOLS 1 AND 2, P1013, DOI 10.1109/WSC.2002.1172994.
   Joines JA, 2002, PROCEEDINGS OF THE 2002 WINTER SIMULATION CONFERENCE, VOLS 1 AND 2, P1306, DOI 10.1109/WSC.2002.1166395.
   Kaelbling LP, 1996, J ARTIF INTELL RES, V4, P237, DOI 10.1613/jair.301.
   NAHMIAS S, 1997, PRODUCTION OPERATION, P338.
   Olafsson S, 2002, PROCEEDINGS OF THE 2002 WINTER SIMULATION CONFERENCE, VOLS 1 AND 2, P79, DOI 10.1109/WSC.2002.1172871.
   SHI L, 2000, OPER RES, P3.
   VANROY B, 1997, P IEEE C DEC CONTR.},
Number-of-Cited-References = {9},
Times-Cited = {4},
Usage-Count-Last-180-days = {0},
Usage-Count-Since-2013 = {2},
Doc-Delivery-Number = {BY24E},
Web-of-Science-Index = {Conference Proceedings Citation Index - Science (CPCI-S)},
Unique-ID = {WOS:000188415500179},
DA = {2022-04-30},
}

@article{ WOS:000272363000003,
Author = {Reynolds, Jeremy R. and O'Reilly, Randall C.},
Title = {Developing PFC representations using reinforcement learning},
Journal = {COGNITION},
Year = {2009},
Volume = {113},
Number = {3, SI},
Pages = {281-292},
Month = {DEC},
Abstract = {From both functional and biological considerations, it is widely
   believed that action production, planning, and goal-oriented behaviors
   supported by the frontal cortex are organized hierarchically {[}Fuster
   (1991); Koechlin, E., Ody, C., \& Kouneiher, F. (2003). Neuroscience:
   The architecture of cognitive control in the human prefrontal cortex.
   Science, 424, 1181-1184; Miller, G. A., Galanter, E., \& Pribram, K. H.
   (1960). Plans and the structure Of behavior. New York: Holt]. However,
   the nature of the different levels of the hierarchy remains unclear, and
   little attention has been paid to the origins of such a hierarchy. We
   address these issues through biologically-inspired computational models
   that develop representations through reinforcement learning. We explore
   several different factors in these models that might plausibly give rise
   to a hierarchical organization of representations within the PFC,
   including an initial connectivity hierarchy within PFC, a hierarchical
   set of connections between PFC and subcortical structures controlling
   it, and differential synaptic plasticity schedules. Simulation results
   indicate that architectural constraints contribute to the segregation of
   different types of representations, and that this segregation
   facilitates learning. These findings are consistent with the idea that
   there is a functional hierarchy in PFC, as captured in our earlier
   computational models of PFC function and a growing body of empirical
   data. (C) 2009 Elsevier B.V. All rights reserved.},
Publisher = {ELSEVIER SCIENCE BV},
Address = {PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS},
Type = {Article},
Language = {English},
Affiliation = {Reynolds, JR (Corresponding Author), Univ Denver, Dept Psychol, 2155 S Race St, Denver, CO 80208 USA.
   Reynolds, Jeremy R., Univ Denver, Dept Psychol, Denver, CO 80208 USA.
   O'Reilly, Randall C., Univ Colorado, Dept Psychol, Boulder, CO 80309 USA.},
DOI = {10.1016/j.cognition.2009.05.015},
ISSN = {0010-0277},
EISSN = {1873-7838},
Keywords = {PFC; Representation; Reinforcement learning; Functional organization},
Keywords-Plus = {DORSOLATERAL PREFRONTAL CORTEX; WORKING-MEMORY; COGNITIVE CONTROL;
   COMPUTATIONAL MODEL; FRONTOPOLAR CORTEX; FMRI EVIDENCE; ORGANIZATION;
   INFORMATION; INTEGRATION; CHILDREN},
Research-Areas = {Psychology},
Web-of-Science-Categories  = {Psychology, Experimental},
Author-Email = {jeremy.reynolds@psy.du.edu},
ORCID-Numbers = {O'Reilly, Randall/0000-0003-0322-4600},
Funding-Acknowledgement = {NIMH NIH HHSUnited States Department of Health \& Human ServicesNational
   Institutes of Health (NIH) - USANIH National Institute of Mental Health
   (NIMH) {[}1 F32 MH075300-01A2, F32 MH075300-01A2, R01 MH069597, P50
   MH079485-029003, F32 MH075300, R01 MH069597-01, P50 MH079485-020002, P50
   MH079485, R01 MH069597-05] Funding Source: Medline; NATIONAL INSTITUTE
   OF MENTAL HEALTHUnited States Department of Health \& Human
   ServicesNational Institutes of Health (NIH) - USANIH National Institute
   of Mental Health (NIMH) {[}P50MH079485, F32MH075300, R01MH069597]
   Funding Source: NIH RePORTER},
Cited-References = {BADRE D, 2008, J COGNITIVE NEUROSCI, V19.
   BARONE P, 1989, EXP BRAIN RES, V78, P447.
   Botvinick M, 2004, PSYCHOL REV, V111, P395, DOI 10.1037/0033-295X.111.2.395.
   Botvinick MM, 2008, TRENDS COGN SCI, V12, P201, DOI 10.1016/j.tics.2008.02.009.
   Botvinick MM, 2007, PHILOS T R SOC B, V362, P1615, DOI 10.1098/rstb.2007.2056.
   Botvinick MM, 2009, COGNITION, V113, P262, DOI 10.1016/j.cognition.2008.08.011.
   Braver TS, 2003, NEURON, V39, P713, DOI 10.1016/S0896-6273(03)00466-5.
   Braver TS, 2002, NEUROIMAGE, V15, P523, DOI 10.1006/nimg.2001.1019.
   Braver TS, 2001, J EXP PSYCHOL GEN, V130, P746, DOI 10.1037//0096-3445.130.4.746.
   Brown TT, 2005, CEREB CORTEX, V15, P275, DOI 10.1093/cercor/bhh129.
   Bunge SA, 2006, CURR DIR PSYCHOL SCI, V15, P118, DOI 10.1111/j.0963-7214.2006.00419.x.
   Chentanez N., 2005, ADV NEURAL INFORM PR, P1281, DOI DOI 10.21236/ADA440280.
   Christoff K, 2000, PSYCHOBIOLOGY, V28, P168.
   Christoff K, 2003, BEHAV NEUROSCI, V117, P1161, DOI 10.1037/0735-7044.117.6.1161.
   Christoff K, 2001, NEUROIMAGE, V14, P1136, DOI 10.1006/nimg.2001.0922.
   D'Esposito M, 1999, BRAIN COGNITION, V41, P66, DOI 10.1006/brcg.1999.1096.
   DAYAN P, 2008, FRONTIERS COMPUTATIO, V1.
   Duncan J, 2000, TRENDS NEUROSCI, V23, P475, DOI 10.1016/S0166-2236(00)01633-7.
   Frank MJ, 2001, COGN AFFECT BEHAV NE, V1, P137, DOI 10.3758/CABN.1.2.137.
   FUSTER J M, 1990, P318.
   Fuster JM, 2004, TRENDS COGN SCI, V8, P143, DOI 10.1016/j.tics.2004.02.004.
   Gogtay N, 2004, P NATL ACAD SCI USA, V101, P8174, DOI 10.1073/pnas.0402680101.
   Goldman-Rakic P.S., 1987, HDB PHYSL, V5, P373.
   Halford G.S., 1993, CHILDRENS UNDERSTAND, V1st.
   Halford GS, 1998, BEHAV BRAIN SCI, V21, P803, DOI 10.1017/S0140525X98001769.
   HALFORD GS, 1984, COGNITIVE PSYCHOL, V16, P65, DOI 10.1016/0010-0285(84)90004-5.
   Haxby JV, 2000, NEUROIMAGE, V11, P380, DOI 10.1006/nimg.2000.0592.
   Jeffress LA., 1951, CEREBRAL MECH BEHAV, DOI {[}10.1037/h0056603, DOI 10.1016/J.HUMOV.2007.04.001].
   Johnson MK, 2003, CEREB CORTEX, V13, P265, DOI 10.1093/cercor/13.3.265.
   Knight, 2002, PRINCIPLES FRONTAL L, P428, DOI {[}https://doi.org/10.1093/acprof:oso/9780195134971.003.0027, DOI 10.1093/ACPROF:OSO/9780195134971.003.0027].
   Koechlin E, 2003, SCIENCE, V302, P1181, DOI 10.1126/science.1088545.
   Koechlin E, 1999, NATURE, V399, P148, DOI 10.1038/20178.
   Koechlin E, 2007, SCIENCE, V318, P594, DOI 10.1126/science.1142995.
   Koechlin E, 2007, TRENDS COGN SCI, V11, P229, DOI 10.1016/j.tics.2007.04.005.
   Kroger JK, 2002, CEREB CORTEX, V12, P477, DOI 10.1093/cercor/12.5.477.
   Long JS, 2000, AM STAT, V54, P217, DOI 10.2307/2685594.
   Miller EK, 2000, NEUROIMAGE, V11, P447, DOI 10.1006/nimg.2000.0574.
   Miller EK, 2001, ANNU REV NEUROSCI, V24, P167, DOI 10.1146/annurev.neuro.24.1.167.
   Nystrom LE, 2000, NEUROIMAGE, V11, P424, DOI 10.1006/nimg.2000.0572.
   O'Donnell S, 2005, NEUROIMAGE, V24, P948, DOI 10.1016/j.neuroimage.2004.10.014.
   O'Reilly RC, 2007, BEHAV NEUROSCI, V121, P31, DOI 10.1037/0735-7044.121.1.31.
   O'Reilly RC, 2006, NEURAL COMPUT, V18, P283, DOI 10.1162/089976606775093909.
   O'Reilly RC, 1998, TRENDS COGN SCI, V2, P455, DOI 10.1016/S1364-6613(98)01241-8.
   O'Reilly RC, 2001, NEURAL COMPUT, V13, P1199, DOI 10.1162/08997660152002834.
   OReilly R.C., 2000, COMPUTATIONAL EXPLOR.
   OReilly RC, 1996, NEURAL COMPUT, V8, P895, DOI 10.1162/neco.1996.8.5.895.
   Paine RW, 2005, ADAPT BEHAV, V13, P211, DOI 10.1177/105971230501300303.
   Petrides M, 2000, EXP BRAIN RES, V133, P44, DOI 10.1007/s002210000399.
   Petrides M, 2007, J NEUROSCI, V27, P11573, DOI 10.1523/JNEUROSCI.2419-07.2007.
   Pickett Marc, 2002, P 19 INT C MACH LEAR, V2, P506.
   Poldrack RA, 1999, NEUROIMAGE, V10, P15, DOI 10.1006/nimg.1999.0441.
   Pribram, 1960, PLANS STRUCTURE BEHA.
   Rao SC, 1997, SCIENCE, V276, P821, DOI 10.1126/science.276.5313.821.
   Raye CL, 2002, NEUROIMAGE, V15, P447, DOI 10.1006/nimg.2001.0983.
   Reynolds JR, 2007, COGNITIVE SCI, V31, P613, DOI 10.1080/15326900701399913.
   Reynolds JR, 2009, CEREB CORTEX, V19, P1208, DOI 10.1093/cercor/bhn164.
   REYNOLDS JR, 2005, THESIS WASHINGTON U.
   REYNOLDS JR, 2009, ADV NEURAL INFORM PR.
   Rizzolatti G, 1998, TRENDS NEUROSCI, V21, P188, DOI 10.1016/S0166-2236(98)01260-0.
   Rizzolatti G, 1996, COGNITIVE BRAIN RES, V3, P131, DOI 10.1016/0926-6410(95)00038-0.
   Robin Nina, 1995, P987.
   Rougier NP, 2005, P NATL ACAD SCI USA, V102, P7338, DOI 10.1073/pnas.0502455102.
   Shaw P, 2008, J NEUROSCI, V28, P3586, DOI 10.1523/JNEUROSCI.5309-07.2008.
   Sowell ER, 1999, NAT NEUROSCI, V2, P859, DOI 10.1038/13154.
   Stuss D.T., 2002, PRINCIPLES FRONTAL L.
   Sutton RS, 1999, ARTIF INTELL, V112, P181, DOI 10.1016/S0004-3702(99)00052-1.
   Wallis JD, 2001, NATURE, V411, P953, DOI 10.1038/35082081.
   WILSON FAW, 1993, SCIENCE, V260, P1955, DOI 10.1126/science.8316836.
   Wood JN, 2003, NAT REV NEUROSCI, V4, P139, DOI 10.1038/nrn1033.},
Number-of-Cited-References = {69},
Times-Cited = {35},
Usage-Count-Last-180-days = {0},
Usage-Count-Since-2013 = {11},
Journal-ISO = {Cognition},
Doc-Delivery-Number = {527JJ},
Web-of-Science-Index = {Social Science Citation Index (SSCI)},
Unique-ID = {WOS:000272363000003},
OA = {Green Accepted},
DA = {2022-04-30},
}

@article{ WOS:000438470400126,
Author = {Stricker, Nicole and Kuhnle, Andreas and Sturm, Roland and Friess, Simon},
Title = {Reinforcement learning for adaptive order dispatching in the
   semiconductor industry},
Journal = {CIRP ANNALS-MANUFACTURING TECHNOLOGY},
Year = {2018},
Volume = {67},
Number = {1},
Pages = {511-514},
Abstract = {The digitalization of production systems tends to provide a huge amount
   of data from heterogeneous sources. This is particularly true for the
   semiconductor industry wherein real time process monitoring is
   inherently required to achieve a high yield of good parts. An
   application of data-driven algorithms in production planning to enhance
   operational excellence for complex semiconductor production systems is
   currently missing. This paper shows the successful implementation of a
   reinforcement learning-based adaptive control system for order
   dispatching in the semiconductor industry. Furthermore, a performance
   comparison of the learning-based control system with the traditionally
   used rule-based system shows remarkable results. Since a strict rulebook
   does not bind the learning-based control system, a flexible adaption to
   changes in the environment can be achieved through a combination of
   online and offline learning. (C) 2018 Published by Elsevier Ltd on
   behalf of CIRP.},
Publisher = {ELSEVIER SCIENCE BV},
Address = {PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS},
Type = {Article},
Language = {English},
Affiliation = {Stricker, N (Corresponding Author), KIT, Wbk Inst Prod Sci, Karlsruhe, Germany.
   Stricker, Nicole; Kuhnle, Andreas, KIT, Wbk Inst Prod Sci, Karlsruhe, Germany.
   Sturm, Roland; Friess, Simon, Infineon Technol AG, Regensburg, Germany.},
DOI = {10.1016/j.cirp.2018.04.041},
ISSN = {0007-8506},
EISSN = {1726-0604},
Keywords = {Production planning; Artificial intelligence; Semiconductor industry},
Keywords-Plus = {PREDICTION; SYSTEMS},
Research-Areas = {Engineering},
Web-of-Science-Categories  = {Engineering, Industrial; Engineering, Manufacturing},
Author-Email = {nicole.stricker@kit.edu},
ORCID-Numbers = {Stricker, Nicole/0000-0001-5367-084X},
Funding-Acknowledgement = {German Federal Ministry of Education and Research (BMBF)Federal Ministry
   of Education \& Research (BMBF) {[}02P14B161]},
Funding-Text = {We extend our sincere thanks to the German Federal Ministry of Education
   and Research (BMBF) for supporting this research project 02P14B161
   ``Empowerment and Implementation Strategies for Industry 4.0{''}.},
Cited-References = {Fordyce K, 2015, INT J IND ENG-THEORY, V22, P575.
   Freitag M, 2016, CIRP ANN-MANUF TECHN, V65, P433, DOI 10.1016/j.cirp.2016.04.066.
   Gunther J, 2016, MECHATRONICS, V34, P1, DOI 10.1016/j.mechatronics.2015.09.004.
   Henke N., 2016, AGE ANAL COMPETING D.
   Monch L., 2013, PRODUCTION PLANNING.
   Monostori L, 2006, CIRP ANN-MANUF TECHN, V55, P697, DOI 10.1016/j.cirp.2006.10.004.
   Monostori L, 2004, CIRP ANN-MANUF TECHN, V53, P349, DOI 10.1016/S0007-8506(07)60714-8.
   Moyne J, 2017, PROCESSES, V5, DOI 10.3390/pr5030039.
   Oliff H, 2017, PROC CIRP, V63, P167, DOI 10.1016/j.procir.2017.03.311.
   Russell S., 2009, ARTIFICIAL INTELLIGE.
   Schuh G, 2017, CIRP ANN-MANUF TECHN, V66, P425, DOI 10.1016/j.cirp.2017.04.003.
   Sutton R. S., 2012, REINFORCEMENT LEARNI.
   TSITSIKLIS JN, 1994, MACH LEARN, V16, P185, DOI 10.1023/A:1022689125041.
   Uzsoy R., 1993, Journal of Electronics Manufacturing, V3, P95, DOI 10.1142/S0960313193000115.
   Wang P, 2017, CIRP ANN-MANUF TECHN, V66, P429, DOI 10.1016/j.cirp.2017.04.013.
   Waschneck B, 2016, CEUR WORKSHOP P, V1793, P12.},
Number-of-Cited-References = {16},
Times-Cited = {44},
Usage-Count-Last-180-days = {8},
Usage-Count-Since-2013 = {21},
Journal-ISO = {CIRP Ann-Manuf. Technol.},
Doc-Delivery-Number = {GM8IY},
Web-of-Science-Index = {Science Citation Index Expanded (SCI-EXPANDED)},
Unique-ID = {WOS:000438470400126},
DA = {2022-04-30},
}

@article{ WOS:000695891500001,
Author = {Kuhnle, Andreas and May, Marvin Carl and Schaefer, Louis and Lanza,
   Gisela},
Title = {Explainable reinforcement learning in production control of job shop
   manufacturing system},
Journal = {INTERNATIONAL JOURNAL OF PRODUCTION RESEARCH},
Abstract = {Manufacturing in the age of Industry 4.0 can be characterised by a high
   product variety and complex material flows. The increasing
   individualisation of products requires adaptive production planning and
   control systems. Research in the area of Machine Learning demonstrates
   the applicability and potential of Reinforcement Learning (RL) systems
   for the control of complex manufacturing. However, a major disadvantage
   of RL-methods is that they are usually considered as `black box' models.
   For this reason, this paper investigates methods of explainable
   reinforcement learning in production control. Based on a comprehensive
   literature review an approach to increase the plausibility of RL-based
   control strategies is presented. The approach combines the advantages of
   high prediction accuracy (e.g. neural networks) and high explainability
   (e.g. decision trees). In doing so, understandable control strategies
   such as heuristics can be generated, and an advanced RL-system can be
   designed including specific domain expertise. The results are
   demonstrated based on a real-world system, taken from semiconductor
   manufacturing, which is investigated in a simulated approach.},
Publisher = {TAYLOR \& FRANCIS LTD},
Address = {2-4 PARK SQUARE, MILTON PARK, ABINGDON OR14 4RN, OXON, ENGLAND},
Type = {Article; Early Access},
Language = {English},
Affiliation = {Kuhnle, A (Corresponding Author), Karlsruhe Inst Technol KIT, WBK Inst Prod Sci, Kaiserstr 12, D-76131 Karlsruhe, Germany.
   Kuhnle, Andreas; May, Marvin Carl; Schaefer, Louis; Lanza, Gisela, Karlsruhe Inst Technol KIT, WBK Inst Prod Sci, Kaiserstr 12, D-76131 Karlsruhe, Germany.},
DOI = {10.1080/00207543.2021.1972179},
EarlyAccessDate = {SEP 2021},
ISSN = {0020-7543},
EISSN = {1366-588X},
Keywords = {production control; reinforcement learning; semiconductor manufacturing;
   explainability; simulation},
Keywords-Plus = {DESIGN; CLASSIFICATION; GO},
Research-Areas = {Engineering; Operations Research \& Management Science},
Web-of-Science-Categories  = {Engineering, Industrial; Engineering, Manufacturing; Operations Research
   \& Management Science},
Author-Email = {andreas.kuhnle@kit.edu},
ORCID-Numbers = {May, Marvin Carl/0000-0002-9361-6685},
Funding-Acknowledgement = {Karlsruhe House of Young Scientists (KHYS)},
Funding-Text = {This collaborative research was supported by the Karlsruhe House of
   Young Scientists (KHYS) in the framework of the Research Travel Grant.
   We extend our sincere gratitude the KHYS for supporting this research.
   https://www.khys.kit.edu/english/research\_travel\_grant\_doc.php},
Cited-References = {{[}Anonymous], 2019, EMERGENT TOOL USE MU.
   Arel I, 2010, IET INTELL TRANSP SY, V4, P128, DOI 10.1049/iet-its.2009.0070.
   Aydin ME, 2000, ROBOT AUTON SYST, V33, P169, DOI 10.1016/S0921-8890(00)00087-7.
   Bach S, 2015, PLOS ONE, V10, DOI 10.1371/journal.pone.0130140.
   BLAZEWICZ J, 1983, DISCRETE APPL MATH, V5, P11, DOI 10.1016/0166-218X(83)90012-4.
   Brittain Marc., 2019, ARXIV190501303.
   Ciosek K., 2019, ADV NEURAL INFORM PR, V32, P1787.
   Colledani M, 2014, CIRP ANN-MANUF TECHN, V63, P773, DOI 10.1016/j.cirp.2014.05.002.
   Dewey Daniel., 2014, 2014 AAAI SPRING S S, P13.
   Dulac-Arnold G., 2019, ARXIV190412901.
   Ennen P, 2016, PROC CIRP, V51, P57, DOI 10.1016/j.procir.2016.05.094.
   Gabel T., 2008, INT J INFORM TECHNOL, V24.
   Gabel T, 2012, INT J PROD RES, V50, P41, DOI 10.1080/00207543.2011.571443.
   Ganin Y, 2018, PR MACH LEARN RES, V80.
   Glascher J, 2010, NEURON, V66, P585, DOI 10.1016/j.neuron.2010.04.016.
   Graham R. L., 1979, Discrete Optimisation, P287.
   GRAVES SC, 1981, OPER RES, V29, P646, DOI 10.1287/opre.29.4.646.
   Greschke P, 2014, PROC CIRP, V17, P160, DOI 10.1016/j.procir.2014.02.040.
   Greydanus Sam, 2017, ARXIV171100138.
   Hausknecht M., 2015, DEEP RECURRENT Q LEA.
   He Sen., 2018, ARXIV180104261.
   Hsu Chi-Hung, 2018, CORR.
   Jaques Natasha., 2018, SOCIAL INFLUENCE INT.
   Jaunet Theo., 2019, DRLVIZ UNDERSTANDING.
   Kober Jens., 2014, SPRINGER TRACTS ADV.
   Kuhnle A., 2017, TENSORFORCE TENSORFL.
   Kuhnle A, 2021, J INTELL MANUF, V32, P855, DOI 10.1007/s10845-020-01612-y.
   Kuhnle A, 2019, PROC CIRP, V81, P234, DOI 10.1016/j.procir.2019.03.041.
   Kuhnle Andreas., 2020, THESIS KIT KARLSRUHE.
   Kupper Daniel., 2018, WILL FLEXIBLE CELL M.
   Lasi H, 2014, BUS INFORM SYST ENG+, V6, P239, DOI 10.1007/s12599-014-0334-4.
   Law A.M., 2014, SIMULATION MODELING.
   Levine S., 2015, END TO END TRAINING.
   Li Jiwei., 2017, UNDERSTANDING NEURAL.
   Li Sheng., 2019, OPTIMIZING COLLISION.
   LITTLE JDC, 1961, OPER RES, V9, P383, DOI 10.1287/opre.9.3.383.
   Madumal Prashan., 2019, EXPLAINABLE REINFORC.
   Mahadevan S., 1998, FLAIRS-98. Proceedings of the Eleventh International Florida Artificial Intelligence Research Symposium Conference, P372.
   Mao HZ, 2016, PROCEEDINGS OF THE 15TH ACM WORKSHOP ON HOT TOPICS IN NETWORKS (HOTNETS `16), P50, DOI 10.1145/3005745.3005750.
   Mavrin B, 2019, PR MACH LEARN RES, V97.
   May M.C., 2021, PROCEDIA CIRP, V99, P27, DOI {[}10.1016/j.procir.2021.03.005, DOI 10.1016/J.PROCIR.2021.03.005].
   May M.C., 2021, PROCEDIA CIRP, V96, P3.
   May M.C., 2021, PROCEDIA CIRP, V96, P45, DOI {[}10.1016/j.procir.2021.01.050, DOI 10.1016/J.PROCIR.2021.01.050].
   Mayer S, 2019, IEEE SYS MAN CYBERN, P120, DOI 10.1109/SMC.2019.8914498.
   Mendonca Russell., 2019, GUIDED METAPOLICY SE.
   Mes M, 2007, EUR J OPER RES, V181, P59, DOI 10.1016/j.ejor.2006.02.051.
   Meurer A, 2017, PEERJ COMPUT SCI, DOI 10.7717/peerj-cs.103.
   Minguillon FE, 2019, PROC CIRP, V79, P385, DOI 10.1016/j.procir.2019.02.099.
   Mnih V., 2013, PROC 27 C NEURAL INF, P1.
   Monch L., 2013, PRODUCTION PLANNING, V10, P978.
   Morch NJS, 1995, 1995 IEEE INTERNATIONAL CONFERENCE ON NEURAL NETWORKS PROCEEDINGS, VOLS 1-6, P2085, DOI 10.1109/ICNN.1995.488997.
   Ng AY, 1999, MACHINE LEARNING, PROCEEDINGS, P278.
   Qu XY, 2019, J MANUF SYST, V50, P1, DOI 10.1016/j.jmsy.2018.11.005.
   Rakelly K, 2019, PR MACH LEARN RES, V97.
   Ribeiro MT, 2016, KDD'16: PROCEEDINGS OF THE 22ND ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P1135, DOI 10.1145/2939672.2939778.
   Riedmiller S, 1999, IJCAI-99: PROCEEDINGS OF THE SIXTEENTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, VOLS 1 \& 2, P764.
   Russell StuartJ., 2016, ALWAYS LEARNING, V3rd.
   Samek W., 2019, LECT NOTES COMPUTER.
   Schonemann M, 2015, J MANUF SYST, V37, P104, DOI 10.1016/j.jmsy.2015.09.002.
   Schulman J., 2017, 170706347 ARXIV.
   Schulman J, 2015, PR MACH LEARN RES, V37, P1889.
   Selvaraju RR, 2017, IEEE I CONF COMP VIS, P618, DOI 10.1109/ICCV.2017.74.
   Silver D, 2018, SCIENCE, V362, P1140, DOI 10.1126/science.aar6404.
   Silver D, 2017, NATURE, V550, P354, DOI 10.1038/nature24270.
   Simonyan K., 2014, ARXIV PREPRINT ARXIV, DOI DOI 10.1080/00994480.2000.10748487.
   Stricker N, 2018, CIRP ANN-MANUF TECHN, V67, P511, DOI 10.1016/j.cirp.2018.04.041.
   Sutton RS, 2018, ADAPT COMPUT MACH LE, P1.
   Tedrake R., 2004, 2004 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS) (IEEE Cat. No.04CH37566), P2849.
   Vinyals O, 2019, NATURE, V575, P350, DOI 10.1038/s41586-019-1724-z.
   Wang J, 2012, INT J PROD RES, V50, P4381, DOI 10.1080/00207543.2011.592158.
   Waschneck B, 2018, ASMC PROC, P301, DOI 10.1109/ASMC.2018.8373191.
   Waschneck Bernd., 2016, GRAZ.
   Wei Zhang, 1995, IJCAI-95. Proceedings of the Fourteenth International Joint Conference on Artificial Intelligence, P1114.
   Wiendahl HP, 2007, CIRP ANN-MANUF TECHN, V56, P783, DOI 10.1016/j.cirp.2007.10.003.
   Wu J, 2011, FUTURE GENER COMP SY, V27, P430, DOI 10.1016/j.future.2010.10.009.
   Yao Mariya., 2019, BREAKTHROUGH RES REI.
   Zhang ZC, 2011, EUR J OPER RES, V215, P446, DOI 10.1016/j.ejor.2011.05.052.},
Number-of-Cited-References = {77},
Times-Cited = {2},
Usage-Count-Last-180-days = {20},
Usage-Count-Since-2013 = {25},
Journal-ISO = {Int. J. Prod. Res.},
Doc-Delivery-Number = {UQ2HV},
Web-of-Science-Index = {Science Citation Index Expanded (SCI-EXPANDED)},
Unique-ID = {WOS:000695891500001},
DA = {2022-04-30},
}

@article{ WOS:000668771600001,
Author = {Heger, Jens and Voss, Thomas},
Title = {Dynamically adjusting the k-values of the ATCS rule in a flexible flow
   shop scenario with reinforcement learning},
Journal = {INTERNATIONAL JOURNAL OF PRODUCTION RESEARCH},
Abstract = {Given the fact that finding the optimal sequence in a flexible flow shop
   is usually an NP-hard problem, priority-based sequencing rules are
   applied in many real-world scenarios. In this contribution, an
   innovative reinforcement learning approach is used as a hyper-heuristic
   to dynamically adjust the k-values of the ATCS sequencing rule in a
   complex manufacturing scenario. For different product mixes as well as
   different utilisation levels, the reinforcement learning approach is
   trained and compared to the k-values found with an extensive simulation
   study. This contribution presents a human comprehensible
   hyper-heuristic, which is able to adjust the k-values to internal and
   external stimuli and can reduce the mean tardiness up to 5\%.},
Publisher = {TAYLOR \& FRANCIS LTD},
Address = {2-4 PARK SQUARE, MILTON PARK, ABINGDON OR14 4RN, OXON, ENGLAND},
Type = {Article; Early Access},
Language = {English},
Affiliation = {Voss, T (Corresponding Author), Leuphana Univ Lueneburg, Inst Prod \& Proc Innovat, Univ Allee 1, D-21335 Luneburg, Germany.
   Heger, Jens; Voss, Thomas, Leuphana Univ Lueneburg, Inst Prod \& Proc Innovat, Univ Allee 1, D-21335 Luneburg, Germany.},
DOI = {10.1080/00207543.2021.1943762},
EarlyAccessDate = {JUN 2021},
ISSN = {0020-7543},
EISSN = {1366-588X},
Keywords = {Sequencing rules; dynamic adjustment; simulation study; reinforcement
   learning; production planning and control},
Keywords-Plus = {WEIGHTED TARDINESS; SCHEDULING JOBS; NETWORK},
Research-Areas = {Engineering; Operations Research \& Management Science},
Web-of-Science-Categories  = {Engineering, Industrial; Engineering, Manufacturing; Operations Research
   \& Management Science},
Author-Email = {jens.heger@leuphana.de
   thomas.voss@leuphana.de},
ORCID-Numbers = {Voss, Thomas/0000-0002-2929-954X},
Cited-References = {ADAMS J, 1988, MANAGE SCI, V34, P391, DOI 10.1287/mnsc.34.3.391.
   Baker KennethR., 1984, J OPER MANAG, V4, P99, DOI {[}10.1016/0272-6963(84)90026-3, DOI 10.1016/0272-6963(84)90026-3].
   Branke J, 2016, IEEE T EVOLUT COMPUT, V20, P110, DOI 10.1109/TEVC.2015.2429314.
   Branke J, 2015, EVOL COMPUT, V23, P249, DOI 10.1162/EVCO\_a\_00131.
   Chen JY, 2010, IIE TRANS, V42, P842, DOI 10.1080/07408171003685825.
   Chen SK, 2019, INT J PROD RES, V57, P3080, DOI 10.1080/00207543.2018.1535205.
   Chen Yan., 2013, 2013 INT C ENG MANAG, P1.
   Fangfang Zhang, 2020, Evolutionary Computation in Combinatorial Optimization. 20th European Conference, EvoCOP 2020. Held as Part of EvoStar 2020. Proceedings. Lecture Notes in Computer Science (LNCS 12102), P214, DOI 10.1007/978-3-030-43680-3\_14.
   Fazlollahtabar H, 2015, IND ROBOT, V42, P252, DOI 10.1108/IR-12-2014-0437.
   Gabel T., 2008, INT J INFORM TECHNOL, V24.
   Gabel Thomas., 2009, THESIS U OSNABRUCK O.
   Gallay O., P HAMB INT C LOG HCL, P19, DOI {[}10.15480/882.1473, DOI 10.15480/882.1473].
   Graham R. L., 1979, Discrete Optimisation, P287.
   Heger J, 2014, DYNAMISCHE REGELSELE.
   Heger J, 2020, WINT SIMUL C PROC, P1608, DOI 10.1109/WSC48552.2020.9383903.
   Heger J, 2016, INT J PROD RES, V54, P6812, DOI 10.1080/00207543.2016.1178406.
   Holland John H, 1984, ADAPTIVE CONTROL ILL, P317, DOI DOI 10.1007/978-1-4684-8941-5\_21.
   Jun S, 2021, INT J PROD RES, V59, P2838, DOI 10.1080/00207543.2020.1741716.
   Kardos Csaba, 2021, Procedia CIRP, V97, P104, DOI 10.1016/j.procir.2020.05.210.
   Knust Sigrid., 1999, THESIS U OSNABRUCK O.
   Kuhnle A, 2021, J INTELL MANUF, V32, P855, DOI 10.1007/s10845-020-01612-y.
   Kuhnle A, 2019, PROC CIRP, V79, P391, DOI 10.1016/j.procir.2019.02.101.
   Kuhnle Andreas., 2020, FORSCHUNGSBERICHTE W, V241.
   Kumar Rajeev, 2016, GLOBAL J ENTERPRISE, V8, P10, DOI {[}10.18311/gjeis/2016/7284, DOI 10.18311/GJEIS/2016/7284].
   Lee YH, 1997, IIE TRANS, V29, P45, DOI 10.1080/07408179708966311.
   May M.C., 2021, PROCEDIA CIRP, V96, P3.
   Mnih V, 2015, NATURE, V518, P529, DOI 10.1038/nature14236.
   Monch L, 2006, ENG APPL ARTIF INTEL, V19, P235, DOI 10.1016/j.engappai.2005.10.001.
   Nguyen S, 2017, COMPLEX INTELL SYST, V3, P41, DOI 10.1007/s40747-017-0036-x.
   Oukil A, 2021, INT J PROD RES, V59, P388, DOI 10.1080/00207543.2019.1696487.
   PANWALKAR SS, 1977, OPER RES, V25, P45, DOI 10.1287/opre.25.1.45.
   Park YS, 2000, COMPUT IND ENG, V38, P189, DOI 10.1016/S0360-8352(00)00038-3.
   Pickardt CW, 2013, INT J PROD ECON, V145, P67, DOI 10.1016/j.ijpe.2012.10.016.
   Poppenborg J, 2012, EUR J IND ENG, V6, P497, DOI 10.1504/EJIE.2012.047662.
   Qu T., 2016, International Journal of Advanced Manufacturing Technology, V84, P147, DOI 10.1007/s00170-015-7220-1.
   Riley M, 2016, IEEE C EVOL COMPUTAT, P3362, DOI 10.1109/CEC.2016.7744215.
   Scholz-Reiter Bernd., 2010, PRODUCTIVITY MANAGEM, V15, P57.
   Sharma P, 2017, P I MECH ENG B-J ENG, V231, P329, DOI 10.1177/0954405415576060.
   Shi L, 2021, INT J PROD RES, V59, P576, DOI 10.1080/00207543.2019.1699671.
   Shiue YR, 2020, IEEE ACCESS, V8, P106542, DOI 10.1109/ACCESS.2020.3000781.
   Shiue YR, 2018, COMPUT IND ENG, V125, P604, DOI 10.1016/j.cie.2018.03.039.
   Silver D, 2017, NATURE, V550, P354, DOI 10.1038/nature24270.
   Stricker N, 2018, CIRP ANN-MANUF TECHN, V67, P511, DOI 10.1016/j.cirp.2018.04.041.
   VEPSALAINEN APJ, 1987, MANAGE SCI, V33, P1035, DOI 10.1287/mnsc.33.8.1035.
   Vinyals Oriol., 2017, PREPRINT ARXIV170804.
   Waschneck B, 2018, PROC CIRP, V72, P1264, DOI 10.1016/j.procir.2018.03.212.
   Wuest T, 2016, PROD MANUF RES, V4, P23, DOI 10.1080/21693277.2016.1192517.
   Zhang FF, 2019, PROCEEDINGS OF THE 2019 GENETIC AND EVOLUTIONARY COMPUTATION CONFERENCE (GECCO'19), P347, DOI 10.1145/3321707.3321790.
   Zhang FF, 2019, IEEE C EVOL COMPUTAT, P41, DOI 10.1109/CEC.2019.8790030.
   Zhang FF, 2018, LECT NOTES ARTIF INT, V11320, P472, DOI 10.1007/978-3-030-03991-2\_43.
   Zhao M, 2019, IEEE INT CON AUTO SC, P331, DOI 10.1109/COASE.2019.8843100.
   Zheng Shuai., 2019, PREPRINT ARXIV191002.},
Number-of-Cited-References = {52},
Times-Cited = {1},
Usage-Count-Last-180-days = {15},
Usage-Count-Since-2013 = {30},
Journal-ISO = {Int. J. Prod. Res.},
Doc-Delivery-Number = {TC6SR},
Web-of-Science-Index = {Science Citation Index Expanded (SCI-EXPANDED)},
Unique-ID = {WOS:000668771600001},
OA = {hybrid},
DA = {2022-04-30},
}

@article{ WOS:000696858100001,
Author = {Panzer, Marcel and Bender, Benedict},
Title = {Deep reinforcement learning in production systems: a systematic
   literature review},
Journal = {INTERNATIONAL JOURNAL OF PRODUCTION RESEARCH},
Abstract = {Shortening product development cycles and fully customisable products
   pose major challenges for production systems. These not only have to
   cope with an increased product diversity but also enable high
   throughputs and provide a high adaptability and robustness to process
   variations and unforeseen incidents. To overcome these challenges, deep
   Reinforcement Learning (RL) has been increasingly applied for the
   optimisation of production systems. Unlike other machine learning
   methods, deep RL operates on recently collected sensor-data in direct
   interaction with its environment and enables real-time responses to
   system changes. Although deep RL is already being deployed in production
   systems, a systematic review of the results has not yet been
   established. The main contribution of this paper is to provide
   researchers and practitioners an overview of applications and to
   motivate further implementations and research of deep RL supported
   production systems. Findings reveal that deep RL is applied in a variety
   of production domains, contributing to data-driven and flexible
   processes. In most applications, conventional methods were outperformed
   and implementation efforts or dependence on human experience were
   reduced. Nevertheless, future research must focus more on transferring
   the findings to real-world systems to analyse safety aspects and
   demonstrate reliability under prevailing conditions.},
Publisher = {TAYLOR \& FRANCIS LTD},
Address = {2-4 PARK SQUARE, MILTON PARK, ABINGDON OR14 4RN, OXON, ENGLAND},
Type = {Review; Early Access},
Language = {English},
Affiliation = {Panzer, M (Corresponding Author), Univ Potsdam, Chair Business Informat Proc \& Syst, Karl Marx St 67, D-14482 Potsdam, Germany.
   Panzer, Marcel; Bender, Benedict, Univ Potsdam, Chair Business Informat Proc \& Syst, Karl Marx St 67, D-14482 Potsdam, Germany.},
DOI = {10.1080/00207543.2021.1973138},
EarlyAccessDate = {SEP 2021},
ISSN = {0020-7543},
EISSN = {1366-588X},
Keywords = {Machine learning; reinforcement learning; production control; production
   planning; manufacturing processes; systematic literature review},
Keywords-Plus = {MANIPULATION; FUTURE; CHALLENGES; MANAGEMENT; ROBUST; FORCE; ARM},
Research-Areas = {Engineering; Operations Research \& Management Science},
Web-of-Science-Categories  = {Engineering, Industrial; Engineering, Manufacturing; Operations Research
   \& Management Science},
Author-Email = {marcel.panzer@wi.uni-potsdam.de},
ResearcherID-Numbers = {Panzer, Marcel/AAZ-8863-2021},
ORCID-Numbers = {Panzer, Marcel/0000-0003-4099-0179},
Cited-References = {Rossit DA, 2019, INT J PROD RES, V57, P3802, DOI 10.1080/00207543.2018.1504248.
   Altenmuller T, 2020, PROD ENG-RES DEV, V14, P319, DOI 10.1007/s11740-020-00967-8.
   Andersen RE, 2019, PROCEDIA MANUF, V38, P171.
   Arinez JF, 2020, J MANUF SCI E-T ASME, V142, DOI 10.1115/1.4047855.
   Baer S, 2019, 2019 SECOND INTERNATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE FOR INDUSTRIES (AI4I 2019), P22, DOI 10.1109/AI4I46381.2019.00014.
   Baer Schirin., 2020, 2020 INT C MAN SYST, P1.
   Bakakeu J., 2018, Applied Mechanics and Materials, V882, P96, DOI 10.4028/www.scientific.net/AMM.882.96.
   Bakakeu J, 2020, CAN CON EL COMP EN.
   Bellman Richard., 1957, DYNAMIC PROGRAMMING, V1.
   Beltran-Hernandez CC, 2020, APPL SCI-BASEL, V10, DOI 10.3390/app10196923.
   Beltran-Hernandez CC, 2020, IEEE ROBOT AUTOM LET, V5, P5709, DOI 10.1109/LRA.2020.3010739.
   Brito T., 2020, PROCEDIA MANUF, V51, P11, DOI {[}10.1016/j.promfg.2020.10.003, DOI 10.1016/J.PROMFG.2020.10.003].
   Cao D, 2020, J MOD POWER SYST CLE, V8, P1029, DOI 10.35833/MPCE.2020.000552.
   Chen BT, 2019, IEEE NETWORK, V33, P61, DOI 10.1109/MNET.001.1800505.
   Chen N, 2020, IEEE ACCESS, V8, P149730, DOI 10.1109/ACCESS.2020.3015801.
   Chien CF, 2020, INT J PROD RES, V58, P2784, DOI 10.1080/00207543.2020.1733125.
   Cooper H.M., 1988, KNOWLEDGE SOC, V1, P104, DOI {[}10.1007/BF03177550, DOI 10.1007/BF03177550].
   Dai WX, 2020, IEEE SENS J, V20, P8307, DOI 10.1109/JSEN.2020.2970747.
   Ding Y, 2019, ADV ENG INFORM, V42, DOI 10.1016/j.aei.2019.100977.
   Dittrich MA, 2020, CIRP ANN-MANUF TECHN, V69, P389, DOI 10.1016/j.cirp.2020.04.005.
   Dong TT, 2020, CONCURR COMP-PRACT E, V32, DOI 10.1002/cpe.5654.
   Dornheim J, 2020, INT J CONTROL AUTOM, V18, P1593, DOI 10.1007/s12555-019-0120-7.
   Durach CF, 2017, J SUPPLY CHAIN MANAG, V53, P67, DOI 10.1111/jscm.12145.
   Epureanu BI, 2020, CIRP ANN-MANUF TECHN, V69, P421, DOI 10.1016/j.cirp.2020.04.008.
   Feldkamp N, 2020, WINT SIMUL C PROC, P1596, DOI 10.1109/WSC48552.2020.9384089.
   Gabel T., 2007, INT J INFORM TECHNOL, V24, P14.
   Ge YY, 2019, IEEE ACCESS, V7, P165007, DOI 10.1109/ACCESS.2019.2952651.
   Greenhalgh T, 2005, BRIT MED J, V331, P1064, DOI 10.1136/bmj.38636.593461.68.
   Gunther J, 2016, MECHATRONICS, V34, P1, DOI 10.1016/j.mechatronics.2015.09.004.
   Guo F, 2019, APPL SOFT COMPUT, V85, DOI 10.1016/j.asoc.2019.105828.
   Guo Li., 2019, 2019 IEEE 21 INT C H.
   Nguyen H, 2019, 2019 THIRD IEEE INTERNATIONAL CONFERENCE ON ROBOTIC COMPUTING (IRC 2019), P590, DOI 10.1109/IRC.2019.00120.
   Han BA, 2020, IEEE ACCESS, V8, P186474, DOI 10.1109/ACCESS.2020.3029868.
   He ZL, 2021, COMPUT IND, V125, DOI 10.1016/j.compind.2020.103373.
   Heger J, 2020, WINT SIMUL C PROC, P1608, DOI 10.1109/WSC48552.2020.9383903.
   Hildebrand Max., 2020, PROCEDIA MANUFACTURI, V51, P1462, DOI {[}10.1016/j.promfg.2020.10.203, DOI 10.1016/J.PROMFG.2020.10.203].
   Hoppe S, 2019, IEEE ROBOT AUTOM LET, V4, P4042, DOI 10.1109/LRA.2019.2928212.
   Hu H, 2020, COMPUT IND ENG, V149, DOI 10.1016/j.cie.2020.106749.
   Hu L, 2020, J MANUF SYST, V55, P1, DOI 10.1016/j.jmsy.2020.02.004.
   Huang J, 2020, EXPERT SYST APPL, V160, DOI 10.1016/j.eswa.2020.113701.
   Huang XF, 2019, IEEE ACCESS, V7, P82194, DOI 10.1109/ACCESS.2019.2924030.
   Hubbs CD, 2020, COMPUT CHEM ENG, V141, DOI 10.1016/j.compchemeng.2020.106982.
   Inoue T, 2017, IEEE INT C INT ROBOT, P819, DOI 10.1109/IROS.2017.8202244.
   Jiang Y, 2019, IEEE T IND ELECTRON, V66, P4587, DOI 10.1109/TIE.2018.2856198.
   Jiang Y, 2018, IEEE T IND INFORM, V14, P1974, DOI 10.1109/TII.2017.2761852.
   Jin ZS, 2019, INT J ADV MANUF TECH, V100, P2163, DOI 10.1007/s00170-018-2864-2.
   Kagermann H., 2013, RECOMMENDATIONS IMPL.
   Kang ZQ, 2020, COMPUT IND ENG, V149, DOI 10.1016/j.cie.2020.106773.
   Khan MA, 2020, IEEE ACCESS, V8, P176598, DOI 10.1109/ACCESS.2020.3027152.
   Kim JB, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20123401.
   Kim YL, 2020, ROBOT CIM-INT MANUF, V62, DOI 10.1016/j.rcim.2019.101863.
   Kuhnle A, 2020, SIMRLFAB SIMULATION.
   Kuhnle A, 2021, J INTELL MANUF, V32, P855, DOI 10.1007/s10845-020-01612-y.
   Kuhnle A, 2019, PROD ENG-RES DEV, V13, P33, DOI 10.1007/s11740-018-0855-7.
   Kumar A, 2020, J INTELL MANUF, V31, P1795, DOI 10.1007/s10845-020-01562-5.
   Lammle Arik., 2020, PROCEDIA CIRP, V93, P1061, DOI {[}10.1016/j.procir.2020.04.153, DOI 10.1016/J.PROCIR.2020.04.153].
   Lange S, 2012, IEEE IJCNN.
   Lee JH, 2018, COMPUT CHEM ENG, V114, P111, DOI 10.1016/j.compchemeng.2017.10.008.
   Lee JH, 2022, INT J PROD RES, V60, P2346, DOI 10.1080/00207543.2021.1887533.
   Lee S, 2020, SUSTAINABILITY-BASEL, V12, DOI 10.3390/su12208718.
   Lei L, 2020, IEEE COMMUN SURV TUT, V22, P1722, DOI 10.1109/COMST.2020.2988367.
   Leng JW, 2021, J CLEAN PROD, V280, DOI 10.1016/j.jclepro.2020.124405.
   Leng JL, 2020, J MANUF SYST, V56, P175, DOI 10.1016/j.jmsy.2020.06.001.
   Li BR, 2020, ROBOT CIM-INT MANUF, V61, DOI 10.1016/j.rcim.2019.101847.
   Li FM, 2020, IEEE ACCESS, V8, P6282, DOI 10.1109/ACCESS.2019.2934174.
   Li FM, 2019, NEUROCOMPUTING, V345, P92, DOI 10.1016/j.neucom.2019.01.087.
   Li JN, 2020, IEEE T CYBERNETICS, V50, P4132, DOI 10.1109/TCYB.2019.2950262.
   Liang HG, 2021, ROBOT CIM-INT MANUF, V67, DOI 10.1016/j.rcim.2020.101991.
   Liao HG, 2020, J MECH DESIGN, V142, DOI 10.1115/1.4045044.
   Liao YX, 2017, INT J PROD RES, V55, P3609, DOI 10.1080/00207543.2017.1308576.
   Light RJ., 1984, SUMMING SCI REV RES.
   Lillicrap T.P., 2015, ARXIV PREPRINT ARXIV.
   Lin CC, 2019, IEEE T IND INFORM, V15, P4276, DOI 10.1109/TII.2019.2908210.
   Liu CL, 2020, IEEE ACCESS, V8, P71752, DOI 10.1109/ACCESS.2020.2987820.
   Liu X, 2021, COMPUT COMMUN, V168, P20, DOI 10.1016/j.comcom.2020.12.013.
   Liu Xing., 2019, 2019 IEEE INT C IND.
   Liu Y, 2020, EUR J OPER RES, V283, P166, DOI 10.1016/j.ejor.2019.10.049.
   Lohmer J, 2021, INT J PROD RES, V59, P2028, DOI 10.1080/00207543.2020.1797207.
   Lu RZ, 2020, APPL ENERG, V276, DOI 10.1016/j.apenergy.2020.115473.
   Lu XL, 2016, IET CONTROL THEORY A, V10, P1348, DOI 10.1049/iet-cta.2015.0798.
   Luo JL, 2019, IEEE INT CONF ROBOT, P3080, DOI 10.1109/ICRA.2019.8793506.
   Luo JL, 2018, IEEE INT C INT ROBOT, P2062, DOI 10.1109/IROS.2018.8594353.
   Luo S, 2020, APPL SOFT COMPUT, V91, DOI 10.1016/j.asoc.2020.106208.
   Luong NC, 2019, IEEE COMMUN SURV TUT, V21, P3133, DOI 10.1109/COMST.2019.2916583.
   Ma Y, 2019, J PROCESS CONTR, V75, P40, DOI 10.1016/j.jprocont.2018.11.004.
   Mahadevan S., 1998, FLAIRS-98. Proceedings of the Eleventh International Florida Artificial Intelligence Research Symposium Conference, P372.
   Malus A, 2020, CIRP ANN-MANUF TECHN, V69, P397, DOI 10.1016/j.cirp.2020.04.001.
   Masinelli G, 2020, IEEE ACCESS, V8, P103803, DOI 10.1109/ACCESS.2020.2998052.
   Mazgualdi ChoumichaEl., 2021, ARTIFICIAL INTELLIGE, V1193, P77.
   Miljkovic Z, 2013, EXPERT SYST APPL, V40, P1721, DOI 10.1016/j.eswa.2012.09.010.
   Mishra M, 2020, ENG APPL ARTIF INTEL, V96, DOI 10.1016/j.engappai.2020.104000.
   Mnih V., 2013, PROC 27 C NEURAL INF, P1.
   Mohammed MQ, 2020, IEEE ACCESS, V8, P178450, DOI 10.1109/ACCESS.2020.3027923.
   Mosavi A, 2020, MATHEMATICS-BASEL, V8, DOI 10.3390/math8101640.
   Naeem M, 2020, IEEE ACCESS, V8, P209320, DOI 10.1109/ACCESS.2020.3038605.
   Noel MM, 2014, APPL SOFT COMPUT, V23, P444, DOI 10.1016/j.asoc.2014.06.037.
   Oh TH, 2020, INT J CONTROL AUTOM, V18, P2983, DOI 10.1007/s12555-020-0153-y.
   Palombarini J. A., 2018, 2018 IEEE BIENN C AR, P1.
   Palombarini JA, 2019, IFAC PAPERSONLINE, V52, P231, DOI 10.1016/j.ifacol.2019.06.067.
   Pandian BJ, 2018, CHEM PROD PROCESS MO, V13, DOI 10.1515/cppm-2017-0040.
   Park IB, 2020, IEEE T AUTOM SCI ENG, V17, P1420, DOI 10.1109/TASE.2019.2956762.
   Park J, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20216183.
   Park J, 2021, INT J PROD RES, V59, P3360, DOI 10.1080/00207543.2020.1870013.
   Peres RS, 2020, IEEE ACCESS, V8, P220121, DOI 10.1109/ACCESS.2020.3042874.
   Petticrew M, 2006, SYSTEMATIC REVIEWS IN THE SOCIAL SCIENCES: A PRACTICAL GUIDE, P1, DOI 10.1002/9780470754887.
   Powell BKM, 2020, COMPUT CHEM ENG, V143, DOI 10.1016/j.compchemeng.2020.107077.
   Quah T, 2020, PROCESSES, V8, DOI 10.3390/pr8111497.
   Riedmiller S, 1999, IJCAI-99: PROCEEDINGS OF THE SIXTEENTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, VOLS 1 \& 2, P764.
   Rummukainen H, 2019, IFAC PAPERSONLINE, V52, P1415, DOI 10.1016/j.ifacol.2019.11.397.
   Samsonov V, 2020, PROCEEDINGS OF THE 22ND INTERNATIONAL CONFERENCE ON ENTERPRISE INFORMATION SYSTEMS (ICEIS), VOL 1, P506, DOI 10.5220/0009354105060514.
   Schaul T., 2016, INT C LEARN REPR SAN.
   Scheiderer Christian., 2019, PROCEDIA MANUFACTURI, V38, P423, DOI {[}10.1016/j.promfg.2020.01.054, DOI 10.1016/J.PROMFG.2020.01.054].
   Schmidt, 2020, 3 INT C APPL INT SYS, P1, DOI {[}10.1145/3378184.3378198, DOI 10.1145/3378184.3378198].
   Schoettler Gerrit., 2020, 2020 IEEE RSJ INT C, DOI {[}10.1109/IROS45743.2020.9341714, DOI 10.1109/IROS45743.2020.9341714].
   Serin G, 2020, INT J ADV MANUF TECH, V109, P953, DOI 10.1007/s00170-020-05449-w.
   Sewak M., 2019, DEEP REINFORCEMENT L.
   Sewak M., 2019, DEEP REINFORCEMENT L, P127.
   Shi DM, 2020, INT J PROD RES, V58, P3362, DOI 10.1080/00207543.2020.1717008.
   Shufang X., 2019, SIMULATION PRODUKTIO, P59.
   Shyalika C., 2020, SN COMPUTER SCI, V1, P306.
   Silver D., 2017, ARXIV171201815.
   Skordilis E, 2020, COMPUT IND ENG, V147, DOI 10.1016/j.cie.2020.106600.
   Spielberg SPK, 2017, 2017 6TH INTERNATIONAL SYMPOSIUM ON ADVANCED CONTROL OF INDUSTRIAL PROCESSES (ADCONIP), P201, DOI 10.1109/ADCONIP.2017.7983780.
   Spielberg S, 2019, AICHE J, V65, DOI 10.1002/aic.16689.
   Stricker N, 2018, CIRP ANN-MANUF TECHN, V67, P511, DOI 10.1016/j.cirp.2018.04.041.
   Sutton RS, 2018, ADAPT COMPUT MACH LE, P1.
   Szarski Martin., 2021, COMPOS PART A-APPL S, V142, P106, DOI {[}10.1016/j.compositesa.2020.106235, DOI 10.1016/J.COMPOSITESA.2020.106235].
   Tang J.K.T., 2015, P 17 EUR C INF SYST, P77, DOI 10.1007/978-3-319-21323-1\_5.
   Thome AMT, 2016, PROD PLAN CONTROL, V27, P408, DOI 10.1080/09537287.2015.1129464.
   Tewari A, 2020, COMPUT CHEM ENG, V141, DOI 10.1016/j.compchemeng.2020.106988.
   Thun Timo., 2020, PROCEDIA MANUFACTURI, V51, P897, DOI {[}10.1016/j.promfg.2020.10.126, DOI 10.1016/J.PROMFG.2020.10.126].
   Tome Silva., 2019, PROCEDIA MANUFACTURI, V38, P194, DOI {[}10.1016/j.promfg.2020.01.026, DOI 10.1016/J.PROMFG.2020.01.026].
   Tranfield D, 2003, BRIT J MANAGE, V14, P207, DOI 10.1111/1467-8551.00375.
   Tsai YT, 2020, J MANUF SYST, V56, P501, DOI 10.1016/j.jmsy.2020.07.001.
   Van Hasselt H., 2016, P AAAI C ART INT, V30.
   Wang F, 2020, IEEE-ASME T MECH, V25, P2574, DOI 10.1109/TMECH.2020.2997799.
   Wang HN, 2020, FRONT INFORM TECH EL, V21, P1726, DOI 10.1631/FITEE.1900533.
   Wang HX, 2021, INT J PROD RES, V59, P5867, DOI 10.1080/00207543.2020.1794075.
   Wang JP, 2019, IEEE T IND INFORM, V15, P2395, DOI 10.1109/TII.2018.2881266.
   Wang Kaixin., 2020, 34 C NEUR INF PROC S.
   Waschneck B, 2018, PROC CIRP, V72, P1264, DOI 10.1016/j.procir.2018.03.212.
   Waschneck B, 2018, ASMC PROC, P301, DOI 10.1109/ASMC.2018.8373191.
   Wasmer K, 2019, J MATER ENG PERFORM, V28, P666, DOI 10.1007/s11665-018-3690-2.
   Watanabe K, 2020, INT J PROD ECON, V226, DOI 10.1016/j.ijpe.2020.107615.
   WATKINS CJCH, 1992, MACH LEARN, V8, P279, DOI 10.1007/bf00992698.
   Webster J, 2002, MIS QUART, V26, pXIII.
   Wei Zhang, 1995, IJCAI-95. Proceedings of the Fourteenth International Joint Conference on Artificial Intelligence, P1114.
   Wenqing Hu, 2019, Procedia Manufacturing, V39, P1242, DOI 10.1016/j.promfg.2020.01.345.
   Wu CX, 2020, APPL SOFT COMPUT, V97, DOI 10.1016/j.asoc.2020.106790.
   Wu WB, 2021, J MANUF SYST, V58, P392, DOI 10.1016/j.jmsy.2020.12.015.
   Xanthopoulos AS, 2018, IEEE ACCESS, V6, DOI 10.1109/ACCESS.2017.2771827.
   Xia KS, 2021, J MANUF SYST, V58, P210, DOI 10.1016/j.jmsy.2020.06.012.
   Xiong H, 2021, NEUROCOMPUTING, V422, P12, DOI 10.1016/j.neucom.2020.09.055.
   Xu J, 2019, IEEE T IND INFORM, V15, P1658, DOI 10.1109/TII.2018.2868859.
   Xu LD, 2018, INT J PROD RES, V56, P2941, DOI 10.1080/00207543.2018.1444806.
   Xu Xinghai., 2020, 2020 IEEE 9 DAT DRIV.
   Yang HL, 2020, IEEE T IND INFORM, V16, P5565, DOI 10.1109/TII.2019.2933867.
   Yoo H, 2021, COMPUT CHEM ENG, V144, DOI 10.1016/j.compchemeng.2020.107133.
   Yu JB, 2020, IEEE T SEMICONDUCT M, V33, P454, DOI 10.1109/TSM.2020.3002896.
   Yu T, 2020, IEEE ACCESS, V8, P163868, DOI 10.1109/ACCESS.2020.3021904.
   Zhang NL, 2020, RELIAB ENG SYST SAFE, V203, DOI 10.1016/j.ress.2020.107094.
   Zhang Tai., 2020, 2020 2 INT C IND ART.
   Zhao MH, 2020, ASSEMBLY AUTOM, V40, P65, DOI 10.1108/AA-11-2018-0211.
   Zhao X, 2020, INT J INTELL ROBOT, V4, P202, DOI 10.1007/s41315-020-00138-z.
   Zheng S, 2020, LECT NOTES ARTIF INT, V11908, P655, DOI 10.1007/978-3-030-46133-1\_39.
   Zhou L., 2020, PROCEDIA CIRP, V93, P383, DOI {[}10.1016/j.procir.2020.05.163, DOI 10.1016/J.PROCIR.2020.05.163].
   Zhou T, 2021, IEEE ACCESS, V9, P752, DOI 10.1109/ACCESS.2020.3046784.
   Zhou Y, 2021, J MANUF SYST, V58, P22, DOI 10.1016/j.jmsy.2020.06.019.
   Zhou ZP, 2017, ACS CENTRAL SCI, V3, P1337, DOI 10.1021/acscentsci.7b00492.
   Zhu HY, 2020, IEEE ACCESS, V8, P9987, DOI 10.1109/ACCESS.2020.2964955.
   Zhu K, 2020, IEEE ACCESS, V8, P226784, DOI 10.1109/ACCESS.2020.3045905.
   Zimmerling Clemens, 2020, Procedia Manufacturing, V47, P847, DOI 10.1016/j.promfg.2020.04.263.
   Zou YB, 2020, IEEE T INSTRUM MEAS, V69, P4270, DOI 10.1109/TIM.2019.2942533.},
Number-of-Cited-References = {173},
Times-Cited = {2},
Usage-Count-Last-180-days = {49},
Usage-Count-Since-2013 = {64},
Journal-ISO = {Int. J. Prod. Res.},
Doc-Delivery-Number = {UR6LI},
Web-of-Science-Index = {Science Citation Index Expanded (SCI-EXPANDED)},
Unique-ID = {WOS:000696858100001},
OA = {hybrid},
DA = {2022-04-30},
}

@article{ WOS:000567911600037,
Author = {Zhang, Nailong and Si, Wujun},
Title = {Deep reinforcement learning for condition-based maintenance planning of
   multi-component systems under dependent competing risks},
Journal = {RELIABILITY ENGINEERING \& SYSTEM SAFETY},
Year = {2020},
Volume = {203},
Month = {NOV},
Abstract = {Condition-Based Maintenance (CBM) planning for multi-component systems
   has been receiving increasing attention in recent years. Most existing
   research on CBM assumes that preventive maintenances should be conducted
   when the degradations of system components reach specific threshold
   levels upon inspection. However, the search of optimal maintenance
   threshold levels is often efficient for low-dimensional CBM but becomes
   challenging if the number of components gets large, especially when
   those components are subject to complex dependencies. To overcome the
   challenge, in this paper we propose a novel and flexible CBM model based
   on a customized deep reinforcement learning for multi-component systems
   with dependent competing risks. Both stochastic and economic
   dependencies among the components are considered. Specifically,
   different from the threshold-based decision making paradigm used in
   traditional CBM, the proposed model directly maps the multi-component
   degradation measurements at each inspection epoch to the maintenance
   decision space with a cost minimization objective, and the leverage of
   deep reinforcement learning enables high computational efficiencies and
   thus makes the proposed model suitable for both low and high dimensional
   CBM. Various numerical studies are conducted for model validations.},
Publisher = {ELSEVIER SCI LTD},
Address = {THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, OXON, ENGLAND},
Type = {Article},
Language = {English},
Affiliation = {Zhang, NL (Corresponding Author), Massachusetts Mutual Life Insurance Co, New York, NY 10010 USA.
   Zhang, Nailong, Massachusetts Mutual Life Insurance Co, New York, NY 10010 USA.
   Si, Wujun, Wichita State Univ, Dept Ind Syst \& Mfg Engn, Wichita, KS 67260 USA.},
DOI = {10.1016/j.ress.2020.107094},
Article-Number = {107094},
ISSN = {0951-8320},
EISSN = {1879-0836},
Keywords = {Maintenance; Markov decision process; Deep Q network; Failure
   dependency; Cost minimization},
Keywords-Plus = {OPPORTUNISTIC MAINTENANCE; GAMMA PROCESS; DEGRADATION; OPTIMIZATION;
   NETWORK; MODELS; POLICY},
Research-Areas = {Engineering; Operations Research \& Management Science},
Web-of-Science-Categories  = {Engineering, Industrial; Operations Research \& Management Science},
Author-Email = {eo9364@wayne.edu
   wujun.si@wichita.edu},
Cited-References = {ahuitl Cuay, 2017, DIALOGUES SOCIAL ROB, P109, DOI DOI 10.1007/978-981-10-2585-3\_8.
   Alaswad S, 2017, RELIAB ENG SYST SAFE, V157, P54, DOI 10.1016/j.ress.2016.08.009.
   Andrzejczak K., 2015, J KONBIN, V35, P5.
   Atallah RF, 2019, IEEE T INTELL TRANSP, V20, P1669, DOI 10.1109/TITS.2018.2832219.
   Bhagat S, 2019, ROBOTICS, V8, DOI 10.3390/robotics8010004.
   Chen N, 2015, EUR J OPER RES, V243, P190, DOI 10.1016/j.ejor.2014.11.029.
   Chen N, 2011, INT J PROD RES, V49, P2083, DOI 10.1080/00207541003694811.
   Cheng TJ, 2012, RELIAB ENG SYST SAFE, V108, P65, DOI 10.1016/j.ress.2012.06.005.
   de Jonge B, 2020, EUR J OPER RES, V285, P805, DOI 10.1016/j.ejor.2019.09.047.
   de Jonge B, 2017, RELIAB ENG SYST SAFE, V158, P21, DOI 10.1016/j.ress.2016.10.002.
   Dhillon B.S., 2002, ENG MAINTENANCE MODE.
   Dieulle L, 2003, EUR J OPER RES, V150, P451, DOI 10.1016/S0377-2217(02)00593-3.
   Ding FF, 2011, INT J RELIAB QUAL SA, V18, P463, DOI 10.1142/S0218539311004196.
   Ding FF, 2012, RENEW ENERG, V45, P175, DOI 10.1016/j.renene.2012.02.030.
   Grall A, 2002, RELIAB ENG SYST SAFE, V76, P167, DOI 10.1016/S0951-8320(01)00148-X.
   Hsieh MH, 2007, IEEE T RELIAB, V56, P369, DOI 10.1109/TR.2007.903276.
   Keizer MCAO, 2017, EUR J OPER RES, V261, P405, DOI 10.1016/j.ejor.2017.02.044.
   Huynh KT, 2015, IEEE T RELIAB, V64, P94, DOI 10.1109/TR.2014.2337791.
   Koochaki J, 2012, INT J PROD RES, V50, P6918, DOI 10.1080/00207543.2011.636924.
   Lawless J, 2004, LIFETIME DATA ANAL, V10, P213, DOI 10.1023/B:LIDA.0000036389.14073.dd.
   Li HP, 2016, RELIAB ENG SYST SAFE, V149, P44, DOI 10.1016/j.ress.2015.12.011.
   Li WJ, 2005, IEEE T RELIAB, V54, P318, DOI 10.1109/TR.2005.847264.
   Liao HT, 2006, EUR J OPER RES, V175, P821, DOI 10.1016/j.ejor.2005.05.017.
   Lin YH, 2015, IEEE T FUZZY SYST, V23, P1428, DOI 10.1109/TFUZZ.2014.2362145.
   Liu B, 2020, IEEE T AUTOM SCI ENG, V17, P177, DOI 10.1109/TASE.2019.2918734.
   Liu B, 2017, EUR J OPER RES, V263, P879, DOI 10.1016/j.ejor.2017.05.006.
   Liu QM, 2015, IND MANAGE DATA SYST, V115, P1412, DOI 10.1108/IMDS-04-2015-0150.
   Do P, 2019, RELIAB ENG SYST SAFE, V182, P86, DOI 10.1016/j.ress.2018.10.007.
   Puterman M.L., 2005, MARKOV DECISION PROC, DOI DOI 10.1002/9780470316887.
   Rasmekomen N, 2016, RELIAB ENG SYST SAFE, V148, P1, DOI 10.1016/j.ress.2015.11.010.
   Shahraki AF, 2020, RELIAB ENG SYST SAFE, V196, DOI 10.1016/j.ress.2019.106738.
   Shakeel PM, 2018, J MED SYST, V42, DOI 10.1007/s10916-018-1045-z.
   Sutton RS, 2018, ADAPT COMPUT MACH LE, P1.
   Tian ZG, 2011, RELIAB ENG SYST SAFE, V96, P581, DOI 10.1016/j.ress.2010.12.023.
   Tseng HH, 2017, MED PHYS, V44, P6690, DOI 10.1002/mp.12625.
   Van Horenbeek A, 2013, RELIAB ENG SYST SAFE, V120, P39, DOI 10.1016/j.ress.2013.02.029.
   Verbert K, 2017, RELIAB ENG SYST SAFE, V159, P310, DOI 10.1016/j.ress.2016.10.032.
   Wang XL, 2020, IEEE T RELIAB, V69, P1480, DOI 10.1109/TR.2020.2983415.
   WATKINS CJCH, 1992, MACH LEARN, V8, P279, DOI 10.1007/bf00992698.
   Wei SY, 2020, STRUCT SAF, V83, DOI 10.1016/j.strusafe.2019.101906.
   Wu JD, 2018, APPL ENERG, V222, P799, DOI 10.1016/j.apenergy.2018.03.104.
   Zhang NL, 2015, IIE TRANS, V47, P521, DOI 10.1080/0740817X.2014.974115.},
Number-of-Cited-References = {42},
Times-Cited = {19},
Usage-Count-Last-180-days = {17},
Usage-Count-Since-2013 = {70},
Journal-ISO = {Reliab. Eng. Syst. Saf.},
Doc-Delivery-Number = {NM2DB},
Web-of-Science-Index = {Science Citation Index Expanded (SCI-EXPANDED)},
Unique-ID = {WOS:000567911600037},
DA = {2022-04-30},
}

@article{ WOS:000652593100323,
Author = {Martins, Miguel S. E. and Viegas, Joaquim L. and Coito, Tiago and Firme,
   Bernardo Marreiros and Sousa, Joao M. C. and Figueiredo, Joao and
   Vieira, Susana M.},
Title = {Reinforcement Learning for Dual-Resource Constrained Scheduling},
Journal = {IFAC PAPERSONLINE},
Year = {2020},
Volume = {53},
Number = {2},
Pages = {10810-10815},
Note = {21st IFAC World Congress on Automatic Control - Meeting Societal
   Challenges, ELECTR NETWORK, JUL 11-17, 2020},
Organization = {Int Federat Automat Control; Siemens; Bayer; ABB; MathWorks; Phoenix
   Contact; Ifak Technol; Berlin Heart; Elsevier; De Gruyter; Tele Medi
   GmbH},
Abstract = {This paper proposes using reinforcement learning to solve scheduling
   problems where two types of resources of limited availability must be
   allocated. The goal is to minimize the makespan of a dual-resource
   constrained flexible job shop scheduling problem. Efficient practical
   implementation is very valuable to industry, yet it is often only solved
   combining heuristics and expert knowledge. A framework for training a
   reinforcement learning agent to schedule diverse dual-resource
   constrained job shops is presented. Comparison with other
   state-of-the-art approaches is done on both simpler and more complex
   instances that the ones used for training. Results show the agent
   produces competitive solutions for small instances that can outperform
   the implemented heuristic if given enough time. Other extensions are
   needed before real-world deployment, such as deadlines and constraining
   resources to work shifts. Copyright (C) 2020 The Authors.},
Publisher = {ELSEVIER},
Address = {RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS},
Type = {Proceedings Paper},
Language = {English},
Affiliation = {Martins, MSE (Corresponding Author), Univ Lisbon, Inst Super Tecn, IDMEC, Lisbon, Portugal.
   Martins, Miguel S. E.; Viegas, Joaquim L.; Coito, Tiago; Firme, Bernardo Marreiros; Sousa, Joao M. C.; Vieira, Susana M., Univ Lisbon, Inst Super Tecn, IDMEC, Lisbon, Portugal.
   Figueiredo, Joao, Univ Evora, Dept Phys, Evora, Portugal.},
DOI = {10.1016/j.ifacol.2020.12.2866},
ISSN = {2405-8963},
Keywords = {Production planning and control; Job and activity scheduling;
   Intelligent manufacturing systems},
Research-Areas = {Automation \& Control Systems},
Web-of-Science-Categories  = {Automation \& Control Systems},
Author-Email = {miguelsemartins@tecnico.ulisboa.pt
   joaquim.viegas@tecnico.ulisboa.pt
   liagoascoito@tecnico.ulisboa.pt
   bernardo.firme@tecnico.ulisboa.pt
   jmsousa@tecnico.ulisboa.pt
   jfig@uevora.pl
   susana.vieira@tecnico.ulisboa.pt},
Funding-Acknowledgement = {FCT, through IDMEC, under LAETA {[}UIDP/50022/2020]},
Funding-Text = {This work was supported by FCT, through IDMEC, under LAETA, project
   UIDP/50022/2020},
Cited-References = {Araz OU, 2005, LECT NOTES ARTIF INT, V3809, P1047.
   Dhiflaoui M, 2018, PROCEDIA COMPUT SCI, V126, P1507, DOI 10.1016/j.procs.2018.08.123.
   Ham A, 2018, IEEE T SEMICONDUCT M, V31, P52, DOI 10.1109/TSM.2017.2768899.
   Jain AS, 1999, EUR J OPER RES, V113, P390, DOI 10.1016/S0377-2217(98)00113-1.
   Nouri HE, 2016, APPL INTELL, V45, P808, DOI 10.1007/s10489-016-0786-y.
   Pinedo ML, 2009, PLANNING AND SCHEDULING IN MANUFACTURING AND SERVICES, SECOND EDITION, P3, DOI 10.1007/978-1-4419-0910-7\_1.
   Ren HY, 2009, 2009 INTERNATIONAL ASIA CONFERENCE ON INFORMATICS IN CONTROL, AUTOMATION, AND ROBOTICS, PROCEEDINGS, P485, DOI 10.1109/CAR.2009.113.
   Shen LJ, 2018, EUR J OPER RES, V265, P503, DOI 10.1016/j.ejor.2017.08.021.
   Sutton RS, 2018, ADAPT COMPUT MACH LE, P1.
   Vieira S.M., 2019, IFAC PAPERSONLINE, V6.
   Vieira S.M., 2019, 30 EUR C OP RES.
   Zhang W., 2000, J ARTIF INTELL RES, V1.},
Number-of-Cited-References = {12},
Times-Cited = {0},
Usage-Count-Last-180-days = {7},
Usage-Count-Since-2013 = {11},
Journal-ISO = {IFAC PAPERSONLINE},
Doc-Delivery-Number = {SF2LQ},
Web-of-Science-Index = {Conference Proceedings Citation Index - Science (CPCI-S)},
Unique-ID = {WOS:000652593100323},
OA = {Green Submitted, gold},
DA = {2022-04-30},
}

@article{ WOS:000591604000030,
Author = {Dittrich, Marc-Andre and Fohlmeister, Silas},
Title = {Cooperative multi-agent system for production control using
   reinforcement learning},
Journal = {CIRP ANNALS-MANUFACTURING TECHNOLOGY},
Year = {2020},
Volume = {69},
Number = {1},
Pages = {389-392},
Abstract = {Multi-agent systems can limit the control problem in complex production
   systems and solve them more efficiently. However, they often show local
   optimization tendencies. This paper presents a novel approach for a
   cooperative multi-agent system, which uses reinforcement learning and
   considers global key performance indicators. For this purpose, a central
   deep q-learning module transfers its knowledge to the cooperative order
   agents. The order agent's experience is stored in a replay memory for
   subsequent reinforcement learning. Interdependencies between the
   characteristics of nonlinear production systems and learning parameters
   are investigated and the performance is evaluated in comparison to
   conventional methods of production control. (C) 2020 CIRP. Published by
   Elsevier Ltd. All rights reserved.},
Publisher = {ELSEVIER},
Address = {RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS},
Type = {Article},
Language = {English},
Affiliation = {Dittrich, MA (Corresponding Author), Leibniz Univ Hannover, Inst Prod Engn \& Machine Tools IFW, Hannover, Germany.
   Dittrich, Marc-Andre; Fohlmeister, Silas, Leibniz Univ Hannover, Inst Prod Engn \& Machine Tools IFW, Hannover, Germany.},
DOI = {10.1016/j.cirp.2020.04.005},
ISSN = {0007-8506},
EISSN = {1726-0604},
Keywords = {Production planning; Machine learning; Multi-agent system},
Research-Areas = {Engineering},
Web-of-Science-Categories  = {Engineering, Industrial; Engineering, Manufacturing},
Author-Email = {dittrich@ifw.uni-hannover.de},
ORCID-Numbers = {Dittrich, Marc-Andre/0000-0001-6481-5637},
Funding-Acknowledgement = {German Research Foundation (DFG)German Research Foundation (DFG) {[}DE
   447/181-1]},
Funding-Text = {The presented investigations were conducted within the research project
   DE 447/181-1. We would like to thank the German Research Foundation
   (DFG) for the support of this project. In addition, we would like to
   thank Berend Denkena for his valuable comments and his support.},
Cited-References = {ElMaraghy H, 2013, CIRP ANN-MANUF TECHN, V62, P629, DOI 10.1016/j.cirp.2013.05.007.
   Freitag M, 2016, CIRP ANN-MANUF TECHN, V65, P433, DOI 10.1016/j.cirp.2016.04.066.
   Glorot X., 2011, P MACH LEARN RES PML, P315.
   HORNIK K, 1991, NEURAL NETWORKS, V4, P251, DOI 10.1016/0893-6080(91)90009-T.
   Leitao P, 2009, ENG APPL ARTIF INTEL, V22, P979, DOI 10.1016/j.engappai.2008.09.005.
   Lodding H., 2013, HDB MANUFACTURING CO.
   Mnih V, 2015, NATURE, V518, P529, DOI 10.1038/nature14236.
   Monostori L, 2006, CIRP ANN-MANUF TECHN, V55, P697, DOI 10.1016/j.cirp.2006.10.004.
   Monostori L, 2016, CIRP ANN-MANUF TECHN, V65, P621, DOI 10.1016/j.cirp.2016.06.005.
   Schuh G, 2017, CIRP ANN-MANUF TECHN, V66, P425, DOI 10.1016/j.cirp.2017.04.003.
   Stricker N, 2018, CIRP ANN-MANUF TECHN, V67, P511, DOI 10.1016/j.cirp.2018.04.041.
   Sutton R. S., 1998, REINFORCEMENT LEARNI.
   Vrabic R, 2018, CIRP ANN-MANUF TECHN, V67, P507, DOI 10.1016/j.cirp.2018.04.037.
   Waschneck B, 2018, PROC CIRP, V72, P1264, DOI 10.1016/j.procir.2018.03.212.
   Williamson DP, 1997, OPER RES, V45, P288, DOI 10.1287/opre.45.2.288.
   Wooldridge M., 2002, INTRO MULTIAGENT SYS.},
Number-of-Cited-References = {16},
Times-Cited = {8},
Usage-Count-Last-180-days = {9},
Usage-Count-Since-2013 = {21},
Journal-ISO = {CIRP Ann-Manuf. Technol.},
Doc-Delivery-Number = {OU5YK},
Web-of-Science-Index = {Science Citation Index Expanded (SCI-EXPANDED)},
Unique-ID = {WOS:000591604000030},
DA = {2022-04-30},
}

@article{ WOS:000425675300003,
Author = {Xanthopoulos, A. S. and Kiatipis, Athanasios and Koulouriotis, D. E. and
   Stieger, Sepp},
Title = {Reinforcement Learning-Based and Parametric Production-Maintenance
   Control Policies for a Deteriorating Manufacturing System},
Journal = {IEEE ACCESS},
Year = {2018},
Volume = {6},
Abstract = {The model of a stochastic production/inventory system that is subject to
   deterioration failures is developed and examined in this paper. Customer
   interarrival times are assumed to be random and backorders are allowed.
   The system experiences a number of deterioration stages before it
   ultimately fails and is rendered inoperable. Repair and maintenance
   activities restore the system to its initial and previous deterioration
   state, respectively. The duration of both repair and maintenance is
   assumed to be stochastic. We address the problem of minimizing the
   expected sum of two conflicting objective functions: the average
   inventory level and the average number of backorders. The solution to
   this problem consists of finding the optimal tradeoff between
   maintaining a high service level and carrying as low inventory as
   possible. The primary goal of this research is to obtain optimal or
   near-optimal joint production/maintenance control policies, by means of
   a novel reinforcement learning-based approach. Furthermore, we examine
   parametric production and maintenance policies that are often used in
   practical situations, namely, Kanban, (s, S), threshold-type condition
   based maintenance and periodic maintenance. The proposed approach is
   compared with the parametric policies in an extensive series of
   simulation experiments and it is found to clearly outperform them in all
   cases. Based on the numerical results obtained by the experiments, the
   behavior of the parametric policies as well as the structure of the
   control policies derived by the Reinforcement Learning-based approach is
   investigated.},
Publisher = {IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC},
Address = {445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA},
Type = {Article},
Language = {English},
Affiliation = {Kiatipis, A (Corresponding Author), Fujitsu Technol Solut GmbH, D-80807 Munich, Germany.
   Xanthopoulos, A. S.; Koulouriotis, D. E., Democritus Univ Thrace, Dept Prod \& Management Engn, GR-67100 Xanthi, Greece.
   Kiatipis, Athanasios; Stieger, Sepp, Fujitsu Technol Solut GmbH, D-80807 Munich, Germany.},
DOI = {10.1109/ACCESS.2017.2771827},
ISSN = {2169-3536},
Keywords = {Inventory control; preventive maintenance; reinforcement learning;
   intelligent manufacturing systems},
Keywords-Plus = {PRODUCTION-INVENTORY SYSTEM; PREVENTIVE MAINTENANCE; JOINT OPTIMIZATION;
   FAILURE},
Research-Areas = {Computer Science; Engineering; Telecommunications},
Web-of-Science-Categories  = {Computer Science, Information Systems; Engineering, Electrical \&
   Electronic; Telecommunications},
Author-Email = {athanasios.kiatipis@ts.fujitsu.com},
ResearcherID-Numbers = {Koulouriotis, Dimitrios/AAI-9437-2021
   Kiatipis, Athanasios/ABA-2428-2020
   },
ORCID-Numbers = {Kiatipis, Athanasios/0000-0001-8250-885X
   KOULOURIOTIS, DIMITRIOS/0000-0003-0194-0654},
Funding-Acknowledgement = {European Union through the Marie Sklodowska-Curie Actions
   {[}H2020-MSCA-ITN-2014-642963]},
Funding-Text = {The work of A. Kiatipis and S. Stieger was supported by the BigStorage:
   Storage-Based Convergence Between HPC and Cloud to Handle Big Data
   project from the European Union through the Marie Sklodowska-Curie
   Actions framework under Grant H2020-MSCA-ITN-2014-642963.},
Cited-References = {Axsater S. a., 2015, INVENTORY CONTROL.
   Cai YW, 2013, PROBAB ENG INFORM SC, V27, P209, DOI 10.1017/S0269964812000423.
   Chen DY, 2002, RELIAB ENG SYST SAFE, V76, P43.
   Das TK, 1999, IIE TRANS, V31, P537, DOI 10.1023/A:1007602423336.
   Ruiz-Castro JE, 2014, IEEE T RELIAB, V63, P646, DOI 10.1109/TR.2014.2315922.
   Fallahnezhad MS, 2014, COMMUN STAT-THEOR M, V43, P3302, DOI 10.1080/03610926.2012.694550.
   Geraghty John, 2010, International Journal of Manufacturing Technology and Management, V20, P94, DOI 10.1504/IJMTM.2010.032894.
   Gosavi A, 2004, MACH LEARN, V55, P5, DOI 10.1023/B:MACH.0000019802.64038.6c.
   Hajej Z, 2015, INT J PROD RES, V53, P4694, DOI 10.1080/00207543.2015.1041569.
   He K, 2015, IEEE T RELIAB, V64, P983, DOI 10.1109/TR.2015.2417153.
   Iravani SMR, 2002, IIE TRANS, V34, P423, DOI 10.1023/A:1013596731865.
   Jafary B, 2017, IEEE T RELIAB, V66, P575, DOI 10.1109/TR.2017.2687426.
   Kader B, 2015, IFAC PAPERSONLINE, V48, P2139, DOI 10.1016/j.ifacol.2015.06.405.
   Kyriakidis EG, 2016, COMMUN STAT-THEOR M, V45, P194, DOI 10.1080/03610926.2013.827723.
   Li N, 2015, MATH PROBL ENG, V2015, DOI 10.1155/2015/957970.
   Li N, 2017, IEEE T SYST MAN CY-S, V47, P916, DOI 10.1109/TSMC.2016.2523802.
   Liao GL, 2016, IEEE T SYST MAN CY-S, V46, P1129, DOI 10.1109/TSMC.2015.2465961.
   Nahas N, 2017, J INTELL MANUF, V28, P85, DOI 10.1007/s10845-014-0963-y.
   Schwartz A., 1993, P 10 INT C MACH LEAR, V298, P305.
   Singh S., 1994, P 12 NAT C ART INT, P202.
   Sutton R. S., 1998, REINFORCEMENT LEARNI, V1.
   Wang X, 2016, J INTELL MANUF, V27, P325, DOI 10.1007/s10845-013-0864-5.
   Wolter A, 2016, CENT EUR J OPER RES, V24, P489, DOI 10.1007/s10100-015-0403-x.
   Xanthopoulos AS, 2015, RELIAB ENG SYST SAFE, V142, P111, DOI 10.1016/j.ress.2015.05.008.
   Xanthopoulos AS, 2013, APPL SOFT COMPUT, V13, P4704, DOI 10.1016/j.asoc.2013.07.015.
   Xanthopoulos A.S., 2016, INT J IND ENG COMP, V7, DOI {[}10.5267/j.ijiec.2016.2.002, DOI 10.5267/J.IJIEC.2016.2.002].
   Yao XD, 2005, NAV RES LOG, V52, P668, DOI 10.1002/nav.20107.
   Zhang XH, 2017, EUR J OPER RES, V262, P479, DOI 10.1016/j.ejor.2017.03.019.
   Zhao SX, 2014, IND MANAGE DATA SYST, V114, P162, DOI 10.1108/IMDS-07-2013-0314.},
Number-of-Cited-References = {29},
Times-Cited = {29},
Usage-Count-Last-180-days = {6},
Usage-Count-Since-2013 = {28},
Journal-ISO = {IEEE Access},
Doc-Delivery-Number = {FW9RX},
Web-of-Science-Index = {Science Citation Index Expanded (SCI-EXPANDED)},
Unique-ID = {WOS:000425675300003},
OA = {gold},
DA = {2022-04-30},
}

@article{ WOS:000538691900001,
Author = {Altenmueller, Thomas and Stueker, Tillmann and Waschneck, Bernd and
   Kuhnle, Andreas and Lanza, Gisela},
Title = {Reinforcement learning for an intelligent and autonomous production
   control of complex job-shops under time constraints},
Journal = {PRODUCTION ENGINEERING-RESEARCH AND DEVELOPMENT},
Year = {2020},
Volume = {14},
Number = {3},
Pages = {319-328},
Month = {JUN},
Abstract = {Reinforcement learning (RL) offers promising opportunities to handle the
   ever-increasing complexity in managing modern production systems. We
   apply a Q-learning algorithm in combination with a process-based
   discrete-event simulation in order to train a self-learning,
   intelligent, and autonomous agent for the decision problem of order
   dispatching in a complex job shop with strict time constraints. For the
   first time, we combine RL in production control with strict time
   constraints. The simulation represents the characteristics of complex
   job shops typically found in semiconductor manufacturing. A real-world
   use case from a wafer fab is addressed with a developed and implemented
   framework. The performance of an RL approach and benchmark heuristics
   are compared. It is shown that RL can be successfully applied to manage
   order dispatching in a complex environment including time constraints.
   An RL-agent with a gain function rewarding the selection of the least
   critical order with respect to time-constraints beats heuristic rules
   strictly by picking the most critical lot first. Hence, this work
   demonstrates that a self-learning agent can successfully manage time
   constraints with the agent performing better than the traditional
   benchmark, a time-constraint heuristic combining due date deviations and
   a classical first-in-first-out approach.},
Publisher = {SPRINGER HEIDELBERG},
Address = {TIERGARTENSTRASSE 17, D-69121 HEIDELBERG, GERMANY},
Type = {Article},
Language = {English},
Affiliation = {Altenmuller, T (Corresponding Author), Infineon Technol AG, Campeon 1-12, D-85579 Neubiberg, Germany.
   Altenmueller, Thomas; Stueker, Tillmann; Waschneck, Bernd, Infineon Technol AG, Campeon 1-12, D-85579 Neubiberg, Germany.
   Kuhnle, Andreas; Lanza, Gisela, KIT, Wbk Inst Prod Sci, Kaiserstr 12, D-76131 Karlsruhe, Germany.},
DOI = {10.1007/s11740-020-00967-8},
EarlyAccessDate = {JUN 2020},
ISSN = {0944-6524},
EISSN = {1863-7353},
Keywords = {Complex job shop; Production planning and control; Reinforcement
   learning; Time constraints},
Keywords-Plus = {DESIGN},
Research-Areas = {Engineering},
Web-of-Science-Categories  = {Engineering, Manufacturing},
Author-Email = {thomas.altenmueller@infineon.com
   andreas.kuhnle@kit.edu},
Funding-Acknowledgement = {Projekt DEAL},
Funding-Text = {Open Access funding provided by Projekt DEAL.},
Cited-References = {Bauernhansl T., 2014, IND 4 0 PRODUKTION A.
   Greschke P, 2014, PROC CIRP, V17, P160, DOI 10.1016/j.procir.2014.02.040.
   Kiener S, 2017, PRODUKTIONSMANAGEMEN.
   Klemmt A, 2012, P 2012 WINT SIM C WS, P1, DOI DOI 10.1109/WSC.2012.6465235.
   Knopp S, 2016, THESIS.
   Kuhnle A, 2019, PROC CIRP, V81, P234, DOI 10.1016/j.procir.2019.03.041.
   Kuhnle A, 2019, PROC CIRP, V79, P391, DOI 10.1016/j.procir.2019.02.101.
   Kuhnle A, 2019, PROD ENG-RES DEV, V13, P33, DOI 10.1007/s11740-018-0855-7.
   Lanza G, 2019, CIRP ANN-MANUF TECHN, V68, P823, DOI 10.1016/j.cirp.2019.05.008.
   Lodding H, 2016, VERFAHREN FERTIGUNGS.
   Mnih V, 2015, NATURE, V518, P529, DOI 10.1038/nature14236.
   Monch L., 2013, PRODUCTION PLANNING.
   Plappert Matthias, 2016, KERAS RL.
   Russell I, 2009, AUSTRALAS ACCOUNT BU, V3.
   Silver D, 2017, NATURE, V550, P354, DOI 10.1038/nature24270.
   Stich Volker, 2012, PRODUKTIONSPLANUNG U.
   Stricker N, 2018, CIRP ANN-MANUF TECHN, V67, P511, DOI 10.1016/j.cirp.2018.04.041.
   Sun DS, 2005, ISSM 2005: IEEE International Symposium on Semiconductor Manufacturing, Conference Proceedings, P295, DOI 10.1109/ISSM.2005.1513361.
   Sutton RS, 2018, ADAPT COMPUT MACH LE, P1.
   Waschneck B, 2016, P SAMI40 WORKSH I KN.
   Waschneck B, 2018, ASMC PROC, P301, DOI 10.1109/ASMC.2018.8373191.
   Wiendahl HP, 2007, CIRP ANN-MANUF TECHN, V56, P783, DOI 10.1016/j.cirp.2007.10.003.
   Wiendahl Hans-Peter, 2000, WORTERBUCH PPS DICT.},
Number-of-Cited-References = {23},
Times-Cited = {10},
Usage-Count-Last-180-days = {6},
Usage-Count-Since-2013 = {10},
Journal-ISO = {Prod. Eng.-Res. Dev.},
Doc-Delivery-Number = {LY1JQ},
Web-of-Science-Index = {Emerging Sources Citation Index (ESCI)},
Unique-ID = {WOS:000538691900001},
OA = {hybrid, Green Published},
DA = {2022-04-30},
}

@article{ WOS:000698290700001,
Author = {Yousefi, Nooshin and Tsianikas, Stamatis and Coit, David W.},
Title = {Dynamic maintenance model for a repairable multi-component system using
   deep reinforcement learning},
Journal = {QUALITY ENGINEERING},
Year = {2022},
Volume = {34},
Number = {1},
Pages = {16-35},
Month = {JAN 2},
Abstract = {Using artificial intelligence for maintenance planning is useful for
   many industries to have a smart decision-making tool that delivers the
   best maintenance policy to minimize the expected maintenance costs. In
   this paper, a deep reinforcement learning method is used to provide a
   new dynamic maintenance model for a degrading repairable system subject
   to degradation and random shock. At any time, the degradation level of
   the system can be considered as the state of the system, and based on
   the available actions, it transits to different levels. The gamma
   process is used to formulate the degradation form of the system. The
   maintenance problem is formulated as a Markov decision process, and Deep
   Q learning algorithm is used to solve the problem. For most of the
   models in the literature, the degradation state of the system must be
   discretized. However, discretization of the degradation states brings
   inaccuracy and inefficiency to the model. In this paper, instead of
   discretizing the degradation state, we consider the exact level of
   degradation as the state of the system. The Deep Q learning method tries
   to recognize patterns instead of mapping every state to its best action.
   A neural network is trained during the learning process of the
   algorithm, and it can be used as a decision-making tool for the
   maintenance team to find the best maintenance action based on the
   current degradation level of the system. A numerical example illustrates
   how the deep reinforcement learning algorithm can be applied to find the
   optimal maintenance action at each degradation level.},
Publisher = {TAYLOR \& FRANCIS INC},
Address = {530 WALNUT STREET, STE 850, PHILADELPHIA, PA 19106 USA},
Type = {Article},
Language = {English},
Affiliation = {Yousefi, N (Corresponding Author), Rutgers State Univ, Dept Ind \& Syst Engn, Piscataway, NJ 08854 USA.
   Yousefi, Nooshin; Tsianikas, Stamatis; Coit, David W., Rutgers State Univ, Dept Ind \& Syst Engn, Piscataway, NJ 08854 USA.
   Coit, David W., Tsinghua Univ, Dept Ind Engn, Beijing, Peoples R China.},
DOI = {10.1080/08982112.2021.1977950},
EarlyAccessDate = {SEP 2021},
ISSN = {0898-2112},
EISSN = {1532-4222},
Keywords = {Deep reinforcement learning; Deep Q network; dynamic maintenance; gamma
   process; Markov decision process},
Keywords-Plus = {INVERSE GAUSSIAN PROCESS; RELIABILITY-ANALYSIS; DEGRADATION; OPERATION;
   POLICY},
Research-Areas = {Engineering; Mathematics},
Web-of-Science-Categories  = {Engineering, Industrial; Statistics \& Probability},
Author-Email = {no.yousefi@rutgers.edu},
Funding-Acknowledgement = {National Natural Science Foundation of ChinaNational Natural Science
   Foundation of China (NSFC) {[}71731008]},
Funding-Text = {The third author's work was partially supported by the National Natural
   Science Foundation of China under key project grant 71731008.},
Cited-References = {Bian LK, 2014, IIE TRANS, V46, P470, DOI 10.1080/0740817X.2013.812269.
   Chen N, 2015, EUR J OPER RES, V243, P190, DOI 10.1016/j.ejor.2014.11.029.
   Coit, 2020, I IND SYST ENG C IIS.
   Coit, 2019, ARXIV190300932.
   Correa-Jullian C, 2020, APPL ENERG, V268, DOI 10.1016/j.apenergy.2020.114943.
   Dehghani NL, 2020, IEEE ACCESS, V8, P22324, DOI 10.1109/ACCESS.2020.2969997.
   Dong WJ, 2020, COMPUT IND ENG, V142, DOI 10.1016/j.cie.2020.106359.
   Kharoufeh JP, 2005, IIE TRANS, V37, P533, DOI 10.1080/07408170590929009.
   Kiritsis, 2014, ADV PRODUCTION MANAG.
   Liao H, 2006, NAV RES LOG, V53, P576, DOI 10.1002/nav.20163.
   Liu BZ, 2018, PR IEEE COMP DESIGN, P1, DOI 10.1109/ICCD.2018.00012.
   LU CJ, 1993, TECHNOMETRICS, V35, P161, DOI 10.2307/1269661.
   Mireh S, 2019, INT J QUAL RELIAB MA, V36, DOI 10.1108/IJQRM-04-2018-0100.
   Tuyet NTA, 2018, ENERG CONVERS MANAGE, V157, P86, DOI 10.1016/j.enconman.2017.11.090.
   Huynh NV, 2019, IEEE J SEL AREA COMM, V37, P2603, DOI 10.1109/JSAC.2019.2933889.
   Omshi EM, 2020, EUR J OPER RES, V282, P81, DOI 10.1016/j.ejor.2019.08.050.
   Park C, 2005, LIFETIME DATA ANAL, V11, P511, DOI 10.1007/s10985-005-5237-8.
   Peng WW, 2019, APPL MATH MODEL, V75, P837, DOI 10.1016/j.apm.2019.07.004.
   Peng WW, 2014, RELIAB ENG SYST SAFE, V130, P175, DOI 10.1016/j.ress.2014.06.005.
   Peng Y, 2010, INT J ADV MANUF TECH, V50, P297, DOI 10.1007/s00170-009-2482-0.
   Rocchetta R, 2019, APPL ENERG, V241, P291, DOI 10.1016/j.apenergy.2019.03.027.
   Sabri-Laghaie K, 2016, IEEE T RELIAB, V65, P1271, DOI 10.1109/TR.2016.2570574.
   Shi Y, 2019, IISE TRANS, V51, P999, DOI 10.1080/24725854.2018.1532135.
   Sun B, 2018, IEEE ACCESS, V6, P10581, DOI 10.1109/ACCESS.2018.2799853.
   Sutton RS, 2018, ADAPT COMPUT MACH LE, P1.
   Sutton Richard S, 1998, INTRO REINFORCEMENT, V1st, DOI DOI 10.1109/TNN.1998.712192.
   Tang L, 2006, AEROSP CONF PROC, P3941.
   van Noortwijk JM, 2009, RELIAB ENG SYST SAFE, V94, P2, DOI 10.1016/j.ress.2007.03.019.
   VANNOORTWIJK JM, 1995, EUR J OPER RES, V82, P270, DOI 10.1016/0377-2217(94)00263-C.
   Wang C, 2015, IEEE T POWER DELIVER, V30, P2362, DOI 10.1109/TPWRD.2015.2442291.
   Wang X, 2016, J INTELL MANUF, V27, P325, DOI 10.1007/s10845-013-0864-5.
   Watkins C.J.C.H., 1989, THESIS KINGS COLL CA.
   Xie M., 2018, IND MAINTENANCE RELI, P190.
   Yousefi N, 2020, RELIAB ENG SYST SAFE, V202, DOI 10.1016/j.ress.2020.107005.
   Yousefi N, 2020, QUAL ENG, V32, P388, DOI 10.1080/08982112.2020.1766692.
   Yousefi N, 2020, COMPUT IND ENG, V143, DOI 10.1016/j.cie.2020.106398.
   Yousefi N, 2019, RELIAB ENG SYST SAFE, V192, DOI 10.1016/j.ress.2019.106547.
   Zhou XJ, 2007, RELIAB ENG SYST SAFE, V92, P530, DOI 10.1016/j.ress.2006.01.006.},
Number-of-Cited-References = {38},
Times-Cited = {0},
Usage-Count-Last-180-days = {12},
Usage-Count-Since-2013 = {15},
Journal-ISO = {Qual. Eng.},
Doc-Delivery-Number = {YU2DQ},
Web-of-Science-Index = {Science Citation Index Expanded (SCI-EXPANDED)},
Unique-ID = {WOS:000698290700001},
DA = {2022-04-30},
}

@article{ WOS:000665893400001,
Author = {de Carvalho, Joao Pedro and Dimitrakopoulos, Roussos},
Title = {Integrating Production Planning with Truck-Dispatching Decisions through
   Reinforcement Learning While Managing Uncertainty},
Journal = {MINERALS},
Year = {2021},
Volume = {11},
Number = {6},
Month = {JUN},
Abstract = {This paper presents a new truck dispatching policy approach that is
   adaptive given different mining complex configurations in order to
   deliver supply material extracted by the shovels to the processors. The
   method aims to improve adherence to the operational plan and fleet
   utilization in a mining complex context. Several sources of operational
   uncertainty arising from the loading, hauling and dumping activities can
   influence the dispatching strategy. Given a fixed sequence of extraction
   of the mining blocks provided by the short-term plan, a discrete event
   simulator model emulates the interaction arising from these mining
   operations. The continuous repetition of this simulator and a reward
   function, associating a score value to each dispatching decision,
   generate sample experiences to train a deep Q-learning reinforcement
   learning model. The model learns from past dispatching experience, such
   that when a new task is required, a well-informed decision can be
   quickly taken. The approach is tested at a copper-gold mining complex,
   characterized by uncertainties in equipment performance and geological
   attributes, and the results show improvements in terms of production
   targets, metal production, and fleet management.},
Publisher = {MDPI},
Address = {ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND},
Type = {Article},
Language = {English},
Affiliation = {de Carvalho, JP; Dimitrakopoulos, R (Corresponding Author), McGill Univ, Dept Min \& Mat Engn, COSMO Stochast Mine Planning Lab, 3450 Univ St, Montreal, PQ H3A 0E8, Canada.
   de Carvalho, Joao Pedro; Dimitrakopoulos, Roussos, McGill Univ, Dept Min \& Mat Engn, COSMO Stochast Mine Planning Lab, 3450 Univ St, Montreal, PQ H3A 0E8, Canada.},
DOI = {10.3390/min11060587},
Article-Number = {587},
EISSN = {2075-163X},
Keywords = {truck dispatching; mining equipment uncertainties; orebody uncertainty;
   discrete event simulation; Q-learning},
Keywords-Plus = {MINING COMPLEXES; FLEET MANAGEMENT; OPTIMIZATION; SIMULATION; GO;
   SYSTEMS; LEVEL; GAME},
Research-Areas = {Geochemistry \& Geophysics; Mineralogy; Mining \& Mineral Processing},
Web-of-Science-Categories  = {Geochemistry \& Geophysics; Mineralogy; Mining \& Mineral Processing},
Author-Email = {joao.decarvalho@mail.mcgill.ca
   roussos.dimitrakopoulos@mcgill.ca},
ORCID-Numbers = {de Carvalho, Joao Pedro/0000-0001-7997-7938},
Funding-Acknowledgement = {National Science and Engineering Research Council of Canada (NSERC) CRD
   GrantNatural Sciences and Engineering Research Council of Canada (NSERC)
   {[}CRDPJ 500414-16]; NSERCNatural Sciences and Engineering Research
   Council of Canada (NSERC) {[}239019]; COSMO mining industry consortium;
   AngloGold Ashanti; AngloAmerican; BHP; De Beers; IAMGOLD; Kinross;
   Newmont Mining; Vale},
Funding-Text = {This work is funded by the National Science and Engineering Research
   Council of Canada (NSERC) CRD Grant CRDPJ 500414-16, NSERC Discovery
   Grant 239019, and the COSMO mining industry consortium (AngloGold
   Ashanti, AngloAmerican, BHP, De Beers, IAMGOLD, Kinross, Newmont Mining
   and Vale).},
Cited-References = {Afrapoli A.M., 2019, P 27 INT S MINE PLAN, P255.
   Afrapoli AM, 2019, EUR J OPER RES, V276, P331, DOI 10.1016/j.ejor.2019.01.008.
   Afrapoli AM, 2019, INT J MIN RECLAM ENV, V33, P42, DOI 10.1080/17480930.2017.1336607.
   Alarie S., 2002, INT J SURFACE MINING, V16, P59, DOI {[}10.1076/ijsm.16.1.59.3408, DOI 10.1076/IJSM.16.1.59.3408].
   Azi N, 2012, ANN OPER RES, V199, P103, DOI 10.1007/s10479-011-0991-3.
   Blome MW, 2020, INT J OCCUP SAF ERGO, V26, P112, DOI 10.1080/10803548.2018.1514135.
   Bocewicz G, 2019, ADV INTELL SYST, V853, P157, DOI 10.1007/978-3-319-99996-8\_15.
   Bodon P., 2010, OREBODY MODELLING ST, V17, P277.
   Bodon P., 2018, ADV APPL STRATEGIC M, P251, DOI {[}10.1007/978-3-319-69320-0\_17, DOI 10.1007/978-3-319-69320-0\_17].
   Both C, 2020, OPTIM ENG, V21, P1717, DOI 10.1007/s11081-020-09495-x.
   Chaowasakoo P, 2017, INT J MIN SCI TECHNO, V27, P229, DOI 10.1016/j.ijmst.2017.01.007.
   Chaowasakoo P, 2017, EUR J OPER RES, V261, P1052, DOI 10.1016/j.ejor.2017.02.039.
   Elbrond J., 1987, INT J SURF MIN RECLA, V1, P1, DOI {[}10.1080/09208118708944095, DOI 10.1080/09208118708944095].
   Del Castillo MF, 2019, RESOUR POLICY, V60, P83, DOI 10.1016/j.resourpol.2018.11.019.
   Gendreau M, 1998, FLEET MANAGEMENT AND LOGISTICS, P115.
   Gola A, 2019, NEUROCOMPUTING, V338, P381, DOI 10.1016/j.neucom.2018.05.125.
   Gomez-Hernandez JJ, 2021, MATH GEOSCI, V53, P193, DOI 10.1007/s11004-021-09926-0.
   Goodfellow RC, 2016, APPL SOFT COMPUT, V40, P292, DOI 10.1016/j.asoc.2015.11.038.
   Goovaerts P, 1997, GEOSTATISTICS NATURA.
   Hashemi AS, 2015, LECT N PROD ENG, P213, DOI 10.1007/978-3-319-12301-1\_20.
   Hoerger S, 1999, MIN ENG-LITTLETON, V51, P26.
   Jaoua A, 2009, INT J MIN RECLAM ENV, V23, P51, DOI 10.1080/17480930802351479.
   Jaoua A, 2012, COMPUT IND, V63, P882, DOI 10.1016/j.compind.2012.07.002.
   Kumar A., 2020, ARTIFICIAL INTELLIGE.
   Kumar A, 2020, J INTELL MANUF, V31, P1795, DOI 10.1007/s10845-020-01562-5.
   Law AverillM., 1982, SIMULATION MODELING, V1st ed.
   Levinson Z, 2020, J S AFR I MIN METALL, V120, P231, DOI 10.17159/2411-9717/829/2020.
   Li, 1990, MINING SCI TECHNOLOG, V10, P337, DOI {[}10.1016/0167-9031(90)90543-2, DOI 10.1016/0167-9031(90)90543-2].
   Lin L.J., 1992, TECH REP.
   Matamoros MEV, 2016, EUR J OPER RES, V255, P911, DOI 10.1016/j.ejor.2016.05.050.
   Minniakhmetov I., 2021, MATH GEOSCI, DOI {[}10.1007/s11004-021-09943-z, DOI 10.1007/S11004-021-09943-Z].
   Mnih V, 2015, NATURE, V518, P529, DOI 10.1038/nature14236.
   Mnih Volodymyr, 2016, INT C MACH LEARN, P1928, DOI DOI 10.5555/3045390.3045594.
   Montiel L., 2018, MIN ENG, V70, P48, DOI DOI 10.19150/me.8645.
   Munirathinam M., 1994, INT J SURFACE MINING, V8, P1.
   Niemann-Delius C., 2004, MINE PLANNING EQUIPM, P579.
   Olson, 1986, MIN ENG LITTLETON CO, V38, P1045.
   Paduraru C, 2019, MIN TECHNOL, V128, P129, DOI 10.1080/25726668.2019.1577596.
   Pillac V, 2013, EUR J OPER RES, V225, P1, DOI 10.1016/j.ejor.2012.08.015.
   Pimentel B.S., 2010, INTELLIGENT SYSTEMS, P133, DOI DOI 10.4018/978-1-61520-605-6.CH008.
   Quigley M, 2020, INT J MIN RECLAM ENV, V34, P362, DOI 10.1080/17480930.2019.1658923.
   Remy N., 2009, APPL GEOSTATISTICS S, V9780521514.
   Rossi M.E, 2014, MINERAL RESOURCE EST.
   Saliba Z, 2019, MIN TECHNOL, V128, P216, DOI 10.1080/25726668.2019.1626169.
   Schrittwieser J, 2020, NATURE, V588, P604, DOI 10.1038/s41586-020-03051-4.
   Secomandi N, 2009, OPER RES, V57, P214, DOI 10.1287/opre.1080.0520.
   Silver D, 2017, NATURE, V550, P354, DOI 10.1038/nature24270.
   Silver D, 2016, NATURE, V529, P484, DOI 10.1038/nature16961.
   Sitek P., 2019, DISTRIBUTED COMPUTIN.
   Soumis F., 1989, INT J MIN RECLAM ENV, V3, P115.
   Stone P., 2007, SPECTRUM SERIES, VVolume 14, P133.
   Sturgul J.R., 2015, DISCRETE SIMULATION.
   Sutton RS, 2018, ADAPT COMPUT MACH LE, P1.
   Ta C. H., 2005, International Journal of Surface Mining, Reclamation and Environment, V19, P162, DOI 10.1080/13895260500128914.
   Temeng V.A., 1997, INT J SURFACE MINING, V11, P203, DOI {[}10.1080/09208119708944093, DOI 10.1080/09208119708944093].
   Torkamani Elmira, 2015, International Journal of Mining and Mineral Engineering, V6, P97.
   Upadhyay SP, 2016, T I MIN METALL A, V125, P82, DOI 10.1179/1743286315Y.0000000024.
   Upadhyay SP, 2018, INT J MIN SCI TECHNO, V28, P153, DOI 10.1016/j.ijmst.2017.12.003.
   van Hasselt H, 2016, THIRTIETH AAAI CONFERENCE ON ARTIFICIAL INTELLIGENCE, P2094.
   Vinyals O., 2017, 170804782 ARXIV.
   Vinyals O, 2019, NATURE, V575, P350, DOI 10.1038/s41586-019-1724-z.
   Whittle G., 2007, OREBODY MODELLING ST, P331.
   Whittle J., 2018, ADV APPL STRATEGIC M, P31.
   Yuriy Greg, 2008, International Journal of Mining, Reclamation and Environment, V22, P70, DOI 10.1080/17480930701589674.},
Number-of-Cited-References = {64},
Times-Cited = {3},
Usage-Count-Last-180-days = {6},
Usage-Count-Since-2013 = {7},
Journal-ISO = {Minerals},
Doc-Delivery-Number = {SY4XR},
Web-of-Science-Index = {Science Citation Index Expanded (SCI-EXPANDED)},
Unique-ID = {WOS:000665893400001},
OA = {gold},
DA = {2022-04-30},
}

@article{ WOS:000681198000004,
Author = {Zhou, Tong and Tang, Dunbing and Zhu, Haihua and Zhang, Zequn},
Title = {Multi-agent reinforcement learning for online scheduling in smart
   factories},
Journal = {ROBOTICS AND COMPUTER-INTEGRATED MANUFACTURING},
Year = {2021},
Volume = {72},
Month = {DEC},
Abstract = {Rapid advances in sensing and communication technologies connect
   isolated manufacturing units, which generates large amounts of data. The
   new trend of mass customization brings a higher level of disturbances
   and uncertainties to production planning. Traditional manufacturing
   systems analyze data and schedule orders in a centralized architecture,
   which is inefficient and unreliable for the overdependence on central
   controllers and limited communication channels. Internet of things (IoT)
   and cloud technologies make it possible to build a distributed
   manufacturing architecture such as the multi-agent system (MAS).
   Recently, artificial intelligence (AI) methods are used to solve
   scheduling problems in the manufacturing setting. However, it is
   difficult for scheduling algorithms to process high-dimensional data in
   a distributed system with heterogeneous manufacturing units. Therefore,
   this paper presents new cyber-physical integration in smart factories
   for online scheduling of low-volume-high-mix orders. First,
   manufacturing units are interconnected with each other through the
   cyber-physical system (CPS) by IoT technologies. Attributes of machining
   operations are stored and transmitted by radio frequency identification
   (RFID) tags. Second, we propose an AI scheduler with novel neural
   networks for each unit (e.g., warehouse, machine) to schedule dynamic
   operations with real-time sensor data. Each AI scheduler can collaborate
   with other schedulers by learning from their scheduling experiences.
   Third, we design new reward functions to improve the decision-making
   abilities of multiple AI schedulers based on reinforcement learning
   (RL). The proposed methodology is evaluated and validated in a smart
   factory by real-world case studies. Experimental results show that the
   new architecture for smart factories not only improves the learning and
   scheduling efficiency of multiple AI schedulers but also effectively
   deals with unexpected events such as rush orders and machine failures.},
Publisher = {PERGAMON-ELSEVIER SCIENCE LTD},
Address = {THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND},
Type = {Article},
Language = {English},
Affiliation = {Tang, DB (Corresponding Author), Nanjing Univ Aeronaut \& Astronaut, Coll Mech \& Elect Engn, Nanjing 210016, Peoples R China.
   Zhou, Tong; Tang, Dunbing; Zhu, Haihua; Zhang, Zequn, Nanjing Univ Aeronaut \& Astronaut, Coll Mech \& Elect Engn, Nanjing 210016, Peoples R China.},
DOI = {10.1016/j.rcim.2021.102202},
EarlyAccessDate = {JUN 2021},
Article-Number = {102202},
ISSN = {0736-5845},
EISSN = {1879-2537},
Keywords = {Online scheduling; Smart factory; Composite reward; Multi-agent system;
   Reinforcement learning},
Keywords-Plus = {MANUFACTURING CONTROL; SYSTEM; ARCHITECTURE},
Research-Areas = {Computer Science; Engineering; Robotics},
Web-of-Science-Categories  = {Computer Science, Interdisciplinary Applications; Engineering,
   Manufacturing; Robotics},
Author-Email = {jayantzh@outlook.com
   d.tang@nuaa.edu.cn},
Funding-Acknowledgement = {National Key Research and Develop-ment Program of China
   {[}2020YFB1710500]; National Natural Science Foundation of ChinaNational
   Natural Science Foundation of China (NSFC) {[}52075257]; Fundamental
   Research Funds for the Central UniversitiesFundamental Research Funds
   for the Central Universities {[}NP2020304]},
Funding-Text = {This work is supported by the National Key Research and Develop-ment
   Program of China (No. 2020YFB1710500) , the National Natural Science
   Foundation of China (No. 52075257) , and the Fundamental Research Funds
   for the Central Universities (No. NP2020304) . The authors express great
   thanks and appreciation to the editors and anony-mous reviewers whose
   constructive comments significantly improved the paper.},
Cited-References = {Abumaizar RJ, 1997, INT J PROD RES, V35, P2065, DOI 10.1080/002075497195074.
   BLAZEWICZ J, 1991, EUR J OPER RES, V51, P283, DOI 10.1016/0377-2217(91)90304-E.
   Chong CS, 2003, PROCEEDINGS OF THE 2003 WINTER SIMULATION CONFERENCE, VOLS 1 AND 2, P1465, DOI 10.1109/WSC.2003.1261590.
   Conway R.W., 1967, THEORY SCHEDULING.
   Dai M, 2019, ROBOT CIM-INT MANUF, V59, P143, DOI 10.1016/j.rcim.2019.04.006.
   Ghaleb M, 2020, COMPUT OPER RES, V123, DOI 10.1016/j.cor.2020.105031.
   Harrington J, 1974, COMPUTER INTEGRATED.
   Jennings Nicholas R, 1998, AGENT TECHNOLOGY FDN, P3, DOI {[}DOI 10.1007/978-3-662-03678-5\_1, 10.1007/978-3-662-03678-5\_1].
   Koren Y, 2010, J MANUF SYST, V29, P130, DOI 10.1016/j.jmsy.2011.01.001.
   Kunnathur A. S., 2004, Journal of Manufacturing Technology Management, V15, P199, DOI 10.1108/09576060410513779.
   KUSIAK A, 1988, EUR J OPER RES, V34, P113, DOI 10.1016/0377-2217(88)90346-3.
   Leitao P, 2006, COMPUT IND, V57, P121, DOI 10.1016/j.compind.2005.05.005.
   Leitao P, 2009, ENG APPL ARTIF INTEL, V22, P979, DOI 10.1016/j.engappai.2008.09.005.
   Li D, 2021, ROBOT CIM-INT MANUF, V71, DOI 10.1016/j.rcim.2021.102144.
   Li K, 2018, EXPERT SYST APPL, V99, P32, DOI 10.1016/j.eswa.2018.01.027.
   Liu C, 2020, ROBOT CIM-INT MANUF, V64, DOI 10.1016/j.rcim.2020.101956.
   Lu YQ, 2019, ROBOT CIM-INT MANUF, V57, P92, DOI 10.1016/j.rcim.2018.11.006.
   Mannion P, 2018, KNOWL ENG REV, V33, DOI 10.1017/S0269888918000292.
   Morariu C, 2020, COMPUT IND, V120, DOI 10.1016/j.compind.2020.103244.
   NASH J, 1951, ANN MATH, V54, P286, DOI 10.2307/1969529.
   Ouelhadj D, 2009, J SCHEDULING, V12, P417, DOI 10.1007/s10951-008-0090-8.
   Park HS, 2012, J MANUF SYST, V31, P337, DOI 10.1016/j.jmsy.2012.05.002.
   Pinedo ML, 2012, SCHEDULING: THEORY, ALGORITHMS, AND SYSTEMS, FOURTH EDITION, P1, DOI 10.1007/978-1-4614-2361-4.
   Rauf M, 2020, ROBOT CIM-INT MANUF, V61, DOI 10.1016/j.rcim.2019.101844.
   Rjoub G, 2019, 2019 7TH INTERNATIONAL CONFERENCE ON FUTURE INTERNET OF THINGS AND CLOUD (FICLOUD 2019), P189, DOI 10.1109/FiCloud.2019.00034.
   Salido MA, 2017, J CLEAN PROD, V162, pS121, DOI 10.1016/j.jclepro.2016.11.002.
   Shen W., 1999, Knowledge and Information Systems, V1, P129.
   Shi WS, 2016, IEEE INTERNET THINGS, V3, P637, DOI 10.1109/JIOT.2016.2579198.
   Sutton RS, 2018, ADAPT COMPUT MACH LE, P1.
   Tang H, 2018, IEEE ACCESS, V6, P12746, DOI 10.1109/ACCESS.2017.2758160.
   Wang LC, 2013, INT J PROD RES, V51, P2667, DOI 10.1080/00207543.2012.738944.
   Wang LH, 2017, T I MEAS CONTROL, V39, P388, DOI 10.1177/0142331216687817.
   Watkins C.J.C.H., 1989, THESIS KINGS COLL LO.
   Wei Zhang, 1995, IJCAI-95. Proceedings of the Fourteenth International Joint Conference on Artificial Intelligence, P1114.
   Xili Chen, 2010, 2010 IEEE International Conference on Automation and Logistics (ICAL), P396, DOI 10.1109/ICAL.2010.5585316.
   Yang H, 2019, IISE TRANS, V51, P1190, DOI 10.1080/24725854.2018.1555383.
   Yeung WL, 2012, INT J PROD RES, V50, P6339, DOI 10.1080/00207543.2011.636763.
   Zhang YF, 2017, J CLEAN PROD, V167, P665, DOI 10.1016/j.jclepro.2017.08.068.
   Zhang ZC, 2012, COMPUT OPER RES, V39, P1315, DOI 10.1016/j.cor.2011.07.019.
   Zhou B, 2021, ROBOT CIM-INT MANUF, V71, DOI 10.1016/j.rcim.2021.102160.
   Zhou T, 2021, IEEE ACCESS, V9, P752, DOI 10.1109/ACCESS.2020.3046784.},
Number-of-Cited-References = {41},
Times-Cited = {3},
Usage-Count-Last-180-days = {54},
Usage-Count-Since-2013 = {94},
Journal-ISO = {Robot. Comput.-Integr. Manuf.},
Doc-Delivery-Number = {TU7FK},
Web-of-Science-Index = {Science Citation Index Expanded (SCI-EXPANDED)},
Unique-ID = {WOS:000681198000004},
DA = {2022-04-30},
}

@article{ WOS:000460730900042,
Author = {Shin, Joohyun and Lee, Jay H.},
Title = {Multi-timescale, multi-period decision-making model development by
   combining reinforcement learning and mathematical programming},
Journal = {COMPUTERS \& CHEMICAL ENGINEERING},
Year = {2019},
Volume = {121},
Pages = {556-573},
Month = {FEB 2},
Abstract = {This study focuses on the linkage between decision layers that have
   different time scales. The resulting expansion of the boundary of
   decision-making process can provide more robust and flexible management
   and operation strategies by resolving inconsistencies between different
   levels. For this, we develop a multi-timescale decision-making model
   that combines Markov decision process (MDP) and mathematical programming
   (MP) in a complementary way and introduce a computationally tractable
   solution algorithm based on reinforcement learning (RL) to solve the
   MP-embedded MDP problem. To support the integration of the decision
   hierarchy, a data-driven uncertainty prediction model is suggested which
   is valid across all time scales considered. A practical example of
   refinery procurement and production planning is presented to illustrate
   the proposed method, along with numerical results of a benchmark case
   study. (C) 2018 Elsevier Ltd. All rights reserved.},
Publisher = {PERGAMON-ELSEVIER SCIENCE LTD},
Address = {THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND},
Type = {Article},
Language = {English},
Affiliation = {Lee, JH (Corresponding Author), Korea Adv Inst Sci \& Technol, Chem \& Biomol Engn Dept, Daejeon, South Korea.
   Shin, Joohyun; Lee, Jay H., Korea Adv Inst Sci \& Technol, Chem \& Biomol Engn Dept, Daejeon, South Korea.},
DOI = {10.1016/j.compchemeng.2018.11.020},
ISSN = {0098-1354},
EISSN = {1873-4375},
Keywords = {Multi-timescale decision making; Decision under uncertainty; Markov
   decision process; Mathematical programming; Reinforcement learning},
Keywords-Plus = {SCHEDULING PROBLEMS; OPTIMIZATION; SYSTEMS; UNCERTAINTY; FORMULATION;
   FRAMEWORK; STRATEGY},
Research-Areas = {Computer Science; Engineering},
Web-of-Science-Categories  = {Computer Science, Interdisciplinary Applications; Engineering, Chemical},
Author-Email = {sinnis379@kaist.ac.kr
   jayhlee@kaist.ac.kr},
ResearcherID-Numbers = {Lee, Jay Hyung/C-1808-2011},
ORCID-Numbers = {Lee, Jay Hyung/0000-0001-6134-6118},
Cited-References = {Amaro ACS, 2008, COMPUT CHEM ENG, V32, P2606, DOI 10.1016/j.compchemeng.2008.03.006.
   Barro D, 2016, OR SPECTRUM, V38, P711, DOI 10.1007/s00291-015-0427-6.
   Bassett MH, 1996, AICHE J, V42, P3373, DOI 10.1002/aic.690421209.
   Bengtsson J, 2010, ENERG SYST, P115, DOI 10.1007/978-3-642-12067-1\_8.
   Birge JR, 2011, SPRINGER SER OPER RE, P3, DOI 10.1007/978-1-4614-0237-4.
   Bose S, 2000, COMPUT CHEM ENG, V24, P329, DOI 10.1016/S0098-1354(00)00469-5.
   Bradtke SJ, 1996, MACH LEARN, V22, P33, DOI 10.1023/A:1018056104778.
   Braun M. W., 2003, Annual Reviews in Control, P229, DOI 10.1016/j.arcontrol.2003.09.006.
   Chen YH, 2013, APPL ENERG, V103, P145, DOI 10.1016/j.apenergy.2012.09.023.
   Cheng L, 2003, COMPUT CHEM ENG, V27, P781, DOI 10.1016/S0098-1354(02)00264-8.
   Cheng LF, 2004, COMPUT CHEM ENG, V29, P149, DOI 10.1016/j.compchemeng.2004.07.030.
   Dann C, 2014, J MACH LEARN RES, V15, P809.
   Dunn S., 2012, RBA B, P65.
   Dupacova J, 2002, Z ANGEW MATH MECH, V82, P753, DOI 10.1002/1521-4001(200211)82:11/12<753::AID-ZAMM753>3.0.CO;2-5.
   Erdirik-Dogan M, 2006, IND ENG CHEM RES, V45, P299, DOI 10.1021/ie050778z.
   FAVENNEC JP, 2001, PETROLEUM REFINING, V5.
   Fisher M, 2001, MANAGE SCI, V47, P679, DOI 10.1287/mnsc.47.5.679.10485.
   Grossmann I, 2005, AICHE J, V51, P1846, DOI 10.1002/aic.10617.
   Grossmann IE, 2012, COMPUT CHEM ENG, V47, P2, DOI 10.1016/j.compchemeng.2012.06.038.
   Grossmann IE, 2010, COMPUT CHEM ENG, V34, P1365, DOI 10.1016/j.compchemeng.2009.11.012.
   Grunow M, 2002, OR SPECTRUM, V24, P281.
   Hawkes AD, 2009, APPL ENERG, V86, P1253, DOI 10.1016/j.apenergy.2008.09.006.
   Honkomp SJ, 1999, COMPUT CHEM ENG, V23, P595, DOI 10.1016/S0098-1354(98)00296-8.
   Konicz AK, 2015, OR SPECTRUM, V37, P583, DOI 10.1007/s00291-014-0375-6.
   Lee JH, 2014, J PROCESS CONTR, V24, P323, DOI 10.1016/j.jprocont.2013.09.025.
   Lin XX, 2002, IND ENG CHEM RES, V41, P3884, DOI 10.1021/ie011002a.
   Maravelias CT, 2009, COMPUT CHEM ENG, V33, P1919, DOI 10.1016/j.compchemeng.2009.06.007.
   McDonald CM, 1998, AICHE SYM S, V94, P62.
   MCKAY KN, 1995, PROD PLAN CONTROL, V6, P384, DOI 10.1080/09537289508930295.
   Mestan E, 2006, IND ENG CHEM RES, V45, P6493, DOI 10.1021/ie0511938.
   Papageorgiou LG, 1996, IND ENG CHEM RES, V35, P488, DOI 10.1021/ie950081l.
   Perea-Lopez E, 2003, COMPUT CHEM ENG, V27, P1201, DOI 10.1016/S0098-1354(03)00047-4.
   Powell W. B., 2007, APPROXIMATE DYNAMIC, P703.
   Powell W. B., 2014, BRIDGING DATA DECISI, P109, DOI DOI 10.1287/EDUC.2014.0128.
   Powell WB, 2016, IEEE T POWER SYST, V31, P1459, DOI 10.1109/TPWRS.2015.2424974.
   Powell WB., 2012, AI OR CONTROL THEORY.
   Pratikakis N.E, 2009, MULTISTAGE DECISIONS.
   Puterman M.L., 2014, MARKOV DECISION PROC.
   Ren HB, 2010, APPL ENERG, V87, P1001, DOI 10.1016/j.apenergy.2009.09.023.
   Sahinidis NV, 2004, COMPUT CHEM ENG, V28, P971, DOI 10.1016/j.compchemeng.2003.09.017.
   Sand G, 2004, COMPUT CHEM ENG, V28, P1087, DOI 10.1016/j.compchemeng.2003.09.009.
   Shobrys DE, 2002, COMPUT CHEM ENG, V26, P149, DOI 10.1016/S0098-1354(01)00737-2.
   Stefansson H, 2006, AICHE J, V52, P4133, DOI 10.1002/aic.10989.
   Sutton R. S., 1998, REINFORCEMENT LEARNI, P1.
   van den Heever SA, 2003, COMPUT CHEM ENG, V27, P1813, DOI 10.1016/S0098-1354(03)00158-3.
   Wang H, 1986, ACOUST SPEECH SIGNAL, V34, P1678.
   Wu D, 2007, CHEM ENG PROCESS, V46, P1129, DOI 10.1016/j.cep.2007.02.021.
   Yan HS, 2003, IIE TRANS, V35, P711, DOI {[}10.1080/07408170304348, 10.1080/07408170390225714].},
Number-of-Cited-References = {48},
Times-Cited = {7},
Usage-Count-Last-180-days = {2},
Usage-Count-Since-2013 = {30},
Journal-ISO = {Comput. Chem. Eng.},
Doc-Delivery-Number = {HO2GT},
Web-of-Science-Index = {Science Citation Index Expanded (SCI-EXPANDED)},
Unique-ID = {WOS:000460730900042},
DA = {2022-04-30},
}

@article{ WOS:000771144000001,
Author = {Dong, Zhuoran and Ren, Tao and Weng, Jiacheng and Qi, Fang and Wang,
   Xinyue},
Title = {Minimizing the Late Work of the Flow Shop Scheduling Problem with a Deep
   Reinforcement Learning Based Approach},
Journal = {APPLIED SCIENCES-BASEL},
Year = {2022},
Volume = {12},
Number = {5},
Month = {MAR},
Abstract = {In the field of industrial manufacturing, assembly line production is
   the most common production process that can be modeled as a permutation
   flow shop scheduling problem (PFSP). Minimizing the late work criteria
   (tasks remaining after due dates arrive) of production planning can
   effectively reduce production costs and allow for faster product
   delivery. In this article, a novel learning-based approach is proposed
   to minimize the late work of the PFSP using deep reinforcement learning
   (DRL) and graph isomorphism network (GIN), which is an innovative
   combination of the field of combinatorial optimization and deep
   learning. The PFSPs are the well-known permutation flow shop problem and
   each job comes with a release date constraint. In this work, the PFSP is
   defined as a Markov decision process (MDP) that can be solved by
   reinforcement learning (RL). A complete graph is introduced for
   describing the PFSP instance. The proposed policy network combines the
   graph representation of PFSP and the sequence information of jobs to
   predict the distribution of candidate jobs. The policy network will be
   invoked multiple times until a complete sequence is obtained. In order
   to further improve the quality of the solution obtained by reinforcement
   learning, an improved iterative greedy (IG) algorithm is proposed to
   search the solution locally. The experimental results show that the
   proposed RL and the combined method of RL+IG can obtain better solutions
   than other excellent heuristic and meta-heuristic algorithms in a short
   time.},
Publisher = {MDPI},
Address = {ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND},
Type = {Article},
Language = {English},
Affiliation = {Ren, T (Corresponding Author), Northeastern Univ, Dept Software, Shenyang 110819, Peoples R China.
   Dong, Zhuoran; Ren, Tao; Weng, Jiacheng; Qi, Fang; Wang, Xinyue, Northeastern Univ, Dept Software, Shenyang 110819, Peoples R China.},
DOI = {10.3390/app12052366},
Article-Number = {2366},
EISSN = {2076-3417},
Keywords = {combinatorial optimization; graph neural network; deep reinforcement
   learning; flow shop scheduling; late work; pointer network; iterated
   greedy},
Keywords-Plus = {SWARM OPTIMIZATION ALGORITHM; ITERATED GREEDY ALGORITHM; HEURISTIC
   ALGORITHM; SEARCH ALGORITHM; M-MACHINE; N-JOB; PERMUTATION},
Research-Areas = {Chemistry; Engineering; Materials Science; Physics},
Web-of-Science-Categories  = {Chemistry, Multidisciplinary; Engineering, Multidisciplinary; Materials
   Science, Multidisciplinary; Physics, Applied},
Author-Email = {chinarentao@163.com
   chinarentao@163.com
   chinarentao@163.com
   chinarentao@163.com
   chinarentao@163.com},
Funding-Acknowledgement = {Fundamental Research Funds for the Central UniversitiesFundamental
   Research Funds for the Central Universities {[}N181706001, N2017009,
   N2017008, N182608003, N181703005]; National Natural Science Foundation
   of ChinaNational Natural Science Foundation of China (NSFC)
   {[}61902057]; Joint Fund of Science \& Technology Department of Liaoning
   Province; State Key Laboratory of Robotics, China {[}2020-KF-12-11]},
Funding-Text = {FundingThis research was funded by Fundamental Research Funds for the
   Central Universities (N181706001, N2017009, N2017008, N182608003,
   N181703005), National Natural Science Foundation of China (61902057),
   Joint Fund of Science \& Technology Department of Liaoning Province and
   State Key Laboratory of Robotics, China (2020-KF-12-11).},
Cited-References = {Baker KR., 2013, PRINCIPLES SEQUENCIN.
   Bello I., 2016, ARXIV161109940.
   Bennett CC, 2013, ARTIF INTELL MED, V57, P9, DOI 10.1016/j.artmed.2012.12.003.
   Blazewicz J, 2000, OPERATIONS RESEARCH PROCEEDINGS 1999, P354, DOI 10.1007/978-3-642-58300-1\_54.
   CAMPBELL HG, 1970, MANAGE SCI B-APPL, V16, pB630.
   Chen RB, 2019, NAV RES LOG, V66, P582, DOI 10.1002/nav.21869.
   Chen X, 2016, J SCHEDULING, V19, P729, DOI 10.1007/s10951-015-0464-7.
   Chen XY, 2019, ADV NEUR IN, V32.
   Dubois-Lacoste J, 2017, COMPUT OPER RES, V81, P160, DOI 10.1016/j.cor.2016.12.021.
   Garey M. R., 1976, Mathematics of Operations Research, V1, P117, DOI 10.1287/moor.1.2.117.
   Gerstl E, 2019, INT J PROD RES, V57, P531, DOI 10.1080/00207543.2018.1456693.
   Gupta JND, 2006, EUR J OPER RES, V169, P699, DOI 10.1016/j.ejor.2005.02.001.
   Hu H., 2017, ARXIV170805930.
   Ince Y, 2016, IEEE C EVOL COMPUTAT, P3401, DOI 10.1109/CEC.2016.7744220.
   Ivkovic Nikola, 2016, International Journal of Machine Learning and Computing, V6, P167, DOI 10.18178/ijmlc.2016.6.3.593.
   Johnson S.M., 1954, NAV RES LOG, V1, P61, DOI DOI 10.1002/NAV.3800010110.
   Khalil E., 2017, ADV NEURAL INF PROCE, V30, P6348, DOI DOI 10.5555/3295222.3295382.
   Kipf T.N., 2016, ARXIV 2016 160902907.
   Kool W., 2018, P INT C LEARN REPR V.
   Lederman G., 2018, ARXIV180708058.
   Leung J, 2004, HDB SCHEDULING ALGOR, P34.
   Lu H., 2019, P INT C LEARN REPR N.
   Ma Q., 2019, COMBINATORIAL OPTIMI.
   NAWAZ M, 1983, OMEGA-INT J MANAGE S, V11, P91, DOI 10.1016/0305-0483(83)90088-9.
   Nowicki E, 1996, EUR J OPER RES, V91, P160, DOI 10.1016/0377-2217(95)00037-2.
   Pan QK, 2008, COMPUT OPER RES, V35, P2807, DOI 10.1016/j.cor.2006.12.030.
   Pesch E, 2009, COMPUT IND ENG, V57, P1202, DOI 10.1016/j.cie.2009.05.011.
   POTTS CN, 1992, OPER RES, V40, P586, DOI 10.1287/opre.40.3.586.
   Ren JF, 2013, INFORM PROCESS LETT, V113, P609, DOI 10.1016/j.ipl.2013.05.005.
   Ren JF, 2009, ASIA PAC J OPER RES, V26, P351, DOI 10.1142/S0217595909002249.
   Rennie SJ, 2017, PROC CVPR IEEE, P1179, DOI 10.1109/CVPR.2017.131.
   Ruiz R, 2005, EUR J OPER RES, V165, P479, DOI 10.1016/j.ejor.2004.04.017.
   Ruiz R, 2007, EUR J OPER RES, V177, P2033, DOI 10.1016/j.ejor.2005.12.009.
   Scarselli F, 2009, IEEE T NEURAL NETWOR, V20, P61, DOI 10.1109/TNN.2008.2005605.
   Sterna M, 2011, OMEGA-INT J MANAGE S, V39, P120, DOI 10.1016/j.omega.2010.06.006.
   Sutskever I., 2014, ADV NEURAL INFORM PR.
   TAILLARD E, 1993, EUR J OPER RES, V64, P278, DOI 10.1016/0377-2217(93)90182-M.
   Takac M., 2018, P 32 INT C NEUR INF, P1.
   Tasgetiren MF, 2004, LECT NOTES COMPUT SC, V3172, P382.
   Tseng LY, 2010, INT J PROD ECON, V128, P144, DOI 10.1016/j.ijpe.2010.06.006.
   Vinyals O., 2015, ADV NEURAL INF PROCE, V28, P1.
   Wang H, 2017, SOFT COMPUT, V21, P4297, DOI 10.1007/s00500-016-2062-9.
   Wang XY, 2022, SWARM EVOL COMPUT, V69, DOI 10.1016/j.swevo.2021.100996.
   WILLIAMS RJ, 1992, MACH LEARN, V8, P229, DOI 10.1007/BF00992696.
   Wu Y., 2019, ARXIV191205784.
   Xu K., 2018, P INT C LEARN REPR V.
   Zhang RS, 2020, PALLIAT SUPPORT CARE, V18, P609, DOI 10.1017/S1478951520000978.},
Number-of-Cited-References = {47},
Times-Cited = {0},
Usage-Count-Last-180-days = {7},
Usage-Count-Since-2013 = {7},
Journal-ISO = {Appl. Sci.-Basel},
Doc-Delivery-Number = {ZW3VO},
Web-of-Science-Index = {Science Citation Index Expanded (SCI-EXPANDED)},
Unique-ID = {WOS:000771144000001},
OA = {gold},
DA = {2022-04-30},
}

@article{ WOS:000716937600131,
Author = {Lang, Sebastian and Kuetgens, Maximilian and Reichardt, Paul and
   Reggelin, Tobias},
Title = {Modeling Production Scheduling Problems as Reinforcement Learning
   Environments based on Discrete-Event Simulation and OpenAl Gym},
Journal = {IFAC PAPERSONLINE},
Year = {2021},
Volume = {54},
Number = {1},
Pages = {793-798},
Note = {17th IFAC Symposium on Information Control Problems in Manufacturing
   (INCOM), Budapest, HUNGARY, JUN 07-09, 2021},
Organization = {Int Federat Automat Control, Tech Comm 5 1 Mfg Plant Control; Int
   Federat Automat Control, Tech Comm 5 2 Management \& Control Mfg \&
   Logist; Int Federat Automat Control, Tech Comm 5 3 Integrat \&
   Interoperabil Enterprise Syst; Int Federat Automat Control, Tech Comm 5
   4 Large Scale Complex Syst; Inst Comp Sci \& Control; Ctr Excellence
   Prod Informat \& Control; Int Federat Automat Control, Tech Comm 1 3
   Discrete Event \& Hybrid Syst; Int Federat Automat Control, Tech Comm 4
   2 Mechatron Syst; Int Federat Automat Control, Tech Comm 4 3 Robot; Int
   Federat Automat Control, Tech Comm 6 4 Fault Detect, Supervis \& Safety
   Tech Proc; Int Federat Automat Control, Tech Comm 7 1 Automot Control;
   Int Federat Automat Control, Tech Comm 7 4 Transportat Syst; Int Federat
   Automat Control, Tech Comm 7 5 Intelligent Autonomous Vehicles; Int
   Federat Automat Control, Tech Comm 9 2 Syst \& Control Societal Impact;
   IPAR 4 0; EPIC InnoLabs; Muegyetem 1782; Obudai Egyetem; IEEE Hungary
   Sect; Mesterseges Intelligencia Koalicio; AGIP; Univ Gyor, Szechenvi
   Egyetem; GE},
Abstract = {Reinforcement learning (RL) is an emerging research topic in production
   and logistics, as it offers potentials to solve complex planning and
   control problems in real time. In recent years, many researchers
   investigated RL algorithms for solving production scheduling problems.
   However, most of the related articles reveal only little information
   about the process of developing and implementing RL applications.
   Against this background, we present a method for modeling production
   scheduling problems as RL environments. More specifically, we propose
   the application of Discrete -Event Simulation for modeling production
   scheduling problems as an interoperable environments and the Gym
   interface of the OpenAl foundation to allow a simple integration of pre
   built RL algorithms from OpenAl Baselines and Stable Baselines. We
   support our explanations with a simple example of a job shop scheduling
   problem. Copyright (C) 2021 The Authors.},
Publisher = {ELSEVIER},
Address = {RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS},
Type = {Proceedings Paper},
Language = {English},
Affiliation = {Lang, S (Corresponding Author), Fraunhofer Inst Factory Operat \& Automat, D-39106 Magdeburg, Germany.
   Lang, Sebastian, Fraunhofer Inst Factory Operat \& Automat, D-39106 Magdeburg, Germany.
   Kuetgens, Maximilian; Reichardt, Paul; Reggelin, Tobias, Otto von Guericke Univ, D-39106 Magdeburg, Germany.},
DOI = {10.1016/j.ifacol.2021.08.093},
EarlyAccessDate = {NOV 2021},
ISSN = {2405-8963},
Keywords = {Reinforcement Learning; Production Scheduling; Production Planning and
   Control; Discrete Event Modeling and Simulation; OpenAI Gym; Artificial
   Intelligence; Deep Learning; Neural Network},
Research-Areas = {Automation \& Control Systems},
Web-of-Science-Categories  = {Automation \& Control Systems},
Author-Email = {sebastian.lang@iff.fraunhofer.de
   maximilian.kuetgens@ovgu.de
   paul.reichardt@ovgu.de
   tobias.reggelin@ovgu.de},
Cited-References = {Arulkumaran K, 2017, IEEE SIGNAL PROC MAG, V34, P26, DOI 10.1109/MSP.2017.2743240.
   Banks J., 2010, DISCRETEEVENT SYSTEM, V5th.
   Brockman Greg, 2016, arXiv.
   DAHL OJ, 1966, COMMUN ACM, V9, P671, DOI 10.1145/365813.365819.
   Dhariwal P., 2017, GITHUB REPOSITORY GI.
   Francois-Lavet V, 2018, FOUND TRENDS MACH LE, V11, P219, DOI 10.1561/2200000071.
   Gershwin SB, 2018, INT J PROD RES, V56, P224, DOI 10.1080/00207543.2017.1395491.
   Hill A., 2018, GITHUB REPOSITORY GI.
   Lang S., 2020, P 53 HAW INT C SYST, P1298.
   Lang S, 2020, WINT SIMUL C PROC, P3057, DOI 10.1109/WSC48552.2020.9383997.
   Lang S, 2019, IFAC PAPERSONLINE, V52, P2716, DOI 10.1016/j.ifacol.2019.11.618.
   Lin CC, 2019, IEEE T IND INFORM, V15, P4276, DOI 10.1109/TII.2019.2908210.
   Luo S, 2020, APPL SOFT COMPUT, V91, DOI 10.1016/j.asoc.2020.106208.
   Matloff N., 2008, INTRO DISCRETE EVENT.
   Mnih V., 2013, PROC 27 C NEURAL INF, P1.
   Mnih V, 2015, NATURE, V518, P529, DOI 10.1038/nature14236.
   Scholz -Reiter B., 2008, BEITRAGE THEORIE LOG, P109.
   Schriber TJ, 2017, WINT SIMUL C PROC, P735, DOI 10.1109/WSC.2017.8247828.
   Shiue YR, 2018, COMPUT IND ENG, V125, P604, DOI 10.1016/j.cie.2018.03.039.
   Stricker N, 2018, CIRP ANN-MANUF TECHN, V67, P511, DOI 10.1016/j.cirp.2018.04.041.
   Sutton RS, 2018, ADAPT COMPUT MACH LE, P1.
   van der Ham R., 2018, J OPEN SOURCE SOFTWA, V3, P767, DOI DOI 10.21105/JOSS.00767.
   Wang HX, 2021, INT J PROD RES, V59, P5867, DOI 10.1080/00207543.2020.1794075.
   Waschneck B, 2018, PROC CIRP, V72, P1264, DOI 10.1016/j.procir.2018.03.212.},
Number-of-Cited-References = {24},
Times-Cited = {0},
Usage-Count-Last-180-days = {11},
Usage-Count-Since-2013 = {11},
Journal-ISO = {IFAC PAPERSONLINE},
Doc-Delivery-Number = {WV0OZ},
Web-of-Science-Index = {Conference Proceedings Citation Index - Science (CPCI-S)},
Unique-ID = {WOS:000716937600131},
OA = {gold},
DA = {2022-04-30},
}

@article{ WOS:000740375200001,
Author = {Wurster, Marco and Michel, Marius and May, Marvin Carl and Kuhnle,
   Andreas and Stricker, Nicole and Lanza, Gisela},
Title = {Modelling and condition-based control of a flexible and hybrid
   disassembly system with manual and autonomous workstations using
   reinforcement learning},
Journal = {JOURNAL OF INTELLIGENT MANUFACTURING},
Year = {2022},
Volume = {33},
Number = {2},
Pages = {575-591},
Month = {FEB},
Abstract = {Remanufacturing includes disassembly and reassembly of used products to
   save natural resources and reduce emissions. While assembly is widely
   understood in the field of operations management, disassembly is a
   rather new problem in production planning and control. The latter faces
   the challenge of high uncertainty of type, quantity and quality
   conditions of returned products, leading to high volatility in
   remanufacturing production systems. Traditionally, disassembly is a
   manual labor-intensive production step that, thanks to advances in
   robotics and artificial intelligence, starts to be automated with
   autonomous workstations. Due to the diverging material flow, the
   application of production systems with loosely linked stations is
   particularly suitable and, owing to the risk of condition induced
   operational failures, the rise of hybrid disassembly systems that
   combine manual and autonomous workstations can be expected. In contrast
   to traditional workstations, autonomous workstations can expand their
   capabilities but suffer from unknown failure rates. For such adverse
   conditions a condition-based control for hybrid disassembly systems,
   based on reinforcement learning, alongside a comprehensive modeling
   approach is presented in this work. The method is applied to a
   real-world production system. By comparison with a heuristic control
   approach, the potential of the RL approach can be proven simulatively
   using two different test cases.},
Publisher = {SPRINGER},
Address = {VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS},
Type = {Article},
Language = {English},
Affiliation = {Wurster, M (Corresponding Author), Karlsruhe Inst Technol KIT, Wbk Inst Prod Sci, Kaiserstr 12, D-76131 Karlsruhe, Germany.
   Wurster, Marco; Michel, Marius; May, Marvin Carl; Kuhnle, Andreas; Stricker, Nicole; Lanza, Gisela, Karlsruhe Inst Technol KIT, Wbk Inst Prod Sci, Kaiserstr 12, D-76131 Karlsruhe, Germany.},
DOI = {10.1007/s10845-021-01863-3},
EarlyAccessDate = {JAN 2022},
ISSN = {0956-5515},
EISSN = {1572-8145},
Keywords = {Remanufacturing; Production control; Reinforcement learning; Hybrid
   disassembly; Disassembly automation},
Keywords-Plus = {PRODUCT; DESIGN; IMPLEMENTATION; END},
Research-Areas = {Computer Science; Engineering},
Web-of-Science-Categories  = {Computer Science, Artificial Intelligence; Engineering, Manufacturing},
Author-Email = {marco.wurster@kit.edu},
ORCID-Numbers = {Wurster, Marco/0000-0001-8145-1257},
Funding-Acknowledgement = {Carl Zeiss Foundation},
Funding-Text = {The project AgiProbot is funded by the Carl Zeiss Foundation.},
Cited-References = {Altekin FT, 2012, INT J PROD RES, V50, P4955, DOI 10.1080/00207543.2011.616915.
   Altenmuller T, 2020, PROD ENG-RES DEV, V14, P319, DOI 10.1007/s11740-020-00967-8.
   Apple Inc, 2019, ENV RESP REP 2019 PR.
   Aytug H, 2005, EUR J OPER RES, V161, P86, DOI 10.1016/j.ejor.2003.08.027.
   Bdiwi M, 2016, IEEE INT CONF ROBOT, P2500, DOI 10.1109/ICRA.2016.7487404.
   Buker U, 2001, ROBOT AUTON SYST, V35, P179, DOI 10.1016/S0921-8890(01)00121-X.
   Caciula J. M, 2007, IFAC P VOLUMES, V40, P789, DOI {[}10.3182/20070927-4-RO-3905.00130, DOI 10.3182/20070927-4-RO-3905.00130].
   Colledani M, 2016, CIRP ANN-MANUF TECHN, V65, P41, DOI 10.1016/j.cirp.2016.04.121.
   Csaji BC, 2006, ADV ENG INFORM, V20, P279, DOI 10.1016/j.aei.2006.01.001.
   Cunha Bruno, 2020, Hybrid Intelligent Systems. 18th International Conference on Hybrid Intelligent Systems (HIS 2018). Advances in Intelligent Systems and Computing (923), P350, DOI 10.1007/978-3-030-14347-3\_34.
   Cunha B, 2018, HYBRID INTELLIGENT S, P350.
   Dios M, 2016, COMPUT IND ENG, V99, P229, DOI 10.1016/j.cie.2016.07.020.
   Duflou JR, 2008, CIRP ANN-MANUF TECHN, V57, P583, DOI 10.1016/j.cirp.2008.09.009.
   Falcao D, 2013, INT C ALG SYMB COMP.
   Gao MM, 2001, IEEE INT SYMP ELECTR, P167, DOI 10.1109/ISEE.2001.924521.
   Guide VDR, 2000, J OPER MANAG, V18, P467, DOI 10.1016/S0272-6963(00)00034-6.
   Gungor A, 2001, INT J PROD RES, V39, P1427, DOI 10.1080/00207540110052157.
   GUPTA SM, 1994, INT J PROD RES, V32, P1857, DOI 10.1080/00207549408957046.
   Hafner, 2020, AGIPROBOT.
   Kim HJ, 2007, INT J PROD RES, V45, P4465, DOI 10.1080/00207540701440097.
   Kim HJ, 2009, INT J ADV MANUF TECH, V40, P1016, DOI 10.1007/s00170-008-1407-7.
   Kim HJ, 2006, ROBOT CIM-INT MANUF, V22, P267, DOI 10.1016/j.rcim.2005.06.003.
   Kim HJ, 2007, IEEE T AUTOM SCI ENG, V4, P194, DOI 10.1109/TASE.2006.880538.
   KIMEMIA J, 1983, IIE TRANS, V15, P353, DOI 10.1080/05695558308974659.
   Knobloch, 2014, VAHLENS HANDBUCHER.
   Kopacek, 2003, IFAC P, V36, P103, DOI {[}10.1016/S1474-6670(17)37669-3, DOI 10.1016/S1474-6670(17)37669-3].
   Kopacek P, 2006, INT J ADV MANUF TECH, V30, P554, DOI 10.1007/s00170-005-0042-9.
   Kuhnle A., 2017, TENSORFORCE TENSORFL.
   Kuhnle A, 2020, SIMRLFAB SIMULATION.
   Kuhnle A, 2021, INT J PROD RES, DOI 10.1080/00207543.2021.1972179.
   Kuhnle A, 2021, J INTELL MANUF, V32, P855, DOI 10.1007/s10845-020-01612-y.
   Kuhnle A, 2019, PROC CIRP, V81, P234, DOI 10.1016/j.procir.2019.03.041.
   Kuhnle A, 2019, TECHNOL INT AUTOMAT, V9, P123, DOI 10.1007/978-3-662-58485-9\_14.
   Kuhnle A, 2019, PROC CIRP, V79, P391, DOI 10.1016/j.procir.2019.02.101.
   Lage M, 2012, PROD PLAN CONTROL, V23, P419, DOI 10.1080/09537287.2011.561815.
   Lambert A., 2004, DISASSEMBLY MODELING.
   Lawler E. L., 1993, HDB OPERATIONS RES M, V4, P445.
   Lee DH, 2001, P I MECH ENG B-J ENG, V215, P695, DOI 10.1243/0954405011518629.
   Lund, 1984, INTEGRATED RESOURCE, V2.
   MCKAY KN, 1988, INTERFACES, V18, P84, DOI 10.1287/inte.18.4.84.
   Mhada F, 2011, J QUAL MAINT ENG, V17, P238, DOI 10.1108/13552511111157362.
   Moore KE, 1998, COMPUT IND ENG, V35, P165, DOI 10.1016/S0360-8352(98)00051-5.
   Pinedo ML., 2016, SCHEDULING, DOI {[}10.1007/978-3-319-26580-3, DOI 10.1007/978-3-319-26580-3].
   Poschmann H, 2020, CHEM-ING-TECH, V92, P341, DOI 10.1002/cite.201900107.
   Priyono A, 2016, J IND ENG MANAG-JIEM, V9, P899, DOI 10.3926/jiem.2053.
   Reisig W., 2013, UNDERSTANDING PETRIN, DOI {[}10.1007/978-3-642-33278-4, DOI 10.1007/978-3-642-33278-4].
   Riggs RJ, 2015, J MANUF SYST, V37, P638, DOI 10.1016/j.jmsy.2014.11.002.
   Rujanavech C., 2016, LIAM INNOVATION STOR.
   Scholz-Reiter B, 1999, ROBOT CIM-INT MANUF, V15, P247, DOI 10.1016/S0736-5845(99)00022-8.
   Slama I, 2019, IFAC PAPERSONLINE, V52, P601, DOI 10.1016/j.ifacol.2019.11.225.
   Sundin E., 2014, INT J AUTOMATION TEC, V8, P644, DOI {[}10.20965/ijat.2014.p0644, DOI 10.20965/IJAT.2014.P0644].
   Tang Y, 2001, IEEE T ROBOTIC AUTOM, V17, P773, DOI 10.1109/70.975899.
   Tolio T, 2017, CIRP ANN-MANUF TECHN, V66, P585, DOI 10.1016/j.cirp.2017.05.001.
   Tumkor S, 2007, 2007 IEEE INTERNATIONAL SYMPOSIUM ON ASSEMBLY AND MANUFACTURING, P70, DOI 10.1109/ISAM.2007.4288451.
   Ullerich C, 2013, INT J PROD RES, V51, P6209, DOI 10.1080/00207543.2013.825406.
   Vongbunyong S, 2015, DISASSEMBLY AUTOMATI, DOI {[}10.1007/978-3-319-15183-0, DOI 10.1007/978-3-319-15183-0].
   Vongbunyong S, 2017, PROC CIRP, V61, P281, DOI 10.1016/j.procir.2016.11.197.
   Vongbunyong S, 2013, ASSEMBLY AUTOM, V33, P38, DOI 10.1108/01445151311294694.
   Waschneck B, 2018, ASMC PROC, P301, DOI 10.1109/ASMC.2018.8373191.
   World Economic Forum, 2019, NEW CIRC VIS EL TIM.
   World Economic Forum \& Accenture Strategy., 2019, HARN 4 IND REV CIRC.
   Wurster Marco, 2021, Procedia CIRP, V97, P508, DOI 10.1016/j.procir.2020.05.267.
   Zussman E, 2000, IEEE T ROBOTIC AUTOM, V16, P171, DOI 10.1109/70.843173.
   Zussman E, 1999, IEEE T ROBOTIC AUTOM, V15, P190, DOI 10.1109/70.744614.},
Number-of-Cited-References = {64},
Times-Cited = {1},
Usage-Count-Last-180-days = {6},
Usage-Count-Since-2013 = {6},
Journal-ISO = {J. Intell. Manuf.},
Doc-Delivery-Number = {YI6YF},
Web-of-Science-Index = {Science Citation Index Expanded (SCI-EXPANDED)},
Unique-ID = {WOS:000740375200001},
OA = {Green Published, hybrid},
DA = {2022-04-30},
}

@inproceedings{ WOS:000679196303006,
Author = {Gros, Timo P. and Gross, Joschka and Wolf, Verena},
Book-Group-Author = {IEEE},
Title = {REAL-TIME DECISION MAKING FOR A CAR MANUFACTURING PROCESS USING DEEP
   REINFORCEMENT LEARNING},
Booktitle = {2020 WINTER SIMULATION CONFERENCE (WSC)},
Series = {Winter Simulation Conference Proceedings},
Year = {2020},
Pages = {3032-3044},
Note = {Winter Simulation Conference, ELECTR NETWORK, DEC 14-18, 2020},
Abstract = {Computer simulations of manufacturing processes are in widespread use
   for optimizing production planning and order processing. If
   unforeseeable events are common, real-time decisions are necessary to
   maximize the performance of the manufacturing process. Pre-trained
   AI-based decision support offers promising opportunities for such
   time-critical production processes. Here, we explore the effectiveness
   of deep reinforcement learning for real-time decision making in a car
   manufacturing process. We combine a simulation model of a central
   production part, the line buffer, with deep reinforcement learning
   algorithms, in particular with deep Q-Learning and Monte Carlo tree
   search. We simulate two different versions of the buffer, a single-agent
   and a multi-agent one, to generate large amounts of data and train
   neural networks to represent near-optimal strategies. Our results show
   that deep reinforcement learning performs extremely well and the
   resulting strategies provide near-optimal decisions in real-time, while
   alternative approaches are either slow or give strategies of poor
   quality.},
Publisher = {IEEE},
Address = {345 E 47TH ST, NEW YORK, NY 10017 USA},
Type = {Proceedings Paper},
Language = {English},
Affiliation = {Gros, TP (Corresponding Author), Saarland Univ, Comp Sci, Saarland Informat Campus, D-66123 Saarbrucken, Germany.
   Gros, TP (Corresponding Author), Saarland Univ, Chair Modeling \& Simulat, Saarland Informat Campus, D-66123 Saarbrucken, Germany.
   Gros, Timo P.; Gross, Joschka, Saarland Univ, Comp Sci, Saarland Informat Campus, D-66123 Saarbrucken, Germany.
   Gros, Timo P., Saarland Univ, Chair Modeling \& Simulat, Saarland Informat Campus, D-66123 Saarbrucken, Germany.
   Wolf, Verena, Saarland Univ, Saarland Informat Campus, D-66123 Saarbrucken, Germany.},
DOI = {10.1109/WSC48552.2020.9383884},
ISSN = {0891-7736},
ISBN = {978-1-7281-9499-8},
Keywords-Plus = {GO; GAME},
Research-Areas = {Computer Science; Operations Research \& Management Science; Mathematics},
Web-of-Science-Categories  = {Computer Science, Interdisciplinary Applications; Computer Science,
   Theory \& Methods; Operations Research \& Management Science;
   Mathematics, Applied},
Author-Email = {timopgros@cs.uni-saarland.de
   s8jagros@stud.uni-saarland.de
   verena.wolf@uni-saarland.de},
Funding-Acknowledgement = {European Regional Development Fund (ERDF)European Commission},
Funding-Text = {This work has been partially funded by the European Regional Development
   Fund (ERDF).},
Cited-References = {Agostinelli F, 2019, NAT MACH INTELL, V1, P356, DOI 10.1038/s42256-019-0070-z.
   Bengio Y., 2009, P 26 ANN INT C MACH, P41, DOI DOI 10.1145/1553374.1553380.
   Busoniu L, 2008, IEEE T SYST MAN CY C, V38, P156, DOI 10.1109/TSMCC.2007.913919.
   Chen W. J., 2017, P IEEE 25 INT C NETW.
   Finnsson H., 2008, AAAI, P259, DOI DOI 10.1145/1273496.1273531.
   Genesereth M., 2014, SYNTHESIS LECT ARTIF, V8, P1, DOI DOI 10.2200/S00564ED1V01Y201311AIM024.
   Gros T. P., 2020, REAL TIME DECISION M.
   Gupta G, 2017, 2017 INTERNATIONAL CONFERENCE ON INNOVATIONS IN ELECTRONICS, SIGNAL PROCESSING AND COMMUNICATION (IESC), P66, DOI 10.1109/IESPC.2017.8071866.
   Kocsis L, 2006, LECT NOTES COMPUT SC, V4212, P282, DOI 10.1007/11871842\_29.
   Kool W., 2018, ARXIV PREPRINT ARXIV.
   Mao HZ, 2016, PROCEEDINGS OF THE 15TH ACM WORKSHOP ON HOT TOPICS IN NETWORKS (HOTNETS `16), P50, DOI 10.1145/3005745.3005750.
   Mazyavkina N., 2020, ARXIV200303600.
   Mnih V., 2013, ARXIV.
   Mnih V, 2015, NATURE, V518, P529, DOI 10.1038/nature14236.
   Nazari M., 2018, NEURIPS, P9839.
   Schain MA, 2008, PERSPECT COMP POLIT, P1, DOI {[}10.1057/9780230616660, 10.1007/978-3-540-87608-3\_1].
   Schwartz HM, 2014, MULTI-AGENT MACHINE LEARNING: A REINFORCEMENT APPROACH, P1, DOI 10.1002/9781118884614.
   Silver D., 2017, ARXIV171201815.
   Silver D, 2018, SCIENCE, V362, P1140, DOI 10.1126/science.aar6404.
   Silver D, 2017, NATURE, V550, P354, DOI 10.1038/nature24270.
   Silver D, 2016, NATURE, V529, P484, DOI 10.1038/nature16961.
   Sutton RS, 2018, ADAPT COMPUT MACH LE, P1.
   Waschneck B, 2018, PROC CIRP, V72, P1264, DOI 10.1016/j.procir.2018.03.212.},
Number-of-Cited-References = {23},
Times-Cited = {0},
Usage-Count-Last-180-days = {4},
Usage-Count-Since-2013 = {5},
Doc-Delivery-Number = {BR9OO},
Web-of-Science-Index = {Conference Proceedings Citation Index - Science (CPCI-S)},
Unique-ID = {WOS:000679196303006},
DA = {2022-04-30},
}

@article{ WOS:000636234700003,
Author = {Yang, Yanhua and Yao, Ligang},
Title = {Optimization Method of Power Equipment Maintenance Plan Decision-Making
   Based on Deep Reinforcement Learning},
Journal = {MATHEMATICAL PROBLEMS IN ENGINEERING},
Year = {2021},
Volume = {2021},
Month = {MAR 15},
Abstract = {The safe and reliable operation of power grid equipment is the basis for
   ensuring the safe operation of the power system. At present, the
   traditional periodical maintenance has exposed the abuses such as
   deficient maintenance and excess maintenance. Based on a multiagent deep
   reinforcement learning decision-making optimization algorithm, a method
   for decision-making and optimization of power grid equipment maintenance
   plans is proposed. In this paper, an optimization model of power grid
   equipment maintenance plan that takes into account the reliability and
   economics of power grid operation is constructed with maintenance
   constraints and power grid safety constraints as its constraints. The
   deep distributed recurrent Q-networks multiagent deep reinforcement
   learning is adopted to solve the optimization model. The deep
   distributed recurrent Q-networks multiagent deep reinforcement learning
   uses the high-dimensional feature extraction capabilities of deep
   learning and decision-making capabilities of reinforcement learning to
   solve the multiobjective decision-making problem of power grid
   maintenance planning. Through case analysis, the comparative results
   show that the proposed algorithm has better optimization and
   decision-making ability, as well as lower maintenance cost. Accordingly,
   the algorithm can realize the optimal decision of power grid equipment
   maintenance plan. The expected value of power shortage and maintenance
   cost obtained by the proposed method is \$71.75\$ \$MW.H\$ and
   \$496000\$ \$yuan\$.},
Publisher = {HINDAWI LTD},
Address = {ADAM HOUSE, 3RD FLR, 1 FITZROY SQ, LONDON, W1T 5HF, ENGLAND},
Type = {Article},
Language = {English},
Affiliation = {Yang, YH (Corresponding Author), Fujian Jiangxia Univ, Sch Engn, Fuzhou 350108, Peoples R China.
   Yang, Yanhua, Fujian Jiangxia Univ, Sch Engn, Fuzhou 350108, Peoples R China.
   Yao, Ligang, Fuzhou Univ, Sch Mech Engn \& Automat, Fuzhou 350116, Peoples R China.},
DOI = {10.1155/2021/9372803},
Article-Number = {9372803},
ISSN = {1024-123X},
EISSN = {1563-5147},
Keywords-Plus = {SYSTEMS},
Research-Areas = {Engineering; Mathematics},
Web-of-Science-Categories  = {Engineering, Multidisciplinary; Mathematics, Interdisciplinary
   Applications},
Author-Email = {mayspring@163.com},
Cited-References = {Abu-Mouti FS, 2012, ANN IEEE SYST CONF, P590.
   Akhavan-Hejazi H, 2018, ENERGY REP, V4, P91, DOI 10.1016/j.egyr.2017.11.002.
   Bakar N.A., 2017, 2017 IEEE C EN CONV.
   Cui X., 2015, POWER SYSTEM CLEAN E, V31, P18.
   Fattahi M, 2014, COMPUT OPER RES, V50, P61, DOI 10.1016/j.cor.2014.04.004.
   Glavic M, 2017, IFAC PAPERSONLINE, V50, P6918, DOI 10.1016/j.ifacol.2017.08.1217.
   {[}李二霞 Li Erxia], 2018, {[}高电压技术, High Voltage Engineering], V44, P3751.
   Li HJ, 2018, NANO COMMUN NETW, V16, P81, DOI 10.1016/j.nancom.2018.02.003.
   Li Ran, 2013, Electric Power Automation Equipment, V33, P1, DOI 10.3969/j.issn.1006-6047.2013.11.001.
   Li Y., 2019, COORDINATED STOCHAS.
   Lindner BG, 2018, INT J ELEC POWER, V101, P458, DOI 10.1016/j.ijepes.2018.02.018.
   {[}刘建伟 Liu Jianwei], 2019, {[}计算机学报, Chinese Journal of Computers], V42, P1406.
   {[}刘全 Liu Quan], 2018, {[}计算机学报, Chinese Journal of Computers], V41, P1.
   Raza MQ, 2015, RENEW SUST ENERG REV, V50, P1352, DOI 10.1016/j.rser.2015.04.065.
   Rocchetta R, 2019, APPL ENERG, V241, P291, DOI 10.1016/j.apenergy.2019.03.027.
   Tian HX, 2019, IEEE ACCESS, V7, P137731, DOI 10.1109/ACCESS.2019.2939483.
   Twaha S, 2018, SUSTAIN CITIES SOC, V41, P320, DOI 10.1016/j.scs.2018.05.027.
   {[}万里鹏 Wan Lipeng], 2019, {[}模式识别与人工智能, Pattern Recognition and Artificial Intelligence], V32, P67.
   Wang YD, 2019, IEEE ACCESS, V7, P39974, DOI 10.1109/ACCESS.2019.2902846.
   {[}吴佳 Wu Jia], 2020, {[}电子科技大学学报, Journal of University of Electronic Science and Technology of China], V49, P255.
   Xu B., 2019, DETERMINING OPTIMAL.
   Yang X., 2017, ELECT POWER ENG TECH, V36, P72.
   Yuan C.L., 2018, INT J PAVEMENT ENG, V12, P162, DOI {[}10.1139/cjb-2019-0093., DOI 10.1080/10298436.2018.1485917, 10.1080/17535654.2018.1555359].
   Zhang DX, 2018, CSEE J POWER ENERGY, V4, P362, DOI 10.17775/CSEEJPES.2018.00520.
   Zhang Y, 2019, IEEE ACCESS, V7, P118898, DOI 10.1109/ACCESS.2019.2937108.
   Zhang ZD, 2020, CSEE J POWER ENERGY, V6, P213, DOI 10.17775/CSEEJPES.2019.00920.},
Number-of-Cited-References = {26},
Times-Cited = {0},
Usage-Count-Last-180-days = {3},
Usage-Count-Since-2013 = {11},
Journal-ISO = {Math. Probl. Eng.},
Doc-Delivery-Number = {RH5BU},
Web-of-Science-Index = {Science Citation Index Expanded (SCI-EXPANDED)},
Unique-ID = {WOS:000636234700003},
OA = {gold},
DA = {2022-04-30},
}

@article{ WOS:000760716000001,
Author = {Feng, Maomao and Li, Yang},
Title = {Predictive Maintenance Decision Making Based on Reinforcement Learning
   in Multistage Production Systems},
Journal = {IEEE ACCESS},
Year = {2022},
Volume = {10},
Pages = {18910-18921},
Abstract = {Predictive maintenance has become increasingly prevalent in modern
   production systems that are challenged by high-mix low-volume production
   and short production life cycle. It is very helpful to prevent costly
   equipment failures, and reduce significant production loss caused by
   unscheduled machine breakdown. Although important, decision models for
   joint predictive maintenance and production in manufacturing systems
   have not been fully explored. Therefore, we propose a reinforcement
   learning based decision model, that brings together production system
   modeling and approximate dynamic programming. We start from the
   development of a state-based model by analyzing the dynamics of a
   multistage production system with predictive maintenance. It provides an
   approach to quantitatively evaluate the various disruptions as well as
   the maintenance decision's impact on production. Then a reinforcement
   learning method is proposed to explore optimal maintenance policies,
   that optimize the production and maintenance cost. To further improve
   the performance of the production system, machine stoppage bottlenecks
   are defined. An event-based indicator is proved to identify bottlenecks
   with production data. We test the proposed models in simulation case
   studies. The proposed predictive maintenance decision model is compared
   with three policies, which are state-based policy (SBP), time-based
   policy (TBP) and greedy policy (GP). The numerical studies show that the
   proposed decision model outperforms the policies, and it has the lowest
   system cost that is 9.68\%, 39.07\%, and 39.56\% lower than SBP, TBP,
   and GP, respectively. In addition, the research shows that bottleneck
   identification and mitigation could help manufacturing systems to
   achieve more than 9.00\% throughput improvement.},
Publisher = {IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC},
Address = {445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA},
Type = {Article},
Language = {English},
Affiliation = {Feng, MM (Corresponding Author), Changan Univ, Sch Foreign Language Studies, Xian 710054, Shaanxi, Peoples R China.
   Feng, Maomao, Changan Univ, Sch Foreign Language Studies, Xian 710054, Shaanxi, Peoples R China.
   Li, Yang, Northwestern Polytech Univ, Sch Mech Engn, Dept Ind Engn, Xian 710072, Shaanxi, Peoples R China.},
DOI = {10.1109/ACCESS.2022.3151170},
ISSN = {2169-3536},
Keywords = {Maintenance engineering; Production systems; Production; Predictive
   maintenance; Predictive models; Markov processes; Costs; Production
   system analysis; Markov chain model; predictive maintenance; decision
   making; approximate dynamic programming; bottleneck},
Research-Areas = {Computer Science; Engineering; Telecommunications},
Web-of-Science-Categories  = {Computer Science, Information Systems; Engineering, Electrical \&
   Electronic; Telecommunications},
Author-Email = {mfeng7@chd.edu.cn},
ORCID-Numbers = {Li, Yang/0000-0002-7127-9905},
Cited-References = {Ahmad R, 2012, COMPUT IND ENG, V63, P135, DOI 10.1016/j.cie.2012.02.002.
   Auschitzky E., 2014, BIG DATA CAN IMPROVE, P822.
   Chang Q, 2007, J MANUF SCI E-T ASME, V129, P661, DOI 10.1115/1.2716713.
   Chang Q, 2013, IEEE T AUTOM SCI ENG, V10, P334, DOI 10.1109/TASE.2012.2210874.
   Chen YM, 2022, IEEE T RELIAB, V71, P484, DOI 10.1109/TR.2020.3044596.
   Csaji BC, 2006, ADV ENG INFORM, V20, P279, DOI 10.1016/j.aei.2006.01.001.
   Cui P.-H., 2021, INT J PROD RES, V2021, P1.
   Iravani SMR, 2002, IIE TRANS, V34, P423, DOI 10.1023/A:1013596731865.
   Jardine AKS, 2006, MECH SYST SIGNAL PR, V20, P1483, DOI 10.1016/j.ymssp.2005.09.012.
   LeCun Y, 2015, NATURE, V521, P436, DOI 10.1038/nature14539.
   Li JS, 2004, IIE TRANS, V36, P755, DOI 10.1080/07408170490458553.
   Li Y, 2018, IEEE T AUTOM SCI ENG, V15, P92, DOI 10.1109/TASE.2016.2585679.
   Li Y, 2017, INT J PROD RES, V55, P4753, DOI 10.1080/00207543.2017.1292063.
   Li Y, 2015, IEEE T SYST MAN CY-S, V45, P109, DOI 10.1109/TSMC.2014.2316268.
   Li Y, 2014, INT J PROD RES, V52, P4239, DOI 10.1080/00207543.2013.874606.
   McDonnell P, 2005, INT J PROD RES, V43, P4321, DOI 10.1080/00207540500142431.
   Meerkov SM, 2010, INT J PROD RES, V48, P4745, DOI 10.1080/00207540903032874.
   Mnih V, 2015, NATURE, V518, P529, DOI 10.1038/nature14236.
   Najid NM, 2011, INT J PROD RES, V49, P2265, DOI 10.1080/00207541003620386.
   Peng SL, 2021, COMPUT IND ENG, V158, DOI 10.1016/j.cie.2021.107321.
   Raza A, 2017, PROC CIRP, V59, P95, DOI 10.1016/j.procir.2016.09.032.
   Schmidhuber J, 2015, NEURAL NETWORKS, V61, P85, DOI 10.1016/j.neunet.2014.09.003.
   Shahrabi J, 2017, COMPUT IND ENG, V110, P75, DOI 10.1016/j.cie.2017.05.026.
   Takata S, 2004, CIRP ANN-MANUF TECHN, V53, P643, DOI 10.1016/S0007-8506(07)60033-X.
   TESAURO G, 1995, COMMUN ACM, V38, P58, DOI 10.1145/203330.203343.
   Van Horenbeek A, 2013, RELIAB ENG SYST SAFE, V120, P39, DOI 10.1016/j.ress.2013.02.029.
   Wong CS, 2013, INT J PROD RES, V51, P883, DOI 10.1080/00207543.2012.677070.
   Xia TB, 2013, INT J PROD RES, V51, P4585, DOI 10.1080/00207543.2013.775524.
   Yang HB, 2021, RELIAB ENG SYST SAFE, V214, DOI 10.1016/j.ress.2021.107713.
   Zhang L, 2013, IIE TRANS, V45, P528, DOI 10.1080/0740817X.2012.721946.
   Zhang P, 2021, COMPUT IND ENG, V161, DOI 10.1016/j.cie.2021.107622.},
Number-of-Cited-References = {31},
Times-Cited = {0},
Usage-Count-Last-180-days = {5},
Usage-Count-Since-2013 = {5},
Journal-ISO = {IEEE Access},
Doc-Delivery-Number = {ZH1OO},
Web-of-Science-Index = {Science Citation Index Expanded (SCI-EXPANDED)},
Unique-ID = {WOS:000760716000001},
OA = {gold},
DA = {2022-04-30},
}

@article{ WOS:000580226800023,
Author = {Samsonov, Vladimir and Behery, Mohamed and Lakemeyer, Gerhard},
Title = {Reinforcement Learning for Short-Term Production Scheduling with
   Sequence-Dependent Setup Waste},
Journal = {ERCIM NEWS},
Year = {2020},
Number = {122, SI},
Pages = {38-39},
Month = {JUL},
Abstract = {Continually refined and adjusted methods for production planning are
   among the cornerstones of manufacturing excellence. Heuristics and
   metaheuristic methods developed to address these tasks are often hard to
   deploy or lead to suboptimal results under constantly changing
   conditions combined with short response times of modern production
   planning. Within the DFG-funded Cluster of Excellence ``Internet of
   Production{''}, a team of researchers from RWTH Aachen University is
   investigating the use of novel deep learning algorithms to facilitate
   complex decision-making processes along the manufacturing chain.},
Publisher = {EUROPEAN RESEARCH CONSORTIUM INFORMATICS \& MATHEMATICS},
Address = {2004, ROUTE LUCIOLES, BP 93, SOPHIA ANTIPOLIS CEDEX, 06902, FRANCE},
Type = {Article},
Language = {English},
Affiliation = {Samsonov, V (Corresponding Author), Cybernet Lab IMA, Aachen, Germany.
   Samsonov, V (Corresponding Author), Rhein Westfal TH Aachen, IfU, Aachen, Germany.
   Lakemeyer, G (Corresponding Author), Rhein Westfal TH Aachen, KBSG, Aachen, Germany.
   Samsonov, Vladimir, Cybernet Lab IMA, Aachen, Germany.
   Samsonov, Vladimir; Behery, Mohamed; Lakemeyer, Gerhard, Rhein Westfal TH Aachen, Aachen, Germany.},
ISSN = {0926-4981},
EISSN = {1564-0094},
Research-Areas = {Computer Science},
Web-of-Science-Categories  = {Computer Science, Interdisciplinary Applications},
Author-Email = {vladimir.samsonov@ima-ifu.rwth-aachen.de
   gerhard@kbsg.rwth-aachen.de},
Cited-References = {Bello I., 2016, ARXIV.
   Nazari Mohammad, 2018, NIPS.
   Silver D., 2017, NATURE.},
Number-of-Cited-References = {3},
Times-Cited = {0},
Usage-Count-Last-180-days = {0},
Usage-Count-Since-2013 = {4},
Journal-ISO = {ERCIM News},
Doc-Delivery-Number = {OE0IY},
Web-of-Science-Index = {Emerging Sources Citation Index (ESCI)},
Unique-ID = {WOS:000580226800023},
DA = {2022-04-30},
}

@article{ WOS:000291895400007,
Author = {Hatono, Itsuo and Yokota, Katsutoshi and Fukunaga, Shifumi},
Title = {A Study on Machine Learning Based Modeling of Skilled Worker Agents for
   Production Planing Laerning Support Systems in Street Production},
Journal = {TETSU TO HAGANE-JOURNAL OF THE IRON AND STEEL INSTITUTE OF JAPAN},
Year = {2011},
Volume = {97},
Number = {6, SI},
Pages = {347-351},
Month = {JUN},
Abstract = {This paper deals with machine learning based modelling of skilled worker
   agents for production planing learning support systems in steel
   production. In this paper, a try-and-error process in generating a
   schedule is assumed to consist of three steps: (I) select appropriate
   priority rules and evaluation items, (2) generate a schedule by using
   the priority rules, (3) evaluate of the generated schedule and revise
   the priority rules based on the evacuation. The scheduling generation
   processis modelledby using Stochastic Learning Automata, whichisakindof
   reinforcement learning method, to obtain thee.ective `know-how' fora
   production planning learning support system. Asimulation experiment has
   been carried out in order to evaluate the model. The simulation results
   suggested that the know-hows obtained in the simulation experiments may
   be able to apply them into a production planning learning support
   system.},
Publisher = {IRON STEEL INST JAPAN KEIDANREN KAIKAN},
Address = {NIIKURA BLDG 2F, 2 KANDA-TSUKASACHO 2-CHOME, TOKYO, CHIYODA-KU 101-0048,
   JAPAN},
Type = {Article},
Language = {Japanese},
Affiliation = {Hatono, I (Corresponding Author), Kobe Univ, Informat Sci \& Technol Ctr, Nada Ku, 1-1 Rokko Dai, Kobe, Hyogo 6578501, Japan.
   Hatono, Itsuo, Kobe Univ, Informat Sci \& Technol Ctr, Nada Ku, Kobe, Hyogo 6578501, Japan.
   Yokota, Katsutoshi, Kobe Univ, Grad Sch Engn, Kobe, Hyogo 6578501, Japan.
   Fukunaga, Shifumi, Kobe Univ, Grad Sch Syst Informat, Kobe, Hyogo 6578501, Japan.},
DOI = {10.2355/tetsutohagane.97.347},
ISSN = {0021-1575},
Keywords = {agents; scheduling; training support system; simulation; reinforcement
   learning},
Research-Areas = {Metallurgy \& Metallurgical Engineering},
Web-of-Science-Categories  = {Metallurgy \& Metallurgical Engineering},
Cited-References = {FUJII N, 2009, CAMP ISIJ, V22, P1010.
   HATONO I, 2009, CAMP ISIJ, V22, P1006.
   NARENDRA K, 1994, LEARNING AUTOMATA IN.
   Tamaki H., 2008, CAMP ISIJ, V21, P1094.
   Tamaki H., 2007, CAMP ISIJ, V20, P934.
   UENO N, 1993, SYST CONTROL INFO, V37, P237.},
Number-of-Cited-References = {6},
Times-Cited = {1},
Usage-Count-Last-180-days = {2},
Usage-Count-Since-2013 = {8},
Journal-ISO = {Tetsu To Hagane-J. Iron Steel Inst. Jpn.},
Doc-Delivery-Number = {780XT},
Web-of-Science-Index = {Science Citation Index Expanded (SCI-EXPANDED)},
Unique-ID = {WOS:000291895400007},
OA = {gold},
DA = {2022-04-30},
}

@inproceedings{ WOS:000687430602104,
Author = {Gannouni, Aymen and Samsonov, Vladimir and Behery, Mohamed and Meisen,
   Tobias and Lakemeyer, Gerhard},
Book-Group-Author = {IEEE},
Title = {Neural Combinatorial Optimization for Production Scheduling with
   Sequence-Dependent Setup Waste},
Booktitle = {2020 IEEE INTERNATIONAL CONFERENCE ON SYSTEMS, MAN, AND CYBERNETICS
   (SMC)},
Series = {IEEE International Conference on Systems Man and Cybernetics Conference
   Proceedings},
Year = {2020},
Pages = {2640-2647},
Note = {IEEE International Conference on Systems, Man, and Cybernetics (SMC),
   ELECTR NETWORK, OCT 11-14, 2020},
Organization = {IEEE; IEEE Syst Man \& Cybernet Soc; IEEE Brain; Intheon; Guger
   Technologies},
Abstract = {One of the main objectives of production planning is to minimize the
   usage of resources and manufacturing-related costs while meeting the
   customer's requirements, such as delivery dates and quality. Production
   planners deal with various scheduling problems that are often NP-hard
   and can not be optimally solved by humans. Solving such problems often
   relies on methods from the Operations Research (OR) field. Recently,
   Neural Combinatorial Optimization (NCO) has emerged as a promising field
   of research that aims at tackling different optimization tasks using the
   latest advancements in machine learning, including deep reinforcement
   learning. These methods can be successfully used for short-term
   production planning because of their flexibility and speed. In this
   paper, we examine the applicability and scalability of neural
   combinatorial optimization methods in the context of production
   planning. We define an evaluation metric to investigate the stability
   and quality of the solutions. Furthermore, we develop an experimental
   setup allowing to compare various approaches for production scheduling
   with sequence-dependent setup costs under real-world production
   conditions. Although an optimality gap is observed when compared to
   established OR methods, our experiments demonstrate the superiority of
   NCO in terms of scheduling time.},
Publisher = {IEEE},
Address = {345 E 47TH ST, NEW YORK, NY 10017 USA},
Type = {Proceedings Paper},
Language = {English},
Affiliation = {Gannouni, A (Corresponding Author), Rhein Westfal TH Aachen, Inst Informat Management Mech Engn, Aachen, Germany.
   Gannouni, Aymen; Samsonov, Vladimir, Rhein Westfal TH Aachen, Inst Informat Management Mech Engn, Aachen, Germany.
   Behery, Mohamed; Lakemeyer, Gerhard, Rhein Westfal TH Aachen, Knowledge Based Syst Grp, Aachen, Germany.
   Meisen, Tobias, Univ Wuppertal, Chair Technol \& Management Digital Transformat, Wuppertal, Germany.},
ISSN = {1062-922X},
ISBN = {978-1-7281-8526-2},
Keywords = {Neural Combinatorial Optimization; Supervised Machine Learning;
   Production Scheduling; Deep Reinforcement Learning},
Keywords-Plus = {TRAVELING SALESMAN PROBLEM; VEHICLE-ROUTING PROBLEM},
Research-Areas = {Computer Science},
Web-of-Science-Categories  = {Computer Science, Cybernetics; Computer Science, Information Systems},
Author-Email = {aymen.gannouni@ima.rwth-aachen.de
   vladimir.samsonov@ima.rwth-aachen.de
   behery@kbsg.rwth-aachen.de
   meisen@uni-wuppertal.de
   gerhard@kbsg.rwth-aachen.de},
ResearcherID-Numbers = {Gannouni, Aymen/AAI-3834-2021
   },
ORCID-Numbers = {Gannouni, Aymen/0000-0002-7102-5307
   Samsonov, Vladimir/0000-0003-4147-6470},
Funding-Acknowledgement = {German Research Foundation (DFG)German Research Foundation (DFG)
   {[}EXC-2023]},
Funding-Text = {The authors would like to thank the German Research Foundation (DFG) for
   the kind support within the Cluster of Excellence -EXC-2023 Internet of
   Production -390621612.},
Cited-References = {Allahverdi A, 1999, OMEGA-INT J MANAGE S, V27, P219, DOI 10.1016/S0305-0483(98)00042-5.
   Allahverdi A, 2008, EUR J OPER RES, V187, P978, DOI 10.1016/j.ejor.2006.09.010.
   Baker K.R., 2009, PRINCIPLES SEQUENCIN.
   Bektas T, 2006, OMEGA-INT J MANAGE S, V34, P209, DOI 10.1016/j.omega.2004.10.004.
   Bello I., 2016, ARXIV.
   Bengio Y, 2018, ARXIV PREPRINT ARXIV.
   Chen HK, 2009, COMPUT OPER RES, V36, P2311, DOI 10.1016/j.cor.2008.09.010.
   Chen X, 1998, COMPUT OPER RES, V25, P1127, DOI 10.1016/S0305-0548(98)00018-5.
   Francois-Lavet V, 2018, FOUND TRENDS MACH LE, V11, P219, DOI 10.1561/2200000071.
   Fu LL, 2017, INT J PROD RES, V55, P5942, DOI 10.1080/00207543.2017.1308572.
   GRAVES SC, 1981, OPER RES, V29, P646, DOI 10.1287/opre.29.4.646.
   Gurobi Optimization LLC, 2020, GUROBI OPTIMIZER REF.
   Ke Guolin, 2017, ADV NEURAL INF PROCE, P3146.
   Lawler E. L., 1993, HDB OPERATIONS RES M, V4, P445.
   Lee SM, 2017, UNIFIED APPROACH INT.
   Lundberg SM, 2020, NAT MACH INTELL, V2, P56, DOI 10.1038/s42256-019-0138-9.
   Papadimitriou C. H., 1977, Theoretical Computer Science, V4, P237, DOI 10.1016/0304-3975(77)90012-3.
   Perron L, OR TOOLS.
   Ribeiro MT, 2016, KDD'16: PROCEEDINGS OF THE 22ND ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P1135, DOI 10.1145/2939672.2939778.
   Samsonov V, 2019, 2019 IEEE SYMPOSIUM SERIES ON COMPUTATIONAL INTELLIGENCE (IEEE SSCI 2019), P799, DOI 10.1109/SSCI44817.2019.9002663.
   Shapley L. S., 1953, VALUE N PERSON GAMES, V2, P307, DOI {[}10.7249/P0295, DOI 10.1515/9781400881970-018].
   Smith KA, 1999, INFORMS J COMPUT, V11, P15, DOI 10.1287/ijoc.11.1.15.
   Takac M., 2018, P 32 INT C NEUR INF, P1.
   Tang LX, 2000, EUR J OPER RES, V124, P267, DOI 10.1016/S0377-2217(99)00380-X.
   Vinyals O., 2015, P NIPS, V28, P2692.
   Welling, 2018, ATTENTION LEARN SOLV.
   WILLIAMS RJ, 1992, MACH LEARN, V8, P229, DOI 10.1007/BF00992696.
   Wolf L, 2018, LEARNING MULTIPLE TR.},
Number-of-Cited-References = {28},
Times-Cited = {1},
Usage-Count-Last-180-days = {10},
Usage-Count-Since-2013 = {11},
Doc-Delivery-Number = {BS1DD},
Web-of-Science-Index = {Conference Proceedings Citation Index - Science (CPCI-S)},
Unique-ID = {WOS:000687430602104},
DA = {2022-04-30},
}

@article{ WOS:000523064900001,
Author = {Kumar, Ashish and Dimitrakopoulos, Roussos and Maulen, Marco},
Title = {Adaptive self-learning mechanisms for updating short-term production
   decisions in an industrial mining complex},
Journal = {JOURNAL OF INTELLIGENT MANUFACTURING},
Year = {2020},
Volume = {31},
Number = {7, SI},
Pages = {1795-1811},
Month = {OCT},
Abstract = {A mining complex is an integrated value chain where the materials
   extracted from a group of mineral deposits are sent to different
   processing streams to produce sellable products. A major short-term
   decision in a mining complex is to determine the flow of materials that
   first includes deciding which handling facilities to send the extracted
   materials and then determining how to utilize the processing facilities.
   The flow of materials through the mining complex is significantly
   dependent on the performance of and interaction between its different
   components. New digital technologies, including the development of
   advanced sensors and monitoring devices, have enabled a mining complex
   to acquire new information about the performance of its different
   components. This paper proposes a new continuous updating framework that
   combines policy gradient reinforcement learning and an extended ensemble
   Kalman filter to adapt the short-term flow of materials in a mining
   complex with incoming information. The framework first uses a new
   extended ensemble Kalman filter to update the uncertainty models of the
   different components of a mining complex with new incoming information.
   Then, the updated uncertainty models are fed to a neural network trained
   using a policy gradient reinforcement learning algorithm to adapt the
   short-term flow of materials in a mining complex. The proposed framework
   is applied to a copper mining complex and shows its ability to
   efficiently adapt the short-term flow of materials in an operational
   mining environment with new incoming information. The framework better
   meets the different production targets while improving the cumulative
   cash flow compared to industry standard approaches.},
Publisher = {SPRINGER},
Address = {VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS},
Type = {Article},
Language = {English},
Affiliation = {Kumar, A (Corresponding Author), McGill Univ, Dept Min \& Mat Engn, COSMO Stochast Mine Planning Lab, FDA Bldg,3450 Univ St, Montreal, PQ H3A 0E8, Canada.
   Kumar, Ashish; Dimitrakopoulos, Roussos, McGill Univ, Dept Min \& Mat Engn, COSMO Stochast Mine Planning Lab, FDA Bldg,3450 Univ St, Montreal, PQ H3A 0E8, Canada.
   Maulen, Marco, BHP, Min Tech, Santiago, Chile.},
DOI = {10.1007/s10845-020-01562-5},
EarlyAccessDate = {APR 2020},
ISSN = {0956-5515},
EISSN = {1572-8145},
Keywords = {Mining complex; Production planning; Artificial intelligence;
   Reinforcement learning; Sensor information; Ensemble Kalman filter;
   Real-time; Destination policies; Deep learning},
Keywords-Plus = {DATA ASSIMILATION; OPTIMIZATION; MODEL; SIMULATION; RECONCILIATION;
   CLASSIFICATION; UNCERTAINTY; INFORMATION; ORE},
Research-Areas = {Computer Science; Engineering},
Web-of-Science-Categories  = {Computer Science, Artificial Intelligence; Engineering, Manufacturing},
Author-Email = {ashish.kumar@mail.mcgill.ca
   roussos.dimitrakopoulos@mcgill.ca
   Marco.Maulen1@bhpbilliton.com},
Funding-Acknowledgement = {National Sciences and Engineering Research Council (NSERC) of Canada CRD
   GrantNatural Sciences and Engineering Research Council of Canada (NSERC)
   {[}500414-16]; NSERC Discovery GrantNatural Sciences and Engineering
   Research Council of Canada (NSERC) {[}239019]; Canada Research Chairs
   ProgramCanada Research Chairs},
Funding-Text = {The work in this paper was funded by the National Sciences and
   Engineering Research Council (NSERC) of Canada CRD Grant 500414-16 and
   NSERC Discovery Grant 239019, the industry consortium members of McGill
   University's COSMO Stochastic Mine Planning Laboratory (AngloGold
   Ashanti, Barrick Gold, BHP, De Beers, IAMGOLD, KinrossGold, Newmont
   Corporation, andVale); and the Canada Research Chairs Program.},
Cited-References = {Aissani N, 2012, J INTELL MANUF, V23, P2513, DOI 10.1007/s10845-011-0580-y.
   Asad MWA, 2016, RESOUR POLICY, V49, P142, DOI 10.1016/j.resourpol.2016.05.005.
   Barde SRA, 2019, J INTELL MANUF, V30, P147, DOI 10.1007/s10845-016-1237-7.
   Benndorf J, 2016, T I MIN METALL A, V125, P54, DOI 10.1080/14749009.2015.1107342.
   Benndorf J, 2015, MATH GEOSCI, V47, P547, DOI 10.1007/s11004-014-9561-y.
   Blom M, 2019, INT J MIN RECLAM ENV, V33, P318, DOI 10.1080/17480930.2018.1448248.
   Bottou L, 2010, COMPSTAT'2010: 19TH INTERNATIONAL CONFERENCE ON COMPUTATIONAL STATISTICS, P177, DOI 10.1007/978-3-7908-2604-3\_16.
   Brewer A, 1999, J INTELL MANUF, V10, P245, DOI 10.1023/A:1008995707211.
   Chen Y, 2012, MATH GEOSCI, V44, P1, DOI 10.1007/s11004-011-9376-z.
   Dalm M, 2019, MATH GEOSCI, V51, P849, DOI 10.1007/s11004-018-9758-6.
   Dalm M, 2014, MINER ENG, V58, P7, DOI 10.1016/j.mineng.2013.12.016.
   Desbarats AJ, 2000, MATH GEOL, V32, P919, DOI 10.1023/A:1007570402430.
   Dimitrakopoulos R, 2002, T I MIN METALL A, V111, pA82.
   Dimitrakopoulos R, 2014, T I MIN METALL A, V123, P90, DOI 10.1179/1743286314Y.0000000062.
   Dimitrakopoulos R, 2004, MATH GEOL, V36, P567, DOI 10.1023/B:MATG.0000037737.11615.df.
   Dovera L, 2011, COMPUTAT GEOSCI, V15, P307, DOI 10.1007/s10596-010-9205-3.
   Nguyen DK, 2015, LECT N PROD ENG, P255, DOI 10.1007/978-3-319-12301-1\_23.
   EVENSEN G, 1994, J GEOPHYS RES-OCEANS, V99, P10143, DOI 10.1029/94JC00572.
   Glorot X., 2010, P 13 INT C ART INT S, P249.
   Goetz AFH, 2009, MINER ENG, V22, P490, DOI 10.1016/j.mineng.2008.12.013.
   Goodfellow R, 2017, MATH GEOSCI, V49, P341, DOI 10.1007/s11004-017-9680-3.
   Goodfellow RC, 2016, APPL SOFT COMPUT, V40, P292, DOI 10.1016/j.asoc.2015.11.038.
   Hinton G. E., 2012, NEURAL NETWROK MACHI.
   Hou J, 2015, PETROL SCI, V12, P114, DOI 10.1007/s12182-014-0005-6.
   Iyakwari S, 2016, MINER ENG, V85, P148, DOI 10.1016/j.mineng.2015.10.020.
   Jewbali A, 2011, COMPUT GEOSCI-UK, V37, P129, DOI 10.1016/j.cageo.2010.04.008.
   Kargupta H., 2010, P 16 ACM SIGKDD INT, P37, DOI {[}10.1145/1835804.1835812, DOI 10.1145/1835804.1835812].
   Koellner WG, 2004, IEEE T IND ELECTRON, V51, P321, DOI 10.1109/TIE.2004.825263.
   Kumar D, 2019, MATH GEOSCI, V51, P75, DOI 10.1007/s11004-018-9762-x.
   Lamghari A, 2017, MATH GEOSCI, V49, P395, DOI 10.1007/s11004-017-9676-z.
   Lane K.F, 1984, APPL COMPUTERS MATH, P485.
   Lane K.F., 1988, EC DEFINITION ORE CU.
   Matamoros MEV, 2016, EUR J OPER RES, V255, P911, DOI 10.1016/j.ejor.2016.05.050.
   Mnih V., 2013, PROC 27 C NEURAL INF, P1.
   Montiel L., 2018, MIN ENG, V70, P48, DOI DOI 10.19150/me.8645.
   Montiel L, 2017, J HEURISTICS, V23, P397, DOI 10.1007/s10732-017-9349-6.
   Montiel L, 2015, EUR J OPER RES, V247, P166, DOI 10.1016/j.ejor.2015.05.002.
   Nair V., 2010, P 27 INT C INT C MAC, P807.
   Mai NL, 2019, RESOUR POLICY, V62, P571, DOI 10.1016/j.resourpol.2018.11.004.
   Paduraru C, 2019, MIN TECHNOL, V128, P129, DOI 10.1080/25726668.2019.1577596.
   Paduraru C, 2018, MIN TECHNOL, V127, P56, DOI 10.1080/14749009.2017.1341142.
   Panzeri M, 2016, COMPUTAT GEOSCI, V20, P637, DOI 10.1007/s10596-015-9540-5.
   Quigley M, 2020, INT J MIN RECLAM ENV, V34, P362, DOI 10.1080/17480930.2019.1658923.
   Rendu J.-M, 2014, INTRO CUT OFF GRADE.
   Rosa L., 2007, P 33 APPL COMP OP RE, P601.
   Rossi ME., 2013, MINERAL RESOURCE EST.
   Ruder S., 2016, ARXIV PREPRINT ARXIV.
   Sarma P, 2006, COMPUTAT GEOSCI, V10, P3, DOI 10.1007/s10596-005-9009-z.
   Shirangi M. G., 2017, THESIS.
   Silver D, 2016, NATURE, V529, P484, DOI 10.1038/nature16961.
   Sutton RS, 2000, ADV NEUR IN, V12, P1057.
   Vargas-Guzman JA, 2002, MATH GEOL, V34, P597, DOI 10.1023/A:1016099029432.
   Verly G, 2005, MATH GEOL, V37, P451, DOI 10.1007/s11004-005-6660-9.
   Vo HX, 2014, MATH GEOSCI, V46, P775, DOI 10.1007/s11004-014-9541-2.
   Wambeke T, 2018, MATH GEOSCI, V50, P801, DOI 10.1007/s11004-018-9740-3.
   Xu T, 2018, ADV WATER RESOUR, V112, P106, DOI 10.1016/j.advwatres.2017.12.011.
   Xue L, 2014, WATER RESOUR RES, V50, P4197, DOI 10.1002/2013WR014525.
   Yuksel C, 2019, MATH GEOSCI, V51, P925, DOI 10.1007/s11004-018-9770-x.},
Number-of-Cited-References = {58},
Times-Cited = {9},
Usage-Count-Last-180-days = {6},
Usage-Count-Since-2013 = {14},
Journal-ISO = {J. Intell. Manuf.},
Doc-Delivery-Number = {NF2LS},
Web-of-Science-Index = {Science Citation Index Expanded (SCI-EXPANDED)},
Unique-ID = {WOS:000523064900001},
OA = {hybrid},
DA = {2022-04-30},
}

@article{ WOS:000311212400018,
Author = {Palombarini, Jorge and Martinez, Ernesto},
Title = {SmartGantt - An interactive system for generating and updating
   rescheduling knowledge using relational abstractions},
Journal = {COMPUTERS \& CHEMICAL ENGINEERING},
Year = {2012},
Volume = {47},
Pages = {202-216},
Month = {DEC 20},
Abstract = {Generating and updating rescheduling knowledge that can be used in real
   time has become a key issue in reactive scheduling due to the dynamic
   and uncertain nature of industrial environments and the emergent trend
   towards cognitive systems in production planning and execution control.
   Disruptive events have a significant impact on the feasibility of plans
   and schedules. In this work, the automatic generation and update through
   learning of rescheduling knowledge using simulated transitions of
   abstract schedule states is proposed. An industrial example where a
   current schedule must be repaired in response to unplanned events such
   as the arrival of a rush order, raw material delay, or an equipment
   failure which gives rise to the need for rescheduling is discussed. A
   software prototype (SmartGantt) for interactive schedule repair in
   real-time is presented. Results demonstrate that responsiveness is
   dramatically improved by using relational reinforcement learning and
   relational abstractions to develop a repair policy. (C) 2012 Elsevier
   Ltd. All rights reserved.},
Publisher = {PERGAMON-ELSEVIER SCIENCE LTD},
Address = {THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND},
Type = {Article},
Language = {English},
Affiliation = {Martinez, E (Corresponding Author), INGAR CONICET UTN, Avellaneda 3657,S3002 GJC, Santa Fe, Argentina.
   Martinez, Ernesto, INGAR CONICET UTN, Santa Fe, Argentina.
   Palombarini, Jorge, GISIQ UTN, RA-5900 Villa Maria, Argentina.},
DOI = {10.1016/j.compchemeng.2012.06.021},
ISSN = {0098-1354},
EISSN = {1873-4375},
Keywords = {Batch plant management; Cognitive production systems; Manufacturing
   control; Rescheduling; Relational reinforcement learning; Uncertainty},
Keywords-Plus = {STRATEGIES},
Research-Areas = {Computer Science; Engineering},
Web-of-Science-Categories  = {Computer Science, Interdisciplinary Applications; Engineering, Chemical},
Author-Email = {ecmarti@santafe-conicet.gob.ar},
Cited-References = {Adhitya A, 2007, AICHE J, V53, P397, DOI 10.1002/aic.11069.
   Blockeel H, 1998, ARTIF INTELL, V101, P285, DOI 10.1016/S0004-3702(98)00034-4.
   Blockeel H, 1999, DATA MIN KNOWL DISC, V3, P59, DOI 10.1023/A:1009867806624.
   Chapman D., 1991, P 12 INT JOINT C ART, P726.
   Croonenborghs T., 2009, THESIS K U LEUVEN LE.
   De Raedt L, 2008, COGN TECHNOL, P1.
   Driessens K., 2003, 20 INT C MACH LEARN.
   Driessens Kurt, 2001, LECT NOTES ARTIF INT, P97.
   Dzeroski S, 2001, MACH LEARN, V43, P7, DOI 10.1023/A:1007694015589.
   Henning GP, 2000, COMPUT CHEM ENG, V24, P2315, DOI 10.1016/S0098-1354(00)00589-5.
   Li ZK, 2008, AICHE J, V54, P2610, DOI 10.1002/aic.11593.
   Martinez EC, 1999, COMPUT CHEM ENG, V23, pS527, DOI 10.1016/S0098-1354(99)80130-6.
   Miyashita K., 2000, International Transactions in Operational Research, V7, P125, DOI 10.1016/S0969-6016(00)00014-9.
   Miyashita K., 1994, ARTIF INTELL, V76, P377.
   MUSIER RFH, 1989, COMPUT CHEM ENG, V13, P229, DOI 10.1016/0098-1354(89)89020-9.
   Palombarini J, 2010, BRAZ J CHEM ENG, V27, P413, DOI 10.1590/S0104-66322010000300006.
   Pfeiffer A, 2007, COMPUT IND, V58, P630, DOI 10.1016/j.compind.2007.05.009.
   Rangsaritratsamee R, 2004, COMPUT IND ENG, V46, P1, DOI 10.1016/j.cie.2003.09.007.
   Shapiro D., 2001, Proceedings of the Fifth International Conference on Autonomous Agents, P254, DOI 10.1145/375735.376305.
   Sutton R. S., 1998, REINFORCEMENT LEARNI.
   Trentesaux D, 2009, ENG APPL ARTIF INTEL, V22, P971, DOI 10.1016/j.engappai.2009.05.001.
   van Otterlo M., 2009, LOGIC ADAPTIVE BEHAV.
   Vieira GE, 2003, J SCHEDULING, V6, P39, DOI 10.1023/A:1022235519958.
   Watkins C.J.C.H, 1989, LEARNING DELAYED REW.
   Wilson JM, 2003, EUR J OPER RES, V149, P430, DOI 10.1016/S0377-2217(02)00769-5.
   Zaeh MF, 2010, ADV ENG INFORM, V24, P300, DOI 10.1016/j.aei.2010.05.014.
   Zhu G, 2005, J OPER RES SOC, V56, P365, DOI 10.1057/palgrave.jors.2601860.
   ZWEBEN M, 1993, IEEE T SYST MAN CYB, V23, P1588, DOI 10.1109/21.257756.},
Number-of-Cited-References = {28},
Times-Cited = {7},
Usage-Count-Last-180-days = {2},
Usage-Count-Since-2013 = {19},
Journal-ISO = {Comput. Chem. Eng.},
Doc-Delivery-Number = {038ZK},
Web-of-Science-Index = {Science Citation Index Expanded (SCI-EXPANDED)},
Unique-ID = {WOS:000311212400018},
DA = {2022-04-30},
}

@article{ WOS:000780113600001,
Author = {van Hezewijk, Lotte and Dellaert, Nico and Van Woensel, Tom and
   Gademann, Noud},
Title = {Using the proximal policy optimisation algorithm for solving the
   stochastic capacitated lot sizing problem},
Journal = {INTERNATIONAL JOURNAL OF PRODUCTION RESEARCH},
Abstract = {This paper studies the multi-item stochastic capacitated lot-sizing
   problem with stationary demand to minimise set-up, holding, and
   backorder costs. This is a common problem in the industry, concerning
   both inventory management and production planning. We study the
   applicability of the Proximal Policy Optimisation (PPO) algorithm in
   this problem, which is a type of Deep Reinforcement Learning (DRL). The
   problem is modelled as a Markov Decision Process (MDP), which can be
   solved to optimality in small problem instances by using Dynamic
   Programming. In these settings, we show that the performance of PPO
   approaches the optimal solution. For larger problem instances with an
   increasing number of products, solving to optimality is intractable, and
   we demonstrate that the PPO solution outperforms the benchmark solution.
   Several adjustments to the standard PPO algorithm are implemented to
   make it more scalable to larger problem instances. We show the linear
   growth in computation time for the algorithm, and present a method for
   explaining the outcomes of the algorithm. We suggest future research
   directions that could improve the scalability and explainability of the
   PPO algorithm.},
Publisher = {TAYLOR \& FRANCIS LTD},
Address = {2-4 PARK SQUARE, MILTON PARK, ABINGDON OR14 4RN, OXON, ENGLAND},
Type = {Article; Early Access},
Language = {English},
Affiliation = {van Hezewijk, L (Corresponding Author), Eindhoven Univ Technol, Atlas 4-402,POB 513, NL-5600 MB Eindhoven, Netherlands.
   van Hezewijk, Lotte; Dellaert, Nico; Van Woensel, Tom, Eindhoven Univ Technol, Dept Ind Engn \& Innovat Sci, Eindhoven, Netherlands.
   van Hezewijk, Lotte; Gademann, Noud, ORTEC BV, Houtsingel 5, NL-2719 EA Zoetermeer, Netherlands.},
DOI = {10.1080/00207543.2022.2056540},
EarlyAccessDate = {APR 2022},
ISSN = {0020-7543},
EISSN = {1366-588X},
Keywords = {Capacitated lot sizing problem; multi-item; stochastic demand; deep
   reinforcement learning; proximal policy optimisation},
Keywords-Plus = {INVENTORY CONTROL; DYNAMIC CONTROL; SERVICE-LEVEL; REINFORCEMENT;
   MANAGEMENT; MODELS},
Research-Areas = {Engineering; Operations Research \& Management Science},
Web-of-Science-Categories  = {Engineering, Industrial; Engineering, Manufacturing; Operations Research
   \& Management Science},
Author-Email = {l.v.hezewijk@tue.nl},
Cited-References = {Arrow KJ, 1951, ECONOMETRICA, V19, P250, DOI 10.2307/1906813.
   Axsater Sven., 1993, LOGISTICS PRODUCTION, V4, P175.
   Baker KennethR., 1977, DECISION SCI, V8, P19, DOI {[}10.1111/j.1540-5915.1977.tb01065.x, DOI 10.1111/J.1540-5915.1977.TB01065.X].
   BELLMAN R, 1954, B AM MATH SOC, V60, P503, DOI 10.1090/S0002-9904-1954-09848-8.
   BOOKBINDER JH, 1988, MANAGE SCI, V34, P1096, DOI 10.1287/mnsc.34.9.1096.
   Boute RN, 2022, EUR J OPER RES, V298, P401, DOI 10.1016/j.ejor.2021.07.016.
   Brandimarte P, 2006, INT J PROD RES, V44, P2997, DOI 10.1080/00207540500435116.
   Busoniu L, 2018, ANNU REV CONTROL, V46, P8, DOI 10.1016/j.arcontrol.2018.09.005.
   Chaharsooghi SK, 2008, DECIS SUPPORT SYST, V45, P949, DOI 10.1016/j.dss.2008.03.007.
   De Smet N, 2020, INT J PROD RES, V58, P4980, DOI 10.1080/00207543.2020.1736722.
   DeCroix GA, 1998, MANAGE SCI, V44, P950, DOI 10.1287/mnsc.44.7.950.
   ERLENKOTTER D, 1989, MANAGE SCI, V35, P898, DOI 10.1287/mnsc.35.7.898.
   FEDERGRUEN A, 1984, OPER RES, V32, P1268, DOI 10.1287/opre.32.6.1268.
   Giannoccaro I, 2002, INT J PROD ECON, V78, P153, DOI 10.1016/S0925-5273(00)00156-0.
   Gijsbrechts Joren., 2021, MANUFACTURING SERVIC.
   Glorot X., 2010, P 13 INT C ARTIFICIA, P249.
   Goodfellow I, 2016, ADAPT COMPUT MACH LE, P1.
   Gosavi A, 2007, OR SPECTRUM, V29, P21, DOI 10.1007/s00291-005-0018-z.
   Graves S. C., 1988, Journal of Manufacturing and Operations Management, V1, P67.
   Graves S. C., 2000, Manufacturing \& Service Operations Management, V2, P68, DOI 10.1287/msom.2.1.68.23267.
   Helber S, 2013, OR SPECTRUM, V35, P75, DOI 10.1007/s00291-012-0283-6.
   Heuillet A, 2021, KNOWL-BASED SYST, V214, DOI 10.1016/j.knosys.2020.106685.
   Jans R, 2008, INT J PROD RES, V46, P1619, DOI 10.1080/00207540600902262.
   Jiang CZ, 2009, EXPERT SYST APPL, V36, P6520, DOI 10.1016/j.eswa.2008.07.036.
   Jie T., 2010, ADV NEURAL INFORM PR, P1000.
   Kara A, 2018, EXPERT SYST APPL, V91, P150, DOI 10.1016/j.eswa.2017.08.046.
   Karimi B, 2003, OMEGA-INT J MANAGE S, V31, P365, DOI 10.1016/S0305-0483(03)00059-8.
   Kim CO, 2005, INT J ADV MANUF TECH, V26, P1184, DOI 10.1007/s00170-004-2069-8.
   King DB, 2015, ACS SYM SER, V1214, P1.
   Kool W, 2019, ARXIV180308475V3.
   Kwon IH, 2008, EXPERT SYST APPL, V35, P389, DOI 10.1016/j.eswa.2007.07.002.
   Lee HL, 2004, HARVARD BUS REV, V82, P102.
   Mnih V., 2013, PROC 27 C NEURAL INF, P1.
   Mnih V, 2016, PR MACH LEARN RES, V48.
   Mnih V, 2015, NATURE, V518, P529, DOI 10.1038/nature14236.
   Mula J, 2006, INT J PROD ECON, V103, P271, DOI 10.1016/j.ijpe.2005.09.001.
   Nahmias Steven., 2015, PRODUCTION OPERATION, V7, P249.
   Nahmias Steven., 2015, PRODUCTION OPERATION, V7, P198.
   Oroojlooyjadid Afshin, 2017, ARXIV170805924V3.
   Park J, 2021, INT J PROD RES, V59, P3360, DOI 10.1080/00207543.2020.1870013.
   Paternina-Arboleda CD, 2005, SIMUL MODEL PRACT TH, V13, P389, DOI 10.1016/j.simpat.2004.12.003.
   Pontrandolfo P, 2002, INT J PROD RES, V40, P1299, DOI 10.1080/00207540110118640.
   Powell WB, 2007, APPROXIMATE DYNAMIC PROGRAMMING: SOLVING THE CURSES OF DIMENSIONALITY, P1, DOI 10.1002/9780470182963.
   Rummukainen H, 2019, IFAC PAPERSONLINE, V52, P1415, DOI 10.1016/j.ifacol.2019.11.397.
   Schulman J., 2017, 170706347 ARXIV.
   Schulman J, 2015, PR MACH LEARN RES, V37, P1889.
   Schulman John., 2016, C TRACK P 4 INT C LE.
   SHANNON CE, 1948, BELL SYST TECH J, V27, P379, DOI 10.1002/j.1538-7305.1948.tb01338.x.
   Sutton RS, 2018, ADAPT COMPUT MACH LE, P1.
   Tavaghof-Gigloo D, 2021, INT J PROD RES, V59, P5087, DOI 10.1080/00207543.2020.1773003.
   Tempelmeier H, 2015, COMPUT OPER RES, V59, P119, DOI 10.1016/j.cor.2015.01.007.
   Tempelmeier H, 2011, OMEGA-INT J MANAGE S, V39, P627, DOI 10.1016/j.omega.2011.01.003.
   Tempelmeier Horst., 2006, INVENTORY MANAGEMENT.
   Tempelmeier Horst., 2013, HDB STOCHASTIC MODEL, P313.
   van Donselaar KH, 2010, MANAGE SCI, V56, P766, DOI 10.1287/mnsc.1090.1141.
   Vanvuchelen N, 2020, COMPUT IND, V119, DOI 10.1016/j.compind.2020.103239.
   Wang J, 2012, INT J PROD RES, V50, P4381, DOI 10.1080/00207543.2011.592158.
   Winands EMM, 2011, EUR J OPER RES, V210, P1, DOI 10.1016/j.ejor.2010.06.011.
   Zahavy Tom, 2018, ARXIV180902121, P1.},
Number-of-Cited-References = {59},
Times-Cited = {0},
Usage-Count-Last-180-days = {0},
Usage-Count-Since-2013 = {0},
Journal-ISO = {Int. J. Prod. Res.},
Doc-Delivery-Number = {0J4ZO},
Web-of-Science-Index = {Science Citation Index Expanded (SCI-EXPANDED)},
Unique-ID = {WOS:000780113600001},
OA = {hybrid},
DA = {2022-04-30},
}

@article{ WOS:000274767500009,
Author = {Arredondo, Facundo and Martinez, Ernesto},
Title = {Learning and adaptation of a policy for dynamic order acceptance in
   make-to-order manufacturing},
Journal = {COMPUTERS \& INDUSTRIAL ENGINEERING},
Year = {2010},
Volume = {58},
Number = {1},
Pages = {70-83},
Month = {FEB},
Abstract = {Order acceptance under uncertainty is a critical decision-making problem
   at the interface between customer relationship management and production
   planning of order-driven manufacturing systems. In this work, a novel
   approach for simulation-based development and on-line adaptation of a
   policy for dynamic order acceptance under uncertainty in make-to-order
   manufacturing using average-reward reinforcement learning is proposed.
   Locally weighted regression is used to generalize the gain value of
   accepting or rejecting similar orders regarding attributes such as
   product mix, price, size and due date. The order acceptance policy is
   learned by classifying an arriving order as belonging either to the
   acceptance set or to the rejection set. For exploitation, only orders in
   the acceptance set must be chosen for shop-floor scheduling. For
   exploration some orders from the rejection set are also considered as
   candidates for acceptance. Comparisons made with different order
   acceptance heuristics highlight the effectiveness of the proposed ARLOA
   algorithm to maximize the average revenue obtained per unit cost of
   installed capacity whilst quickly responding to unknown variations in
   order arrival rates and attributes. (C) 2009 Elsevier Ltd. All rights
   reserved.},
Publisher = {PERGAMON-ELSEVIER SCIENCE LTD},
Address = {THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND},
Type = {Article},
Language = {English},
Affiliation = {Martinez, E (Corresponding Author), INGAR CONICET UTN, S3002 GJC, RA-3657 Avellaneda, Santa Fe, Argentina.
   Arredondo, Facundo; Martinez, Ernesto, INGAR CONICET UTN, RA-3657 Avellaneda, Santa Fe, Argentina.},
DOI = {10.1016/j.cie.2009.08.005},
ISSN = {0360-8352},
EISSN = {1879-0550},
Keywords = {Order acceptance; Demand management; Reinforcement learning;
   Make-to-order manufacturing; Revenue management; Order similarity},
Keywords-Plus = {REVENUE MANAGEMENT; STRATEGIES; AGGREGATE; SUPPORT; TIMES},
Research-Areas = {Computer Science; Engineering},
Web-of-Science-Categories  = {Computer Science, Interdisciplinary Applications; Engineering,
   Industrial},
Author-Email = {ecmarti@santafe-conicet.gov.ar},
Cited-References = {Atkeson CG, 1997, ARTIF INTELL REV, V11, P11, DOI 10.1023/A:1006559212014.
   Barut M, 2005, DECISION SCI, V36, P287, DOI 10.1111/j.1540-5414.2005.00074.x.
   Barut M, 2004, EUR J OPER RES, V155, P112, DOI 10.1016/S0377-2217(02)00860-3.
   Calosso T, 2004, ROBOT CIM-INT MANUF, V20, P405, DOI 10.1016/j.rcim.2004.03.003.
   Calosso T, 2003, INT J PROD ECON, V85, P233, DOI 10.1016/S0925-5273(03)00112-9.
   Das TK, 1999, MANAGE SCI, V45, P560, DOI 10.1287/mnsc.45.4.560.
   Defregger F, 2007, OR SPECTRUM, V29, P137, DOI 10.1007/s00291-005-0016-1.
   Ebben MJR, 2005, OR SPECTRUM, V27, P107, DOI 10.1007/s00291-004-0171-9.
   Enns ST, 2002, PROD PLAN CONTROL, V13, P614, DOI 10.1080/0953728021000026258.
   Enns ST, 2000, INT J PROD ECON, V63, P229, DOI 10.1016/S0925-5273(99)00024-9.
   Herbots J, 2007, NAV RES LOG, V54, P874, DOI 10.1002/nav.20259.
   Hing MM, 2007, J HEURISTICS, V13, P167, DOI 10.1007/s10732-006-9006-y.
   HING MM, 2001, 66 U TWENT.
   HING MM, 2006, THESIS U TWENTE EIND.
   IVANESCU C, 2004, THESIS TU EINDHOVEN.
   Ivanescu CV, 2002, OR SPECTRUM, V24, P467.
   Jalora A., 2006, THESIS TEXAS A M U.
   MOREIRA M, 2005, THESIS U PORTO PORTU.
   Nandi A, 2003, PROCEEDINGS OF THE 2003 WINTER SIMULATION CONFERENCE, VOLS 1 AND 2, P1251, DOI 10.1109/WSC.2003.1261558.
   Nandi A, 2004, SIMUL-T SOC MOD SIM, V80, P131, DOI 10.1177/0037549704045046.
   NAWIJN WM, 1985, OPER RES, V33, P625, DOI 10.1287/opre.33.3.625.
   PHILIPOOM PR, 1992, INT J PROD RES, V30, P2559, DOI 10.1080/00207549208948176.
   Quante R, 2009, OR SPECTRUM, V31, P31, DOI 10.1007/s00291-008-0125-8.
   Raaymakers WHM, 2000, IIE TRANS, V32, P989, DOI 10.1080/07408170008967456.
   Raaymakers WHM, 2000, J INTELL MANUF, V11, P217, DOI 10.1023/A:1008999002145.
   RAAYMAKERS WHM, 1999, THESIS TU EINDHOVEN.
   SCHWARTZ A, 1993, P 10 INT C MACH LEAR, P298.
   SINGH S, 1994, P 12 NAT C ART INT 2.
   Smart W. D., 2000, P 17 INT C MACH LEAR, P903.
   SNOEK M, 2000, P 7 INT C NEUR INF P, P815.
   Sutton R. S., 1998, REINFORCEMENT LEARNI.
   TENKATE HA, 1994, INT J PROD ECON, V37, P139, DOI 10.1016/0925-5273(94)90014-0.
   WANG J, 1994, MATH COMPUT MODEL, V19, P1, DOI 10.1016/0895-7177(94)90086-8.
   WESTER FAW, 1992, INT J PROD RES, V30, P1313, DOI 10.1080/00207549208942959.
   Wight O., 1970, PROD INVEN MANAGE, V11, P9.
   Wouters MJF, 1997, PROD PLAN CONTROL, V8, P2, DOI 10.1080/095372897235497.
   Zorzini M, 2008, INT J PROD ECON, V112, P919, DOI 10.1016/j.ijpe.2007.08.005.},
Number-of-Cited-References = {37},
Times-Cited = {30},
Usage-Count-Last-180-days = {3},
Usage-Count-Since-2013 = {36},
Journal-ISO = {Comput. Ind. Eng.},
Doc-Delivery-Number = {558SW},
Web-of-Science-Index = {Science Citation Index Expanded (SCI-EXPANDED)},
Unique-ID = {WOS:000274767500009},
DA = {2022-04-30},
}

@inproceedings{ WOS:000771712000024,
Author = {Dasbach, Thomas and Olbort, Johannes and Wenk, Felix and Ander, Reiner},
Editor = {Junior, OC and Noel, F and Rivest, L and Bouras, A},
Title = {Sequencing Through a Global Decision Instance Based on a Neural Network},
Booktitle = {PRODUCT LIFECYCLE MANAGEMENT: GREEN AND BLUE TECHNOLOGIES TO SUPPORT
   SMART AND SUSTAINABLE ORGANIZATIONS, PT I},
Series = {IFIP Advances in Information and Communication Technology},
Year = {2022},
Volume = {639},
Pages = {334-344},
Note = {18th IFIP WG 5.1 International Conference on Product Lifecycle
   Management (PLM), ELECTR NETWORK, JUL 11-14, 2021},
Organization = {Int Federat Informat Proc Working Grp 5 1; Pontif Catholic Univ Parana},
Abstract = {An existing concept for sequence planning in production planning and
   control was extended by a global decision instance based on neural
   networks. Therefore, information regarding the state of the production
   and available orders were normalized and analyzed by one agent. In
   contrast to a partially observable Markow Decision Problem one single
   agent was allowed and used to process all available information.
   Feasibility and problems were examined and compared with a concept for
   decentralized decisions. The implementation consists of two parts, which
   continuously interact with each other. One part is a simulation of a job
   shop, including multiple machines. The other parts tackle the Markow
   Decision Problem with the use of double Q reinforcement learning in
   order to estimate the best sequence at any given time. Later, problems
   due to scaling and comparisons to the usage of multiple agents are
   given.},
Publisher = {SPRINGER INTERNATIONAL PUBLISHING AG},
Address = {GEWERBESTRASSE 11, CHAM, CH-6330, SWITZERLAND},
Type = {Proceedings Paper},
Language = {English},
Affiliation = {Dasbach, T (Corresponding Author), Tech Univ Darmstadt, DiK, Otto Berndt Str 2, Darmstadt, Germany.
   Dasbach, Thomas; Olbort, Johannes; Wenk, Felix; Ander, Reiner, Tech Univ Darmstadt, DiK, Otto Berndt Str 2, Darmstadt, Germany.},
DOI = {10.1007/978-3-030-94335-6\_24},
ISSN = {1868-4238},
EISSN = {1868-422X},
ISBN = {978-3-030-94335-6; 978-3-030-94334-9},
Keywords = {Sequence planning; Artificial intelligence; Neural network},
Research-Areas = {Computer Science; Science \& Technology - Other Topics; Engineering},
Web-of-Science-Categories  = {Computer Science, Information Systems; Green \& Sustainable Science \&
   Technology; Engineering, Industrial},
Author-Email = {dasbach@dik.tu-darmstadt.de},
ResearcherID-Numbers = {Anderl, Reiner/P-9130-2014},
ORCID-Numbers = {Anderl, Reiner/0000-0001-7681-2118},
Cited-References = {Claus T, 2015, PRODUKTIONSPLANUNG S, DOI {[}10.1007/978-3-662-43542-7, DOI 10.1007/978-3-662-43542-7].
   Huang D.-S, 2006, LNCS LNAI, V4114, DOI {[}10.1007/11816171, DOI 10.1007/11816171].
   Jaehn F, 2014, ABLAUFPLANUNG EINFUH, DOI {[}10.1007/978-3-642-54439-2, DOI 10.1007/978-3-642-54439-2].
   Lillicrap T.P., 2015, ARXIV PREPRINT ARXIV.
   Lin Z, 2019, OPTIMIZATION, V68, P2088, DOI 10.1080/02331934.2019.1658759.
   Lodding H., 2016, VERFAHREN FERTIGUNGS, DOI {[}10.1007/978-3-662-48459-3, DOI 10.1007/978-3-662-48459-3].
   ROSENBLATT F, 1958, PSYCHOL REV, V65, P386, DOI 10.1037/h0042519.
   Sutton RS, 2018, ADAPT COMPUT MACH LE, P1.
   Swamidass P.M, 2000, ENCY PRODUCTION MANU.
   Wuendahl H.-P, 2010, BETRIEBSORGANISATION.},
Number-of-Cited-References = {10},
Times-Cited = {0},
Usage-Count-Last-180-days = {0},
Usage-Count-Since-2013 = {0},
Doc-Delivery-Number = {BS8EB},
Web-of-Science-Index = {Conference Proceedings Citation Index - Science (CPCI-S)},
Unique-ID = {WOS:000771712000024},
DA = {2022-04-30},
}

@article{ WOS:000637162400001,
Author = {Tanimoto, Akira},
Title = {Combinatorial Q-Learning for Condition-Based Infrastructure Maintenance},
Journal = {IEEE ACCESS},
Year = {2021},
Volume = {9},
Pages = {46788-46799},
Abstract = {Infrastructure maintenance planning is a large-scale optimization
   problem of planning when and on which components to carry out
   maintenance so as to keep the whole infrastructure in good condition
   with minimal maintenance cost. Recent advances in condition monitoring
   techniques have enabled timely maintenance in response to the condition
   of each part regardless of age. In addition to the condition, the
   spatial structure is also important for cost-efficiency in
   infrastructure maintenance since traveling costs and/or setup costs can
   be saved by simultaneous maintenance of neighboring components, which is
   called economic dependency. This optimization problem naively has a high
   computational complexity of O(2(nH)), where n is the number of
   components and H is the planning horizon, and the predictive modeling of
   degradation is also a big issue. To solve this problem efficiently at
   scale, our proposed method utilizes two kinds of dynamic programming for
   temporal and spatial scalability and consequently enjoys O(n) complexity
   at each time step. For temporal scalability, we utilize a direct
   modeling approach for the action value of maintenance instead of
   modeling degradation, namely, Q-learning. For spatial scalability, we
   exploit locality in economic dependency by means of a reasonable
   approximation of the Q-function. A typical baseline approach is to
   divide the whole infrastructure into fixed groups of neighboring
   components beforehand and determine if maintenance should be performed
   for all the components in each group at each time step. In contrast, our
   scalable method enables fully combinatorial optimization for each
   component at each time step. We demonstrate the advantage of our method
   in a simulated environment, and the resulting maintenance history
   intuitively illustrates the benefit of our dynamic grouping approach. We
   also show that our method has a kind of interpretability in the
   optimization at each time step.},
Publisher = {IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC},
Address = {445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA},
Type = {Article},
Language = {English},
Affiliation = {Tanimoto, A (Corresponding Author), NEC Corp Ltd, Kawasaki, Kanagawa 2110011, Japan.
   Tanimoto, Akira, NEC Corp Ltd, Kawasaki, Kanagawa 2110011, Japan.},
DOI = {10.1109/ACCESS.2021.3059244},
ISSN = {2169-3536},
Keywords = {Predictive maintenance; artificial intelligence; decision support
   systems; reinforcement learning; combinatorial optimization; dynamic
   programming},
Keywords-Plus = {PREDICTIVE MAINTENANCE; REINFORCEMENT; MODELS},
Research-Areas = {Computer Science; Engineering; Telecommunications},
Web-of-Science-Categories  = {Computer Science, Information Systems; Engineering, Electrical \&
   Electronic; Telecommunications},
Author-Email = {a.tanimoto@nec.com},
ResearcherID-Numbers = {Tanimoto, Akira/AAX-8864-2021},
Cited-References = {Adlinge S.S., 2013, INT J INNOVATIVE RES, V2, P437.
   Aissani N, 2009, ENG APPL ARTIF INTEL, V22, P1089, DOI 10.1016/j.engappai.2009.01.014.
   Andriotis C. P., 2020, ARXIV200701380.
   Arulkumaran K, 2017, IEEE SIGNAL PROC MAG, V34, P26, DOI 10.1109/MSP.2017.2743240.
   Barde SRA, 2019, J INTELL MANUF, V30, P147, DOI 10.1007/s10845-016-1237-7.
   Bousdekis Alexandros, 2018, Journal of Intelligent Manufacturing, V29, P1303, DOI 10.1007/s10845-015-1179-5.
   Chambon S, 2011, INT J GEOPHYS, V2011, DOI 10.1155/2011/989354.
   Compare M, 2018, INT J ADV MANUF TECH, V99, P2981, DOI 10.1007/s00170-018-2690-6.
   Dekker R, 1997, MATH METHOD OPER RES, V45, P411, DOI 10.1007/BF01194788.
   Famurewa SM, 2015, P I MECH ENG F-J RAI, V229, P12, DOI 10.1177/0954409713495667.
   Getoor L., 2007, INTRO STAT RELATIONA.
   Gu SX, 2016, PR MACH LEARN RES, V48.
   Hong S.S., 2003, INT J PAVEMENT ENG, VVol. 4, P235, DOI DOI 10.1080/10298430410001672246.
   Inaudi D, 2010, J PRESS VESS-T ASME, V132, DOI 10.1115/1.3062942.
   Jardine A.K.S., 2005, MAINTENANCE REPLACEM.
   Kim S, 2007, PROCEEDINGS OF THE SIXTH INTERNATIONAL SYMPOSIUM ON INFORMATION PROCESSING IN SENSOR NETWORKS, P254, DOI 10.1145/1236360.1236395.
   Kuhnle A, 2019, PROD ENG-RES DEV, V13, P33, DOI 10.1007/s11740-018-0855-7.
   Li HN, 2004, ENG STRUCT, V26, P1647, DOI 10.1016/j.engstruct.2004.05.018.
   Liu JM, 2016, KDD'16: PROCEEDINGS OF THE 22ND ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P1005, DOI 10.1145/2939672.2939776.
   Liu Y, 2020, EUR J OPER RES, V283, P166, DOI 10.1016/j.ejor.2019.10.049.
   Mnih V., 2013, ARXIV.
   Nguyen KA, 2015, RELIAB ENG SYST SAFE, V144, P83, DOI 10.1016/j.ress.2015.07.017.
   Nicolai RP, 2008, SPRINGER SER RELIAB, P263, DOI 10.1007/978-1-84800-011-7\_11.
   Papadakis IS, 2005, OR SPECTRUM, V27, P63, DOI 10.1007/s00291-004-0167-5.
   Peng CY, 2013, IEEE T RELIAB, V62, P338, DOI 10.1109/TR.2013.2257055.
   Peng Y, 2010, INT J ADV MANUF TECH, V50, P297, DOI 10.1007/s00170-009-2482-0.
   Riedmiller M, 2005, LECT NOTES ARTIF INT, V3720, P317.
   Shahriari B, 2016, P IEEE, V104, P148, DOI 10.1109/JPROC.2015.2494218.
   Singh SP, 1996, MACH LEARN, V22, P123.
   Snoek J., 2012, ADV NEURAL INFORM PR, V25, P2951.
   Srivastava NK, 2016, GLOB BUS REV, V17, P105, DOI 10.1177/0972150915610697.
   Su Z, 2019, TRANSPORT RES C-EMER, V105, P359, DOI 10.1016/j.trc.2019.05.045.
   Su Z, 2017, TRANSPORT RES C-EMER, V84, P92, DOI 10.1016/j.trc.2017.08.018.
   Sutton RS, 2018, ADAPT COMPUT MACH LE, P1.
   Tian ZG, 2011, RELIAB ENG SYST SAFE, V96, P581, DOI 10.1016/j.ress.2010.12.023.
   Van Horenbeek A, 2013, RELIAB ENG SYST SAFE, V120, P39, DOI 10.1016/j.ress.2013.02.029.
   Verbert K, 2017, RELIAB ENG SYST SAFE, V159, P310, DOI 10.1016/j.ress.2016.10.032.
   WATKINS CJCH, 1992, MACH LEARN, V8, P279, DOI 10.1007/bf00992698.
   Wei SY, 2020, STRUCT SAF, V83, DOI 10.1016/j.strusafe.2019.101906.
   Xanthopoulos AS, 2018, IEEE ACCESS, V6, DOI 10.1109/ACCESS.2017.2771827.
   Yao LY, 2020, COMPUT-AIDED CIV INF, V35, P1230, DOI 10.1111/mice.12558.
   Zhang NL, 2020, RELIAB ENG SYST SAFE, V203, DOI 10.1016/j.ress.2020.107094.
   Zheng H, 2015, IEEE IJCNN.
   Zhou RSR, 2011, ANN APPL STAT, V5, P1586, DOI 10.1214/10-AOAS448.},
Number-of-Cited-References = {44},
Times-Cited = {0},
Usage-Count-Last-180-days = {2},
Usage-Count-Since-2013 = {5},
Journal-ISO = {IEEE Access},
Doc-Delivery-Number = {RI8NI},
Web-of-Science-Index = {Science Citation Index Expanded (SCI-EXPANDED)},
Unique-ID = {WOS:000637162400001},
OA = {gold},
DA = {2022-04-30},
}

@article{ WOS:000506454400001,
Author = {Wang, Lu and Ai, Wenqing and Deng, Tianhu and Shen, Zuo-Jun M. and Hong,
   Changjing},
Title = {Optimal production ramp-up in the smartphone manufacturing industry},
Journal = {NAVAL RESEARCH LOGISTICS},
Year = {2020},
Volume = {67},
Number = {8, SI},
Pages = {685-704},
Month = {DEC},
Abstract = {Motivated by challenges in the smartphone manufacturing industry, we
   develop a dynamic production ramp-up model that can be applied to
   economically satisfy nonstationary demand for short-life-cycle products
   by high-tech companies. Due to shorter life cycles and more rapid
   evolution of smartphones, production ramp-up has been increasingly
   critical to the success of a new smartphone. In the production ramp-up,
   the key challenge is to match the increasing capacity to nonstationary
   demand. The high-tech smartphone manufacturers are urged to jointly
   consider the effect of increasing capacity and decreasing demand. We
   study the production planning problem using a high-dimensional Markov
   decision process (MDP) model to characterize the production ramp-up. To
   address the curse of dimensionality, we refine Monte Carlo tree search
   (MCTS) algorithm and theoretically analyze its convergence and
   computational complexity. In a real case study, we find that the MDP
   model achieves revenue improvement by stopping producing the existing
   product earlier than the benchmark policy. In synthetic instances, we
   validate that the proposed MCTS algorithm saves computation time without
   loss of solution quality compared with traditional value iteration
   algorithm. As part of the Lenovo production solution, our MDP model
   enables high-tech smartphone manufacturers to better plan the production
   ramp-up.},
Publisher = {WILEY},
Address = {111 RIVER ST, HOBOKEN 07030-5774, NJ USA},
Type = {Article},
Language = {English},
Affiliation = {Deng, TH (Corresponding Author), Tsinghua Univ, Dept Ind Engn, Shunde Bldg,Tsinghua Campus, Beijing 100084, Peoples R China.
   Wang, Lu; Ai, Wenqing; Deng, Tianhu, Tsinghua Univ, Dept Ind Engn, Shunde Bldg,Tsinghua Campus, Beijing 100084, Peoples R China.
   Shen, Zuo-Jun M., Univ Calif Berkeley, Dept Ind Engn \& Operat Res, Berkeley, CA 94720 USA.
   Shen, Zuo-Jun M., Univ Calif Berkeley, Dept Civil \& Environm Engn, Berkeley, CA 94720 USA.
   Hong, Changjing, Lenovo Grp Ltd, Beijing, Peoples R China.},
DOI = {10.1002/nav.21886},
EarlyAccessDate = {JAN 2020},
ISSN = {0894-069X},
EISSN = {1520-6750},
Keywords = {Markov decision process; Monte Carlo tree search; production ramp-up;
   reinforcement learning; smartphone manufacturing industry},
Keywords-Plus = {GO; GAME},
Research-Areas = {Operations Research \& Management Science},
Web-of-Science-Categories  = {Operations Research \& Management Science},
Author-Email = {deng13@mail.tsinghua.edu.cn},
Funding-Acknowledgement = {National Natural Science Foundation of ChinaNational Natural Science
   Foundation of China (NSFC) {[}71822105, 71991462, 91746210]},
Funding-Text = {National Natural Science Foundation of China, 71822105, 71991462,
   91746210.},
Cited-References = {Almgren H, 2000, INT J PROD RES, V38, P4577, DOI 10.1080/00207540050205316.
   {[}Anonymous], 2015, FORTUNE.
   {[}Anonymous], 2018, FUJ PLANS INCR INT L.
   Aydin ME, 2000, ROBOT AUTON SYST, V33, P169, DOI 10.1016/S0921-8890(00)00087-7.
   Aytac B, 2013, ANN OPER RES, V203, P255, DOI 10.1007/s10479-010-0771-5.
   Ball PD, 2011, P I MECH ENG B-J ENG, V225, P959, DOI 10.1177/09544054JEM2071.
   Baud-Lavigne B, 2010, INT J PROD RES, V48, P5843, DOI 10.1080/00207540903150593.
   Bertsimas D, 2017, EUR J OPER RES, V263, P664, DOI 10.1016/j.ejor.2017.05.032.
   Bhatnagar R, 2007, INT J PROD RES, V45, P2051, DOI 10.1080/00207540600665802.
   Breiman L., 1992, MATH GAZ, V77, P128.
   Browne CB, 2012, IEEE T COMP INTEL AI, V4, P1, DOI 10.1109/TCIAIG.2012.2186810.
   Chaslot G.M.J.B., 2006, BNAIC 06 P 18 BELG N, P91.
   Doltsinis S., 2013, INT C MACH LEARN APP, P610.
   Doltsinis S. C., 2012, P 14 IFAC S INF CONT, V45, P1628, DOI DOI 10.3182/20120523-3-R0-2023.00288.
   Doltsinis S, 2014, IEEE T SYST MAN CY-S, V44, P1125, DOI 10.1109/TSMC.2013.2294155.
   Fjallstrom S, 2009, J MANUF TECHNOL MANA, V20, P178, DOI 10.1108/17410380910929619.
   Glock CH, 2012, INT J PROD RES, V50, P5707, DOI 10.1080/00207543.2011.616549.
   Hu KJ, 2019, M\&SOM-MANUF SERV OP, V21, P66, DOI 10.1287/msom.2017.0691.
   Jiang Daniel R., 2017, TECHNICAL REPORT.
   Kartal B., 2013, 9 ART INT INT DIG EN.
   Kontio J, 2005, INT J INNOV TECHNOL, V2, P101, DOI 10.1142/S021987700500037X.
   Kushner H., 2003, STOCHASTIC APPROXIMA.
   Lovejoy B., 2017, APPLES APPETITE COMP.
   Mao C, 2018, TRANSPORT RES C-EMER, V93, P179, DOI 10.1016/j.trc.2018.06.001.
   Matta A, 2007, INT J FLEX MANUF SYS, V19, P173, DOI 10.1007/s10696-007-9023-7.
   McKiernan D., 2015, 9 SCENARIOS COMMON A.
   Meier H., 2006, P 16 CIRP INT DES SE.
   Mnih V., 2013, ARXIV.
   Mnih V, 2015, NATURE, V518, P529, DOI 10.1038/nature14236.
   Nair S., 2018, STAR ONLINE.
   Peter D., 2007, P 3 N AM GAM ON C GA, P273.
   Rasmussen P., 2018, ELECT COMPONENTS SHO.
   Rdutnik M., 2017, 2017 RELEASE CALENDA.
   Richard S.S., 2018, REINFORCEMENT LEARNI, V2nd.
   Shah N., 2018, APPLES REVENUE SUPER.
   Shahrabi J, 2017, COMPUT IND ENG, V110, P75, DOI 10.1016/j.cie.2017.05.026.
   Silver D, 2018, SCIENCE, V362, P1140, DOI 10.1126/science.aar6404.
   Silver D, 2017, NATURE, V550, P354, DOI 10.1038/nature24270.
   Silver D, 2016, NATURE, V529, P484, DOI 10.1038/nature16961.
   Smart, 2015, LIF CYCL MOB PHON.
   Statista, 2018, GLOB SMARTPH SHIPM 2.
   Surbier L, 2014, PROD PLAN CONTROL, V25, P1264, DOI 10.1080/09537287.2013.817624.
   Terwiesch C, 2004, IEEE T ENG MANAGE, V51, P70, DOI 10.1109/TEM.2003.822465.
   Terwiesch C, 2001, R\&D MANAGE, V31, P435, DOI 10.1111/1467-9310.00230.
   Terwiesch C., 1998, INT J PROD ECON, V70, P1.
   Wang YC, 2005, ENG APPL ARTIF INTEL, V18, P73, DOI 10.1016/j.engappai.2004.08.018.
   Wei Zhang, 1995, IJCAI-95. Proceedings of the Fourteenth International Joint Conference on Artificial Intelligence, P1114.
   Winkler H, 2007, PROD ENG-RES DEV, V1, P103, DOI 10.1007/s11740-007-0011-2.},
Number-of-Cited-References = {48},
Times-Cited = {0},
Usage-Count-Last-180-days = {6},
Usage-Count-Since-2013 = {13},
Journal-ISO = {Nav. Res. Logist.},
Doc-Delivery-Number = {OK3QV},
Web-of-Science-Index = {Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)},
Unique-ID = {WOS:000506454400001},
DA = {2022-04-30},
}

@article{ WOS:000254680300003,
Author = {Askairi-Nasab, H. and Frimpong, S. and Szymanski, J.},
Title = {Investigating continuous time open pit dynamics},
Journal = {JOURNAL OF THE SOUTH AFRICAN INSTITUTE OF MINING AND METALLURGY},
Year = {2008},
Volume = {108},
Number = {2},
Pages = {61-71},
Month = {FEB},
Abstract = {Current mine production planning, scheduling, and allocation of
   resources are based on mathematical programming models. In practice, the
   optimized solution cannot be attained without examining all possible
   combinations and permutations of the extraction sequence. Operations
   research methods have limited applications in large-scale surface mining
   operations because the number of variables becomes too large. The
   primary objective of this study is to develop and implement a hybrid
   simulation framework for {[}he open pit scheduling problem. The paper
   investigates the dynamics of open pit geometry and the subsequent
   material movement as a continuous system described by time-dependent
   differential equations. The continuous open pit simulator (COPS)
   implemented in MATLAB, based on modified elliptical frustum is used to
   model the evolution of open pit geometry in time and space. Discrete
   open pit simulator (DOPS) mimics the periodic expansion of the open pit
   layouts. Function approximation of the discrete simulated push-backs
   provides the means to convert the set of partial differential equations
   (PDEs), capturing the dynamics of open pit layouts, to a system of
   ordinary differential equations (ODEs). Numerical integration with the
   Runge-Kutta scheme yields the trajectory of the pit geometry over time
   with the respective volume of materials and the net present value (NPV)
   of the mining operation. A case study of an iron ore mine with 114 000
   blocks was carried out to verify and validate the model. The optimized
   pit limit was designed using Lerchs-Grossman's algorithm. The best-case
   annual schedule, generated by the shells node in Whittle Four-X yielded
   an NPV of \$449 million over a 21-year mine life at a discount rate of
   10\% per annum. DOPS best scenario out of 2 500 simulation iterations
   resulted in an NPV of \$443 million and COPS yielded an NPV of \$440
   million over the same time span. The hybrid simulation model is the
   basis for future research using reinforcement learning based on
   goal-directed intelligent agents.},
Publisher = {SOUTH AFRICAN INST MINING METALLURGY},
Address = {5 HOLLARD ST, 5TH FLOOR, CHAMBER OF MINES BUILDING, PO BOX 61127,
   MARSHALLTOWN         L 2107, SOUTH AFRICA},
Type = {Article},
Language = {English},
Affiliation = {Askairi-Nasab, H (Corresponding Author), Univ Alberta, Sch Min \& Petr Engn, Edmonton, AB, Canada.
   Askairi-Nasab, H.; Szymanski, J., Univ Alberta, Sch Min \& Petr Engn, Edmonton, AB, Canada.
   Frimpong, S., Univ Missouri, Dept Min \& Nucl Engn, Rolla, MO 65401 USA.},
ISSN = {0038-223X},
Research-Areas = {Metallurgy \& Metallurgical Engineering; Mining \& Mineral Processing},
Web-of-Science-Categories  = {Metallurgy \& Metallurgical Engineering; Mining \& Mineral Processing},
Cited-References = {Abramowitz M., 1972, HDB MATH FUNCTIONS F, P880.
   ASKARINASAB H, 2004, P CIM IND IND C EXH.
   ASKARINASAB H, 2005, P COMP APPL MIN IND, P21.
   Cartwright J.H., 1992, INT J BIFURCAT CHAOS, V2, P427.
   Chanda E. K. C., 1992, P 23 APCOM S SME, P759.
   CHANG DY, 1995, CONSTR BUILD MATER, V9, P205, DOI 10.1016/0950-0618(95)00011-4.
   Deutsch C., 1998, APPL GEOSTATISTICAL.
   DOWD PA, 1987, T I MIN METALL A, V96, pA171.
   Elveli B., 1995, INT J SURFACE MIN RE, V9, P149, DOI DOI 10.1080/09208119508964741.
   Frimpong S, 2001, MINER RESOUR ENG, V10, P185, DOI 10.1142/S0950609801000609.
   Frimpong S., 1998, INT J SURFACE MINING, V12, P163.
   Halatchev R.A., 2005, P 32 INT S APPL COMP, P315.
   KRIGE DG, 1951, THESIS U WITWATERSAN.
   LERCHS H, 1965, T CAN I MIN METALL, V68, P17.
   MANN C, 1992, P 23 S APPL COMP OP, P487.
   MARQUARDT DW, 1963, J SOC IND APPL MATH, V11, P441.
   ONUR AH, 1993, T I MIN METALL A, V102, pA105.
   Tolwinski B., 1992, P 23 APCOM S, P399.
   {*}WHITTL PROGR PTY, 1998, WHITTL STRAT MIN PLA.
   YOUDI Z, 1992, P 23 APCOM S SME, P499.},
Number-of-Cited-References = {20},
Times-Cited = {2},
Usage-Count-Last-180-days = {0},
Usage-Count-Since-2013 = {8},
Journal-ISO = {J. S. Afr. Inst. Min. Metall.},
Doc-Delivery-Number = {284BN},
Web-of-Science-Index = {Science Citation Index Expanded (SCI-EXPANDED)},
Unique-ID = {WOS:000254680300003},
DA = {2022-04-30},
}
